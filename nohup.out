Using config everywhere
{'image': {'crop': (1, 1),
           'height': 258,
           'padding': (0, 0, 0, 0),
           'width': 293},
 'loader': 'custom',
 'test': {'divide_test': 0.1,
          'ignore': ['AmatriceQuakes',
                     '18.468--67.111099',
                     '33.210098--116.409103',
                     '18.979361--155.667892',
                     '39.5089--119.836601',
                     '36.956821--97.96302',
                     'OklahomaQuakes',
                     '18.018099--66.022209',
                     '33.6688--116.672997',
                     '19.372066--155.45723-minmag1',
                     '-34.7924--70.781403',
                     '-35.009899--71.930298',
                     'SouthAmerica',
                     '-33.391899--70.738098',
                     '41.195831--111.941673',
                     '-18.3708--70.341904-minmag1',
                     '37.672501--113.071487',
                     '33.509701--116.561501',
                     '20.125248--155.777374',
                     '33.539398--116.592201-minmag1',
                     '32.891998--116.422302',
                     '-33.391899--70.738098-minmag1',
                     '33.029999--116.085297',
                     '33.457699--117.170799',
                     '33.599991--117.195427',
                     '40.723--111.907173',
                     '18.979361--155.667892-minmag1',
                     '-28.204599--71.073898',
                     '33.260201--116.322304',
                     '-35.009899--71.930298-minmag1',
                     '33.210098--116.409103-minmag1',
                     '33.029999--116.085297-minmag1',
                     '19.372066--155.45723',
                     '18.4709--66.740303-minmag1',
                     '17.969427--67.04422',
                     '-33.9967--71.590202',
                     '33.495499--116.583397',
                     '32.820301--117.056702',
                     '39.539101--119.813797',
                     '-33.259102--71.137703-minmag1',
                     '19.493172--155.386017-minmag1',
                     '19.480289--154.888565',
                     '37.205967--97.9133',
                     '36.807339--97.74765',
                     '-30.8389--70.689102',
                     '37.29977--97.572701',
                     '-30.172701--70.799301',
                     '-33.308998--71.3908',
                     'ls',
                     '-35.205399--71.966599',
                     '19.493172--155.386017',
                     '33.144199--116.119301',
                     '-22.95196--68.178757',
                     '33.495499--116.583397-minmag1',
                     '48.010799--114.363297',
                     '37.044071--97.764748',
                     '-31.203699--71.000298',
                     '37.136131--97.618317',
                     '-33.0229--71.637398',
                     '-34.496052--71.961197',
                     '38.457401--118.7658',
                     '37.197968--97.879379',
                     '-32.763699--70.550797',
                     '39.155861--111.819458'],
          'path': 'all-spectrograms-symlinks/97'},
 'train': {'divide_test': 0,
           'ignore': ['benz'],
           'path': 'all-spectrograms-symlinks/97'},
 'weigh_classes': [1, 3]}

Writing Info
/home/audretjm/anaconda3/envs/earthquake/lib/python3.6/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  % get_backend())
Train Epoch: 1 [1024/702208 (0%)]	Loss: 0.554820Train Epoch: 1 [2048/702208 (0%)]	Loss: 0.578854Train Epoch: 1 [3072/702208 (0%)]	Loss: 0.528094Train Epoch: 1 [4096/702208 (1%)]	Loss: 0.546747Train Epoch: 1 [5120/702208 (1%)]	Loss: 0.497606Train Epoch: 1 [6016/702208 (1%)]	Loss: 0.484889Train Epoch: 1 [7040/702208 (1%)]	Loss: 0.469279Train Epoch: 1 [8064/702208 (1%)]	Loss: 0.453459Train Epoch: 1 [9088/702208 (1%)]	Loss: 0.438250Train Epoch: 1 [10112/702208 (1%)]	Loss: 0.428671Train Epoch: 1 [11008/702208 (2%)]	Loss: 0.410851Train Epoch: 1 [12032/702208 (2%)]	Loss: 0.423825Train Epoch: 1 [13056/702208 (2%)]	Loss: 0.426740Train Epoch: 1 [14080/702208 (2%)]	Loss: 0.366146Train Epoch: 1 [15104/702208 (2%)]	Loss: 0.381345Train Epoch: 1 [16000/702208 (2%)]	Loss: 0.425824Train Epoch: 1 [16128/702208 (2%)]	Loss: 0.406706Train Epoch: 1 [17024/702208 (2%)]	Loss: 0.329947Train Epoch: 1 [18048/702208 (3%)]	Loss: 0.365997Train Epoch: 1 [19072/702208 (3%)]	Loss: 0.378495Train Epoch: 1 [20096/702208 (3%)]	Loss: 0.376749Train Epoch: 1 [21120/702208 (3%)]	Loss: 0.402359Train Epoch: 1 [22016/702208 (3%)]	Loss: 0.349477Train Epoch: 1 [23040/702208 (3%)]	Loss: 0.321058Train Epoch: 1 [24064/702208 (3%)]	Loss: 0.314025Train Epoch: 1 [25088/702208 (4%)]	Loss: 0.261464
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 93 %
Accuracy of the network on test loader class  0: [7704 / 8283] 93 %
Accuracy of the network on test loader class  1: [4254 / 4517] 94 %

Writing model: iterations-25088-total-93.42-class0-93.01-class1-94.17999999999999
Train Epoch: 1 [26112/702208 (4%)]	Loss: 0.269094Train Epoch: 1 [27008/702208 (4%)]	Loss: 0.403457Train Epoch: 1 [28032/702208 (4%)]	Loss: 0.265206Train Epoch: 1 [29056/702208 (4%)]	Loss: 0.309975Train Epoch: 1 [30080/702208 (4%)]	Loss: 0.185219Train Epoch: 1 [31104/702208 (4%)]	Loss: 0.362047Train Epoch: 1 [32000/702208 (5%)]	Loss: 0.297811Train Epoch: 1 [32128/702208 (5%)]	Loss: 0.291841Train Epoch: 1 [33024/702208 (5%)]	Loss: 0.230797Train Epoch: 1 [34048/702208 (5%)]	Loss: 0.301790Train Epoch: 1 [35072/702208 (5%)]	Loss: 0.343902Train Epoch: 1 [36096/702208 (5%)]	Loss: 0.318396Train Epoch: 1 [37120/702208 (5%)]	Loss: 0.343735Train Epoch: 1 [38016/702208 (5%)]	Loss: 0.235300Train Epoch: 1 [39040/702208 (6%)]	Loss: 0.352820Train Epoch: 1 [40064/702208 (6%)]	Loss: 0.317673Train Epoch: 1 [41088/702208 (6%)]	Loss: 0.296728Train Epoch: 1 [42112/702208 (6%)]	Loss: 0.253378Train Epoch: 1 [43008/702208 (6%)]	Loss: 0.294398Train Epoch: 1 [44032/702208 (6%)]	Loss: 0.277072Train Epoch: 1 [45056/702208 (6%)]	Loss: 0.347426Train Epoch: 1 [46080/702208 (7%)]	Loss: 0.232559Train Epoch: 1 [47104/702208 (7%)]	Loss: 0.220138Train Epoch: 1 [48000/702208 (7%)]	Loss: 0.351996Train Epoch: 1 [48128/702208 (7%)]	Loss: 0.435822Train Epoch: 1 [49024/702208 (7%)]	Loss: 0.322801Train Epoch: 1 [50048/702208 (7%)]	Loss: 0.233906
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 93 %
Accuracy of the network on test loader class  0: [7701 / 8283] 92 %
Accuracy of the network on test loader class  1: [4273 / 4517] 94 %

Writing model: iterations-50048-total-93.55-class0-92.97-class1-94.6

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 87 %
Accuracy of the network on train loader class  0: [11302 / 12833] 88 %
Accuracy of the network on train loader class  1: [6265 / 7135] 87 %
Train Epoch: 1 [51072/702208 (7%)]	Loss: 0.202131Train Epoch: 1 [52096/702208 (7%)]	Loss: 0.301538Train Epoch: 1 [53120/702208 (8%)]	Loss: 0.231571Train Epoch: 1 [54016/702208 (8%)]	Loss: 0.354502Train Epoch: 1 [55040/702208 (8%)]	Loss: 0.253385Train Epoch: 1 [56064/702208 (8%)]	Loss: 0.204875Train Epoch: 1 [57088/702208 (8%)]	Loss: 0.206288Train Epoch: 1 [58112/702208 (8%)]	Loss: 0.311093Train Epoch: 1 [59008/702208 (8%)]	Loss: 0.236839Train Epoch: 1 [60032/702208 (9%)]	Loss: 0.221598Train Epoch: 1 [61056/702208 (9%)]	Loss: 0.198035Train Epoch: 1 [62080/702208 (9%)]	Loss: 0.218403Train Epoch: 1 [63104/702208 (9%)]	Loss: 0.232961Train Epoch: 1 [64000/702208 (9%)]	Loss: 0.275427Train Epoch: 1 [64128/702208 (9%)]	Loss: 0.225652Train Epoch: 1 [65024/702208 (9%)]	Loss: 0.221349Train Epoch: 1 [66048/702208 (9%)]	Loss: 0.216483Train Epoch: 1 [67072/702208 (10%)]	Loss: 0.267962Train Epoch: 1 [68096/702208 (10%)]	Loss: 0.234057Train Epoch: 1 [69120/702208 (10%)]	Loss: 0.223657Train Epoch: 1 [70016/702208 (10%)]	Loss: 0.219302Train Epoch: 1 [71040/702208 (10%)]	Loss: 0.272591Train Epoch: 1 [72064/702208 (10%)]	Loss: 0.194292Train Epoch: 1 [73088/702208 (10%)]	Loss: 0.256425Train Epoch: 1 [74112/702208 (11%)]	Loss: 0.217533Train Epoch: 1 [75008/702208 (11%)]	Loss: 0.284840
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 92 %
Accuracy of the network on test loader class  0: [7445 / 8283] 89 %
Accuracy of the network on test loader class  1: [4439 / 4517] 98 %

Writing model: iterations-75008-total-92.84-class0-89.88000000000001-class1-98.27
Train Epoch: 1 [76032/702208 (11%)]	Loss: 0.135191Train Epoch: 1 [77056/702208 (11%)]	Loss: 0.274432Train Epoch: 1 [78080/702208 (11%)]	Loss: 0.311423Train Epoch: 1 [79104/702208 (11%)]	Loss: 0.246699Train Epoch: 1 [80000/702208 (11%)]	Loss: 0.262804Train Epoch: 1 [80128/702208 (11%)]	Loss: 0.209349Train Epoch: 1 [81024/702208 (12%)]	Loss: 0.193048Train Epoch: 1 [82048/702208 (12%)]	Loss: 0.205320Train Epoch: 1 [83072/702208 (12%)]	Loss: 0.200298Train Epoch: 1 [84096/702208 (12%)]	Loss: 0.203404Train Epoch: 1 [85120/702208 (12%)]	Loss: 0.267269Train Epoch: 1 [86016/702208 (12%)]	Loss: 0.262233Train Epoch: 1 [87040/702208 (12%)]	Loss: 0.161395Train Epoch: 1 [88064/702208 (13%)]	Loss: 0.207959Train Epoch: 1 [89088/702208 (13%)]	Loss: 0.286717Train Epoch: 1 [90112/702208 (13%)]	Loss: 0.257754Train Epoch: 1 [91008/702208 (13%)]	Loss: 0.243081Train Epoch: 1 [92032/702208 (13%)]	Loss: 0.224214Train Epoch: 1 [93056/702208 (13%)]	Loss: 0.202906Train Epoch: 1 [94080/702208 (13%)]	Loss: 0.161813Train Epoch: 1 [95104/702208 (14%)]	Loss: 0.296648Train Epoch: 1 [96000/702208 (14%)]	Loss: 0.187770Train Epoch: 1 [96128/702208 (14%)]	Loss: 0.202708Train Epoch: 1 [97024/702208 (14%)]	Loss: 0.222379Train Epoch: 1 [98048/702208 (14%)]	Loss: 0.225621Train Epoch: 1 [99072/702208 (14%)]	Loss: 0.169318Train Epoch: 1 [100096/702208 (14%)]	Loss: 0.135302
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7852 / 8283] 94 %
Accuracy of the network on test loader class  1: [4393 / 4517] 97 %

Writing model: iterations-100096-total-95.66-class0-94.8-class1-97.25

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 90 %
Accuracy of the network on train loader class  0: [11578 / 12833] 90 %
Accuracy of the network on train loader class  1: [6542 / 7135] 91 %
Train Epoch: 1 [101120/702208 (14%)]	Loss: 0.207226Train Epoch: 1 [102016/702208 (15%)]	Loss: 0.186908Train Epoch: 1 [103040/702208 (15%)]	Loss: 0.163718Train Epoch: 1 [104064/702208 (15%)]	Loss: 0.302394Train Epoch: 1 [105088/702208 (15%)]	Loss: 0.205544Train Epoch: 1 [106112/702208 (15%)]	Loss: 0.180924Train Epoch: 1 [107008/702208 (15%)]	Loss: 0.165104Train Epoch: 1 [108032/702208 (15%)]	Loss: 0.198320Train Epoch: 1 [109056/702208 (16%)]	Loss: 0.185263Train Epoch: 1 [110080/702208 (16%)]	Loss: 0.109928Train Epoch: 1 [111104/702208 (16%)]	Loss: 0.175940Train Epoch: 1 [112000/702208 (16%)]	Loss: 0.225318Train Epoch: 1 [112128/702208 (16%)]	Loss: 0.166036Train Epoch: 1 [113024/702208 (16%)]	Loss: 0.259783Train Epoch: 1 [114048/702208 (16%)]	Loss: 0.180012Train Epoch: 1 [115072/702208 (16%)]	Loss: 0.189737Train Epoch: 1 [116096/702208 (17%)]	Loss: 0.215528Train Epoch: 1 [117120/702208 (17%)]	Loss: 0.229951Train Epoch: 1 [118016/702208 (17%)]	Loss: 0.230803Train Epoch: 1 [119040/702208 (17%)]	Loss: 0.111362Train Epoch: 1 [120064/702208 (17%)]	Loss: 0.172879Train Epoch: 1 [121088/702208 (17%)]	Loss: 0.188984Train Epoch: 1 [122112/702208 (17%)]	Loss: 0.242629Train Epoch: 1 [123008/702208 (18%)]	Loss: 0.289757Train Epoch: 1 [124032/702208 (18%)]	Loss: 0.175452Train Epoch: 1 [125056/702208 (18%)]	Loss: 0.225677
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 94 %
Accuracy of the network on test loader class  0: [7677 / 8283] 92 %
Accuracy of the network on test loader class  1: [4404 / 4517] 97 %

Writing model: iterations-125056-total-94.38-class0-92.67999999999999-class1-97.5
Train Epoch: 1 [126080/702208 (18%)]	Loss: 0.213894Train Epoch: 1 [127104/702208 (18%)]	Loss: 0.131430Train Epoch: 1 [128000/702208 (18%)]	Loss: 0.139551Train Epoch: 1 [128128/702208 (18%)]	Loss: 0.255471Train Epoch: 1 [129024/702208 (18%)]	Loss: 0.186704Train Epoch: 1 [130048/702208 (19%)]	Loss: 0.219415Train Epoch: 1 [131072/702208 (19%)]	Loss: 0.217991Train Epoch: 1 [132096/702208 (19%)]	Loss: 0.171174Train Epoch: 1 [133120/702208 (19%)]	Loss: 0.192296Train Epoch: 1 [134016/702208 (19%)]	Loss: 0.157560Train Epoch: 1 [135040/702208 (19%)]	Loss: 0.224524Train Epoch: 1 [136064/702208 (19%)]	Loss: 0.178575Train Epoch: 1 [137088/702208 (20%)]	Loss: 0.205928Train Epoch: 1 [138112/702208 (20%)]	Loss: 0.202055Train Epoch: 1 [139008/702208 (20%)]	Loss: 0.152838Train Epoch: 1 [140032/702208 (20%)]	Loss: 0.149419Train Epoch: 1 [141056/702208 (20%)]	Loss: 0.248814Train Epoch: 1 [142080/702208 (20%)]	Loss: 0.154239Train Epoch: 1 [143104/702208 (20%)]	Loss: 0.158856Train Epoch: 1 [144000/702208 (21%)]	Loss: 0.185368Train Epoch: 1 [144128/702208 (21%)]	Loss: 0.132571Train Epoch: 1 [145024/702208 (21%)]	Loss: 0.180894Train Epoch: 1 [146048/702208 (21%)]	Loss: 0.194807Train Epoch: 1 [147072/702208 (21%)]	Loss: 0.181587Train Epoch: 1 [148096/702208 (21%)]	Loss: 0.219253Train Epoch: 1 [149120/702208 (21%)]	Loss: 0.167482Train Epoch: 1 [150016/702208 (21%)]	Loss: 0.164774
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 94 %
Accuracy of the network on test loader class  0: [7667 / 8283] 92 %
Accuracy of the network on test loader class  1: [4435 / 4517] 98 %

Writing model: iterations-150016-total-94.55-class0-92.56-class1-98.18

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 85 %
Accuracy of the network on train loader class  0: [10222 / 12833] 79 %
Accuracy of the network on train loader class  1: [6821 / 7135] 95 %
Train Epoch: 1 [151040/702208 (22%)]	Loss: 0.129906Train Epoch: 1 [152064/702208 (22%)]	Loss: 0.148109Train Epoch: 1 [153088/702208 (22%)]	Loss: 0.154580Train Epoch: 1 [154112/702208 (22%)]	Loss: 0.257076Train Epoch: 1 [155008/702208 (22%)]	Loss: 0.262049Train Epoch: 1 [156032/702208 (22%)]	Loss: 0.161261Train Epoch: 1 [157056/702208 (22%)]	Loss: 0.157737Train Epoch: 1 [158080/702208 (23%)]	Loss: 0.168102Train Epoch: 1 [159104/702208 (23%)]	Loss: 0.171113Train Epoch: 1 [160000/702208 (23%)]	Loss: 0.118692Train Epoch: 1 [160128/702208 (23%)]	Loss: 0.251161Train Epoch: 1 [161024/702208 (23%)]	Loss: 0.193385Train Epoch: 1 [162048/702208 (23%)]	Loss: 0.136401Train Epoch: 1 [163072/702208 (23%)]	Loss: 0.208052Train Epoch: 1 [164096/702208 (23%)]	Loss: 0.182022Train Epoch: 1 [165120/702208 (24%)]	Loss: 0.188568Train Epoch: 1 [166016/702208 (24%)]	Loss: 0.208252Train Epoch: 1 [167040/702208 (24%)]	Loss: 0.226741Train Epoch: 1 [168064/702208 (24%)]	Loss: 0.176831Train Epoch: 1 [169088/702208 (24%)]	Loss: 0.163523Train Epoch: 1 [170112/702208 (24%)]	Loss: 0.124949Train Epoch: 1 [171008/702208 (24%)]	Loss: 0.163465Train Epoch: 1 [172032/702208 (24%)]	Loss: 0.121430Train Epoch: 1 [173056/702208 (25%)]	Loss: 0.100116Train Epoch: 1 [174080/702208 (25%)]	Loss: 0.227081Train Epoch: 1 [175104/702208 (25%)]	Loss: 0.180237
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [8019 / 8283] 96 %
Accuracy of the network on test loader class  1: [4372 / 4517] 96 %

Writing model: iterations-175104-total-96.8-class0-96.81-class1-96.78999999999999
Train Epoch: 1 [176000/702208 (25%)]	Loss: 0.210687Train Epoch: 1 [176128/702208 (25%)]	Loss: 0.112636Train Epoch: 1 [177024/702208 (25%)]	Loss: 0.146155Train Epoch: 1 [178048/702208 (25%)]	Loss: 0.180781Train Epoch: 1 [179072/702208 (26%)]	Loss: 0.159120Train Epoch: 1 [180096/702208 (26%)]	Loss: 0.222719Train Epoch: 1 [181120/702208 (26%)]	Loss: 0.131505Train Epoch: 1 [182016/702208 (26%)]	Loss: 0.166685Train Epoch: 1 [183040/702208 (26%)]	Loss: 0.194346Train Epoch: 1 [184064/702208 (26%)]	Loss: 0.168502Train Epoch: 1 [185088/702208 (26%)]	Loss: 0.186690Train Epoch: 1 [186112/702208 (27%)]	Loss: 0.144672Train Epoch: 1 [187008/702208 (27%)]	Loss: 0.126213Train Epoch: 1 [188032/702208 (27%)]	Loss: 0.146452Train Epoch: 1 [189056/702208 (27%)]	Loss: 0.138402Train Epoch: 1 [190080/702208 (27%)]	Loss: 0.179376Train Epoch: 1 [191104/702208 (27%)]	Loss: 0.138835Train Epoch: 1 [192000/702208 (27%)]	Loss: 0.172367Train Epoch: 1 [192128/702208 (27%)]	Loss: 0.214724Train Epoch: 1 [193024/702208 (27%)]	Loss: 0.129155Train Epoch: 1 [194048/702208 (28%)]	Loss: 0.162091Train Epoch: 1 [195072/702208 (28%)]	Loss: 0.173287Train Epoch: 1 [196096/702208 (28%)]	Loss: 0.181847Train Epoch: 1 [197120/702208 (28%)]	Loss: 0.144248Train Epoch: 1 [198016/702208 (28%)]	Loss: 0.113783Train Epoch: 1 [199040/702208 (28%)]	Loss: 0.145211Train Epoch: 1 [200064/702208 (28%)]	Loss: 0.233479
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7934 / 8283] 95 %
Accuracy of the network on test loader class  1: [4419 / 4517] 97 %

Writing model: iterations-200064-total-96.50999999999999-class0-95.78999999999999-class1-97.83

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 91 %
Accuracy of the network on train loader class  0: [11588 / 12833] 90 %
Accuracy of the network on train loader class  1: [6635 / 7135] 92 %
Train Epoch: 1 [201088/702208 (29%)]	Loss: 0.166587Train Epoch: 1 [202112/702208 (29%)]	Loss: 0.179917Train Epoch: 1 [203008/702208 (29%)]	Loss: 0.200828Train Epoch: 1 [204032/702208 (29%)]	Loss: 0.139459Train Epoch: 1 [205056/702208 (29%)]	Loss: 0.099412Train Epoch: 1 [206080/702208 (29%)]	Loss: 0.229484Train Epoch: 1 [207104/702208 (29%)]	Loss: 0.158226Train Epoch: 1 [208000/702208 (30%)]	Loss: 0.125726Train Epoch: 1 [208128/702208 (30%)]	Loss: 0.145481Train Epoch: 1 [209024/702208 (30%)]	Loss: 0.109871Train Epoch: 1 [210048/702208 (30%)]	Loss: 0.116768Train Epoch: 1 [211072/702208 (30%)]	Loss: 0.107607Train Epoch: 1 [212096/702208 (30%)]	Loss: 0.117493Train Epoch: 1 [213120/702208 (30%)]	Loss: 0.174091Train Epoch: 1 [214016/702208 (30%)]	Loss: 0.139938Train Epoch: 1 [215040/702208 (31%)]	Loss: 0.181930Train Epoch: 1 [216064/702208 (31%)]	Loss: 0.206354Train Epoch: 1 [217088/702208 (31%)]	Loss: 0.244581Train Epoch: 1 [218112/702208 (31%)]	Loss: 0.179219Train Epoch: 1 [219008/702208 (31%)]	Loss: 0.168180Train Epoch: 1 [220032/702208 (31%)]	Loss: 0.280823Train Epoch: 1 [221056/702208 (31%)]	Loss: 0.162622Train Epoch: 1 [222080/702208 (32%)]	Loss: 0.100480Train Epoch: 1 [223104/702208 (32%)]	Loss: 0.119512Train Epoch: 1 [224000/702208 (32%)]	Loss: 0.131916Train Epoch: 1 [224128/702208 (32%)]	Loss: 0.302592Train Epoch: 1 [225024/702208 (32%)]	Loss: 0.158310
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 94 %
Accuracy of the network on test loader class  0: [7589 / 8283] 91 %
Accuracy of the network on test loader class  1: [4469 / 4517] 98 %

Writing model: iterations-225024-total-94.19999999999999-class0-91.62-class1-98.94
Train Epoch: 1 [226048/702208 (32%)]	Loss: 0.195639Train Epoch: 1 [227072/702208 (32%)]	Loss: 0.160599Train Epoch: 1 [228096/702208 (32%)]	Loss: 0.170711Train Epoch: 1 [229120/702208 (33%)]	Loss: 0.182571Train Epoch: 1 [230016/702208 (33%)]	Loss: 0.163316Train Epoch: 1 [231040/702208 (33%)]	Loss: 0.228369Train Epoch: 1 [232064/702208 (33%)]	Loss: 0.155435Train Epoch: 1 [233088/702208 (33%)]	Loss: 0.127809Train Epoch: 1 [234112/702208 (33%)]	Loss: 0.113947Train Epoch: 1 [235008/702208 (33%)]	Loss: 0.126796Train Epoch: 1 [236032/702208 (34%)]	Loss: 0.269425Train Epoch: 1 [237056/702208 (34%)]	Loss: 0.115583Train Epoch: 1 [238080/702208 (34%)]	Loss: 0.106413Train Epoch: 1 [239104/702208 (34%)]	Loss: 0.164425Train Epoch: 1 [240000/702208 (34%)]	Loss: 0.209685Train Epoch: 1 [240128/702208 (34%)]	Loss: 0.086215Train Epoch: 1 [241024/702208 (34%)]	Loss: 0.208701Train Epoch: 1 [242048/702208 (34%)]	Loss: 0.146097Train Epoch: 1 [243072/702208 (35%)]	Loss: 0.166095Train Epoch: 1 [244096/702208 (35%)]	Loss: 0.182328Train Epoch: 1 [245120/702208 (35%)]	Loss: 0.164040Train Epoch: 1 [246016/702208 (35%)]	Loss: 0.139977Train Epoch: 1 [247040/702208 (35%)]	Loss: 0.157522Train Epoch: 1 [248064/702208 (35%)]	Loss: 0.188707Train Epoch: 1 [249088/702208 (35%)]	Loss: 0.181328Train Epoch: 1 [250112/702208 (36%)]	Loss: 0.148235
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7868 / 8283] 94 %
Accuracy of the network on test loader class  1: [4458 / 4517] 98 %

Writing model: iterations-250112-total-96.3-class0-94.99-class1-98.69

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 89 %
Accuracy of the network on train loader class  0: [11147 / 12833] 86 %
Accuracy of the network on train loader class  1: [6709 / 7135] 94 %
Train Epoch: 1 [251008/702208 (36%)]	Loss: 0.150881Train Epoch: 1 [252032/702208 (36%)]	Loss: 0.117321Train Epoch: 1 [253056/702208 (36%)]	Loss: 0.142456Train Epoch: 1 [254080/702208 (36%)]	Loss: 0.168877Train Epoch: 1 [255104/702208 (36%)]	Loss: 0.112720Train Epoch: 1 [256000/702208 (36%)]	Loss: 0.128997Train Epoch: 1 [256128/702208 (36%)]	Loss: 0.143862Train Epoch: 1 [257024/702208 (37%)]	Loss: 0.107821Train Epoch: 1 [258048/702208 (37%)]	Loss: 0.118422Train Epoch: 1 [259072/702208 (37%)]	Loss: 0.136870Train Epoch: 1 [260096/702208 (37%)]	Loss: 0.115260Train Epoch: 1 [261120/702208 (37%)]	Loss: 0.195948Train Epoch: 1 [262016/702208 (37%)]	Loss: 0.187591Train Epoch: 1 [263040/702208 (37%)]	Loss: 0.158159Train Epoch: 1 [264064/702208 (38%)]	Loss: 0.125159Train Epoch: 1 [265088/702208 (38%)]	Loss: 0.140999Train Epoch: 1 [266112/702208 (38%)]	Loss: 0.136362Train Epoch: 1 [267008/702208 (38%)]	Loss: 0.200593Train Epoch: 1 [268032/702208 (38%)]	Loss: 0.123629Train Epoch: 1 [269056/702208 (38%)]	Loss: 0.151546Train Epoch: 1 [270080/702208 (38%)]	Loss: 0.105231Train Epoch: 1 [271104/702208 (39%)]	Loss: 0.110451Train Epoch: 1 [272000/702208 (39%)]	Loss: 0.236076Train Epoch: 1 [272128/702208 (39%)]	Loss: 0.108239Train Epoch: 1 [273024/702208 (39%)]	Loss: 0.229484Train Epoch: 1 [274048/702208 (39%)]	Loss: 0.189373Train Epoch: 1 [275072/702208 (39%)]	Loss: 0.274813
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7822 / 8283] 94 %
Accuracy of the network on test loader class  1: [4444 / 4517] 98 %

Writing model: iterations-275072-total-95.83-class0-94.43-class1-98.38
Train Epoch: 1 [276096/702208 (39%)]	Loss: 0.121756Train Epoch: 1 [277120/702208 (39%)]	Loss: 0.131361Train Epoch: 1 [278016/702208 (40%)]	Loss: 0.116007Train Epoch: 1 [279040/702208 (40%)]	Loss: 0.149541Train Epoch: 1 [280064/702208 (40%)]	Loss: 0.095551Train Epoch: 1 [281088/702208 (40%)]	Loss: 0.149984Train Epoch: 1 [282112/702208 (40%)]	Loss: 0.207289Train Epoch: 1 [283008/702208 (40%)]	Loss: 0.171594Train Epoch: 1 [284032/702208 (40%)]	Loss: 0.175246Train Epoch: 1 [285056/702208 (41%)]	Loss: 0.178638Train Epoch: 1 [286080/702208 (41%)]	Loss: 0.131051Train Epoch: 1 [287104/702208 (41%)]	Loss: 0.241005Train Epoch: 1 [288000/702208 (41%)]	Loss: 0.142543Train Epoch: 1 [288128/702208 (41%)]	Loss: 0.156012Train Epoch: 1 [289024/702208 (41%)]	Loss: 0.103081Train Epoch: 1 [290048/702208 (41%)]	Loss: 0.164970Train Epoch: 1 [291072/702208 (41%)]	Loss: 0.191153Train Epoch: 1 [292096/702208 (42%)]	Loss: 0.090850Train Epoch: 1 [293120/702208 (42%)]	Loss: 0.175407Train Epoch: 1 [294016/702208 (42%)]	Loss: 0.112997Train Epoch: 1 [295040/702208 (42%)]	Loss: 0.062731Train Epoch: 1 [296064/702208 (42%)]	Loss: 0.088257Train Epoch: 1 [297088/702208 (42%)]	Loss: 0.176285Train Epoch: 1 [298112/702208 (42%)]	Loss: 0.255998Train Epoch: 1 [299008/702208 (43%)]	Loss: 0.127784Train Epoch: 1 [300032/702208 (43%)]	Loss: 0.082575
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7985 / 8283] 96 %
Accuracy of the network on test loader class  1: [4439 / 4517] 98 %

Writing model: iterations-300032-total-97.06-class0-96.39999999999999-class1-98.27

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 90 %
Accuracy of the network on train loader class  0: [11399 / 12833] 88 %
Accuracy of the network on train loader class  1: [6770 / 7135] 94 %
Train Epoch: 1 [301056/702208 (43%)]	Loss: 0.090034Train Epoch: 1 [302080/702208 (43%)]	Loss: 0.135396Train Epoch: 1 [303104/702208 (43%)]	Loss: 0.139917Train Epoch: 1 [304000/702208 (43%)]	Loss: 0.108196Train Epoch: 1 [304128/702208 (43%)]	Loss: 0.115070Train Epoch: 1 [305024/702208 (43%)]	Loss: 0.152526Train Epoch: 1 [306048/702208 (44%)]	Loss: 0.117068Train Epoch: 1 [307072/702208 (44%)]	Loss: 0.104106Train Epoch: 1 [308096/702208 (44%)]	Loss: 0.222275Train Epoch: 1 [309120/702208 (44%)]	Loss: 0.083773Train Epoch: 1 [310016/702208 (44%)]	Loss: 0.133273Train Epoch: 1 [311040/702208 (44%)]	Loss: 0.166720Train Epoch: 1 [312064/702208 (44%)]	Loss: 0.177600Train Epoch: 1 [313088/702208 (45%)]	Loss: 0.156470Train Epoch: 1 [314112/702208 (45%)]	Loss: 0.151176Train Epoch: 1 [315008/702208 (45%)]	Loss: 0.126279Train Epoch: 1 [316032/702208 (45%)]	Loss: 0.155169Train Epoch: 1 [317056/702208 (45%)]	Loss: 0.139790Train Epoch: 1 [318080/702208 (45%)]	Loss: 0.088051Train Epoch: 1 [319104/702208 (45%)]	Loss: 0.148352Train Epoch: 1 [320000/702208 (46%)]	Loss: 0.124731Train Epoch: 1 [320128/702208 (46%)]	Loss: 0.203346Train Epoch: 1 [321024/702208 (46%)]	Loss: 0.092141Train Epoch: 1 [322048/702208 (46%)]	Loss: 0.140088Train Epoch: 1 [323072/702208 (46%)]	Loss: 0.153632Train Epoch: 1 [324096/702208 (46%)]	Loss: 0.104790Train Epoch: 1 [325120/702208 (46%)]	Loss: 0.380766
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7786 / 8283] 93 %
Accuracy of the network on test loader class  1: [4451 / 4517] 98 %

Writing model: iterations-325120-total-95.6-class0-94.0-class1-98.54
Train Epoch: 1 [326016/702208 (46%)]	Loss: 0.142021Train Epoch: 1 [327040/702208 (47%)]	Loss: 0.118989Train Epoch: 1 [328064/702208 (47%)]	Loss: 0.110241Train Epoch: 1 [329088/702208 (47%)]	Loss: 0.108607Train Epoch: 1 [330112/702208 (47%)]	Loss: 0.165027Train Epoch: 1 [331008/702208 (47%)]	Loss: 0.152719Train Epoch: 1 [332032/702208 (47%)]	Loss: 0.092520Train Epoch: 1 [333056/702208 (47%)]	Loss: 0.099985Train Epoch: 1 [334080/702208 (48%)]	Loss: 0.147776Train Epoch: 1 [335104/702208 (48%)]	Loss: 0.123897Train Epoch: 1 [336000/702208 (48%)]	Loss: 0.146215Train Epoch: 1 [336128/702208 (48%)]	Loss: 0.130097Train Epoch: 1 [337024/702208 (48%)]	Loss: 0.111799Train Epoch: 1 [338048/702208 (48%)]	Loss: 0.129833Train Epoch: 1 [339072/702208 (48%)]	Loss: 0.100105Train Epoch: 1 [340096/702208 (48%)]	Loss: 0.097480Train Epoch: 1 [341120/702208 (49%)]	Loss: 0.093613Train Epoch: 1 [342016/702208 (49%)]	Loss: 0.141510Train Epoch: 1 [343040/702208 (49%)]	Loss: 0.141511Train Epoch: 1 [344064/702208 (49%)]	Loss: 0.226594Train Epoch: 1 [345088/702208 (49%)]	Loss: 0.152560Train Epoch: 1 [346112/702208 (49%)]	Loss: 0.134920Train Epoch: 1 [347008/702208 (49%)]	Loss: 0.079522Train Epoch: 1 [348032/702208 (50%)]	Loss: 0.079031Train Epoch: 1 [349056/702208 (50%)]	Loss: 0.114855Train Epoch: 1 [350080/702208 (50%)]	Loss: 0.176088
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7864 / 8283] 94 %
Accuracy of the network on test loader class  1: [4461 / 4517] 98 %

Writing model: iterations-350080-total-96.28999999999999-class0-94.94-class1-98.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 93 %
Accuracy of the network on train loader class  0: [11771 / 12833] 91 %
Accuracy of the network on train loader class  1: [6867 / 7135] 96 %
Train Epoch: 1 [351104/702208 (50%)]	Loss: 0.122349Train Epoch: 1 [352000/702208 (50%)]	Loss: 0.094191Train Epoch: 1 [352128/702208 (50%)]	Loss: 0.120623Train Epoch: 1 [353024/702208 (50%)]	Loss: 0.122238Train Epoch: 1 [354048/702208 (50%)]	Loss: 0.126964Train Epoch: 1 [355072/702208 (51%)]	Loss: 0.184954Train Epoch: 1 [356096/702208 (51%)]	Loss: 0.191933Train Epoch: 1 [357120/702208 (51%)]	Loss: 0.168879Train Epoch: 1 [358016/702208 (51%)]	Loss: 0.128292Train Epoch: 1 [359040/702208 (51%)]	Loss: 0.141306Train Epoch: 1 [360064/702208 (51%)]	Loss: 0.093018Train Epoch: 1 [361088/702208 (51%)]	Loss: 0.223491Train Epoch: 1 [362112/702208 (52%)]	Loss: 0.120025Train Epoch: 1 [363008/702208 (52%)]	Loss: 0.132563Train Epoch: 1 [364032/702208 (52%)]	Loss: 0.174708Train Epoch: 1 [365056/702208 (52%)]	Loss: 0.116724Train Epoch: 1 [366080/702208 (52%)]	Loss: 0.128345Train Epoch: 1 [367104/702208 (52%)]	Loss: 0.319557Train Epoch: 1 [368000/702208 (52%)]	Loss: 0.101379Train Epoch: 1 [368128/702208 (52%)]	Loss: 0.182243Train Epoch: 1 [369024/702208 (53%)]	Loss: 0.159563Train Epoch: 1 [370048/702208 (53%)]	Loss: 0.210713Train Epoch: 1 [371072/702208 (53%)]	Loss: 0.149100Train Epoch: 1 [372096/702208 (53%)]	Loss: 0.162449Train Epoch: 1 [373120/702208 (53%)]	Loss: 0.085717Train Epoch: 1 [374016/702208 (53%)]	Loss: 0.125217Train Epoch: 1 [375040/702208 (53%)]	Loss: 0.129436
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8033 / 8283] 96 %
Accuracy of the network on test loader class  1: [4412 / 4517] 97 %

Writing model: iterations-375040-total-97.23-class0-96.98-class1-97.68
Train Epoch: 1 [376064/702208 (54%)]	Loss: 0.126776Train Epoch: 1 [377088/702208 (54%)]	Loss: 0.071561Train Epoch: 1 [378112/702208 (54%)]	Loss: 0.123349Train Epoch: 1 [379008/702208 (54%)]	Loss: 0.081420Train Epoch: 1 [380032/702208 (54%)]	Loss: 0.125680Train Epoch: 1 [381056/702208 (54%)]	Loss: 0.106102Train Epoch: 1 [382080/702208 (54%)]	Loss: 0.112740Train Epoch: 1 [383104/702208 (55%)]	Loss: 0.088395Train Epoch: 1 [384000/702208 (55%)]	Loss: 0.143970Train Epoch: 1 [384128/702208 (55%)]	Loss: 0.143780Train Epoch: 1 [385024/702208 (55%)]	Loss: 0.120870Train Epoch: 1 [386048/702208 (55%)]	Loss: 0.157880Train Epoch: 1 [387072/702208 (55%)]	Loss: 0.152977Train Epoch: 1 [388096/702208 (55%)]	Loss: 0.095505Train Epoch: 1 [389120/702208 (55%)]	Loss: 0.108285Train Epoch: 1 [390016/702208 (56%)]	Loss: 0.133302Train Epoch: 1 [391040/702208 (56%)]	Loss: 0.121689Train Epoch: 1 [392064/702208 (56%)]	Loss: 0.089731Train Epoch: 1 [393088/702208 (56%)]	Loss: 0.102793Train Epoch: 1 [394112/702208 (56%)]	Loss: 0.124573Train Epoch: 1 [395008/702208 (56%)]	Loss: 0.133301Train Epoch: 1 [396032/702208 (56%)]	Loss: 0.065214Train Epoch: 1 [397056/702208 (57%)]	Loss: 0.134527Train Epoch: 1 [398080/702208 (57%)]	Loss: 0.083770Train Epoch: 1 [399104/702208 (57%)]	Loss: 0.194286Train Epoch: 1 [400000/702208 (57%)]	Loss: 0.146123
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 93 %
Accuracy of the network on test loader class  0: [7409 / 8283] 89 %
Accuracy of the network on test loader class  1: [4497 / 4517] 99 %

Writing model: iterations-400000-total-93.02-class0-89.45-class1-99.56

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 86 %
Accuracy of the network on train loader class  0: [10391 / 12833] 80 %
Accuracy of the network on train loader class  1: [6929 / 7135] 97 %
Train Epoch: 1 [400128/702208 (57%)]	Loss: 0.080450
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 93 %
Accuracy of the network on test loader class  0: [7509 / 8283] 90 %
Accuracy of the network on test loader class  1: [4491 / 4517] 99 %

Writing model: iterations-400128-total-93.75-class0-90.66-class1-99.42

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 87 %
Accuracy of the network on train loader class  0: [10606 / 12833] 82 %
Accuracy of the network on train loader class  1: [6895 / 7135] 96 %
Train Epoch: 1 [401024/702208 (57%)]	Loss: 0.093176Train Epoch: 1 [402048/702208 (57%)]	Loss: 0.087955Train Epoch: 1 [403072/702208 (57%)]	Loss: 0.130231Train Epoch: 1 [404096/702208 (58%)]	Loss: 0.102244Train Epoch: 1 [405120/702208 (58%)]	Loss: 0.098973Train Epoch: 1 [406016/702208 (58%)]	Loss: 0.109641Train Epoch: 1 [407040/702208 (58%)]	Loss: 0.171740Train Epoch: 1 [408064/702208 (58%)]	Loss: 0.095144Train Epoch: 1 [409088/702208 (58%)]	Loss: 0.116211Train Epoch: 1 [410112/702208 (58%)]	Loss: 0.135818Train Epoch: 1 [411008/702208 (59%)]	Loss: 0.120054Train Epoch: 1 [412032/702208 (59%)]	Loss: 0.103603Train Epoch: 1 [413056/702208 (59%)]	Loss: 0.126978Train Epoch: 1 [414080/702208 (59%)]	Loss: 0.123477Train Epoch: 1 [415104/702208 (59%)]	Loss: 0.157736Train Epoch: 1 [416000/702208 (59%)]	Loss: 0.152762Train Epoch: 1 [416128/702208 (59%)]	Loss: 0.077058Train Epoch: 1 [417024/702208 (59%)]	Loss: 0.107351Train Epoch: 1 [418048/702208 (60%)]	Loss: 0.094379Train Epoch: 1 [419072/702208 (60%)]	Loss: 0.101386Train Epoch: 1 [420096/702208 (60%)]	Loss: 0.156096Train Epoch: 1 [421120/702208 (60%)]	Loss: 0.143744Train Epoch: 1 [422016/702208 (60%)]	Loss: 0.158241Train Epoch: 1 [423040/702208 (60%)]	Loss: 0.083533Train Epoch: 1 [424064/702208 (60%)]	Loss: 0.104185Train Epoch: 1 [425088/702208 (61%)]	Loss: 0.121317
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8027 / 8283] 96 %
Accuracy of the network on test loader class  1: [4436 / 4517] 98 %

Writing model: iterations-425088-total-97.37-class0-96.91-class1-98.21
Train Epoch: 1 [426112/702208 (61%)]	Loss: 0.116252Train Epoch: 1 [427008/702208 (61%)]	Loss: 0.097615Train Epoch: 1 [428032/702208 (61%)]	Loss: 0.103429Train Epoch: 1 [429056/702208 (61%)]	Loss: 0.125894Train Epoch: 1 [430080/702208 (61%)]	Loss: 0.100780Train Epoch: 1 [431104/702208 (61%)]	Loss: 0.061831Train Epoch: 1 [432000/702208 (62%)]	Loss: 0.081146Train Epoch: 1 [432128/702208 (62%)]	Loss: 0.129080Train Epoch: 1 [433024/702208 (62%)]	Loss: 0.093617Train Epoch: 1 [434048/702208 (62%)]	Loss: 0.120217Train Epoch: 1 [435072/702208 (62%)]	Loss: 0.082418Train Epoch: 1 [436096/702208 (62%)]	Loss: 0.108923Train Epoch: 1 [437120/702208 (62%)]	Loss: 0.118371Train Epoch: 1 [438016/702208 (62%)]	Loss: 0.147246Train Epoch: 1 [439040/702208 (63%)]	Loss: 0.095747Train Epoch: 1 [440064/702208 (63%)]	Loss: 0.116208Train Epoch: 1 [441088/702208 (63%)]	Loss: 0.154050Train Epoch: 1 [442112/702208 (63%)]	Loss: 0.127649Train Epoch: 1 [443008/702208 (63%)]	Loss: 0.112548Train Epoch: 1 [444032/702208 (63%)]	Loss: 0.058129Train Epoch: 1 [445056/702208 (63%)]	Loss: 0.143613Train Epoch: 1 [446080/702208 (64%)]	Loss: 0.125199Train Epoch: 1 [447104/702208 (64%)]	Loss: 0.063430Train Epoch: 1 [448000/702208 (64%)]	Loss: 0.081041Train Epoch: 1 [448128/702208 (64%)]	Loss: 0.077134Train Epoch: 1 [449024/702208 (64%)]	Loss: 0.107381Train Epoch: 1 [450048/702208 (64%)]	Loss: 0.145101
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7728 / 8283] 93 %
Accuracy of the network on test loader class  1: [4493 / 4517] 99 %

Writing model: iterations-450048-total-95.48-class0-93.30000000000001-class1-99.47

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 91 %
Accuracy of the network on train loader class  0: [11430 / 12833] 89 %
Accuracy of the network on train loader class  1: [6911 / 7135] 96 %
Train Epoch: 1 [451072/702208 (64%)]	Loss: 0.151255Train Epoch: 1 [452096/702208 (64%)]	Loss: 0.233266Train Epoch: 1 [453120/702208 (65%)]	Loss: 0.126259Train Epoch: 1 [454016/702208 (65%)]	Loss: 0.136590Train Epoch: 1 [455040/702208 (65%)]	Loss: 0.199948Train Epoch: 1 [456064/702208 (65%)]	Loss: 0.201328Train Epoch: 1 [457088/702208 (65%)]	Loss: 0.086347Train Epoch: 1 [458112/702208 (65%)]	Loss: 0.140004Train Epoch: 1 [459008/702208 (65%)]	Loss: 0.110638Train Epoch: 1 [460032/702208 (66%)]	Loss: 0.125348Train Epoch: 1 [461056/702208 (66%)]	Loss: 0.168140Train Epoch: 1 [462080/702208 (66%)]	Loss: 0.135498Train Epoch: 1 [463104/702208 (66%)]	Loss: 0.164450Train Epoch: 1 [464000/702208 (66%)]	Loss: 0.126696Train Epoch: 1 [464128/702208 (66%)]	Loss: 0.138677Train Epoch: 1 [465024/702208 (66%)]	Loss: 0.158698Train Epoch: 1 [466048/702208 (66%)]	Loss: 0.149067Train Epoch: 1 [467072/702208 (67%)]	Loss: 0.135250Train Epoch: 1 [468096/702208 (67%)]	Loss: 0.158720Train Epoch: 1 [469120/702208 (67%)]	Loss: 0.126233Train Epoch: 1 [470016/702208 (67%)]	Loss: 0.166546Train Epoch: 1 [471040/702208 (67%)]	Loss: 0.143967Train Epoch: 1 [472064/702208 (67%)]	Loss: 0.158583Train Epoch: 1 [473088/702208 (67%)]	Loss: 0.091892Train Epoch: 1 [474112/702208 (68%)]	Loss: 0.237905Train Epoch: 1 [475008/702208 (68%)]	Loss: 0.069673
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7984 / 8283] 96 %
Accuracy of the network on test loader class  1: [4449 / 4517] 98 %

Writing model: iterations-475008-total-97.13000000000001-class0-96.39-class1-98.49
Train Epoch: 1 [476032/702208 (68%)]	Loss: 0.095732Train Epoch: 1 [477056/702208 (68%)]	Loss: 0.073206Train Epoch: 1 [478080/702208 (68%)]	Loss: 0.073445Train Epoch: 1 [479104/702208 (68%)]	Loss: 0.093466Train Epoch: 1 [480000/702208 (68%)]	Loss: 0.073155Train Epoch: 1 [480128/702208 (68%)]	Loss: 0.076383Train Epoch: 1 [481024/702208 (69%)]	Loss: 0.088694Train Epoch: 1 [482048/702208 (69%)]	Loss: 0.142682Train Epoch: 1 [483072/702208 (69%)]	Loss: 0.168010Train Epoch: 1 [484096/702208 (69%)]	Loss: 0.138236Train Epoch: 1 [485120/702208 (69%)]	Loss: 0.132276Train Epoch: 1 [486016/702208 (69%)]	Loss: 0.061062Train Epoch: 1 [487040/702208 (69%)]	Loss: 0.098451Train Epoch: 1 [488064/702208 (70%)]	Loss: 0.077872Train Epoch: 1 [489088/702208 (70%)]	Loss: 0.225462Train Epoch: 1 [490112/702208 (70%)]	Loss: 0.122525Train Epoch: 1 [491008/702208 (70%)]	Loss: 0.139380Train Epoch: 1 [492032/702208 (70%)]	Loss: 0.191940Train Epoch: 1 [493056/702208 (70%)]	Loss: 0.078553Train Epoch: 1 [494080/702208 (70%)]	Loss: 0.122226Train Epoch: 1 [495104/702208 (71%)]	Loss: 0.125221Train Epoch: 1 [496000/702208 (71%)]	Loss: 0.074078Train Epoch: 1 [496128/702208 (71%)]	Loss: 0.072802Train Epoch: 1 [497024/702208 (71%)]	Loss: 0.074163Train Epoch: 1 [498048/702208 (71%)]	Loss: 0.080663Train Epoch: 1 [499072/702208 (71%)]	Loss: 0.100288Train Epoch: 1 [500096/702208 (71%)]	Loss: 0.132375
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7775 / 8283] 93 %
Accuracy of the network on test loader class  1: [4457 / 4517] 98 %

Writing model: iterations-500096-total-95.56-class0-93.87-class1-98.67

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 92 %
Accuracy of the network on train loader class  0: [11581 / 12833] 90 %
Accuracy of the network on train loader class  1: [6806 / 7135] 95 %
Train Epoch: 1 [501120/702208 (71%)]	Loss: 0.116026Train Epoch: 1 [502016/702208 (71%)]	Loss: 0.109808Train Epoch: 1 [503040/702208 (72%)]	Loss: 0.085458Train Epoch: 1 [504064/702208 (72%)]	Loss: 0.108567Train Epoch: 1 [505088/702208 (72%)]	Loss: 0.152534Train Epoch: 1 [506112/702208 (72%)]	Loss: 0.142821Train Epoch: 1 [507008/702208 (72%)]	Loss: 0.091745Train Epoch: 1 [508032/702208 (72%)]	Loss: 0.114264Train Epoch: 1 [509056/702208 (72%)]	Loss: 0.211158Train Epoch: 1 [510080/702208 (73%)]	Loss: 0.186152Train Epoch: 1 [511104/702208 (73%)]	Loss: 0.062482Train Epoch: 1 [512000/702208 (73%)]	Loss: 0.075035Train Epoch: 1 [512128/702208 (73%)]	Loss: 0.247064Train Epoch: 1 [513024/702208 (73%)]	Loss: 0.079265Train Epoch: 1 [514048/702208 (73%)]	Loss: 0.113625Train Epoch: 1 [515072/702208 (73%)]	Loss: 0.076682Train Epoch: 1 [516096/702208 (73%)]	Loss: 0.086660Train Epoch: 1 [517120/702208 (74%)]	Loss: 0.107101Train Epoch: 1 [518016/702208 (74%)]	Loss: 0.077533Train Epoch: 1 [519040/702208 (74%)]	Loss: 0.084622Train Epoch: 1 [520064/702208 (74%)]	Loss: 0.156818Train Epoch: 1 [521088/702208 (74%)]	Loss: 0.111253Train Epoch: 1 [522112/702208 (74%)]	Loss: 0.129558Train Epoch: 1 [523008/702208 (74%)]	Loss: 0.073855Train Epoch: 1 [524032/702208 (75%)]	Loss: 0.160224Train Epoch: 1 [525056/702208 (75%)]	Loss: 0.092257
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7835 / 8283] 94 %
Accuracy of the network on test loader class  1: [4481 / 4517] 99 %

Writing model: iterations-525056-total-96.22-class0-94.59-class1-99.2
Train Epoch: 1 [526080/702208 (75%)]	Loss: 0.098373Train Epoch: 1 [527104/702208 (75%)]	Loss: 0.123912Train Epoch: 1 [528000/702208 (75%)]	Loss: 0.109712Train Epoch: 1 [528128/702208 (75%)]	Loss: 0.133759Train Epoch: 1 [529024/702208 (75%)]	Loss: 0.142618Train Epoch: 1 [530048/702208 (75%)]	Loss: 0.100311Train Epoch: 1 [531072/702208 (76%)]	Loss: 0.145616Train Epoch: 1 [532096/702208 (76%)]	Loss: 0.116354Train Epoch: 1 [533120/702208 (76%)]	Loss: 0.129395Train Epoch: 1 [534016/702208 (76%)]	Loss: 0.154198Train Epoch: 1 [535040/702208 (76%)]	Loss: 0.105491Train Epoch: 1 [536064/702208 (76%)]	Loss: 0.129835Train Epoch: 1 [537088/702208 (76%)]	Loss: 0.134641Train Epoch: 1 [538112/702208 (77%)]	Loss: 0.109287Train Epoch: 1 [539008/702208 (77%)]	Loss: 0.110582Train Epoch: 1 [540032/702208 (77%)]	Loss: 0.094011Train Epoch: 1 [541056/702208 (77%)]	Loss: 0.176446Train Epoch: 1 [542080/702208 (77%)]	Loss: 0.080668Train Epoch: 1 [543104/702208 (77%)]	Loss: 0.064421Train Epoch: 1 [544000/702208 (77%)]	Loss: 0.156181Train Epoch: 1 [544128/702208 (77%)]	Loss: 0.126208Train Epoch: 1 [545024/702208 (78%)]	Loss: 0.112028Train Epoch: 1 [546048/702208 (78%)]	Loss: 0.097006Train Epoch: 1 [547072/702208 (78%)]	Loss: 0.150398Train Epoch: 1 [548096/702208 (78%)]	Loss: 0.120045Train Epoch: 1 [549120/702208 (78%)]	Loss: 0.104614Train Epoch: 1 [550016/702208 (78%)]	Loss: 0.078908
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 94 %
Accuracy of the network on test loader class  0: [7573 / 8283] 91 %
Accuracy of the network on test loader class  1: [4493 / 4517] 99 %

Writing model: iterations-550016-total-94.27-class0-91.43-class1-99.47

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 93 %
Accuracy of the network on train loader class  0: [11935 / 12833] 93 %
Accuracy of the network on train loader class  1: [6796 / 7135] 95 %
Train Epoch: 1 [551040/702208 (78%)]	Loss: 0.120592Train Epoch: 1 [552064/702208 (79%)]	Loss: 0.142420Train Epoch: 1 [553088/702208 (79%)]	Loss: 0.099148Train Epoch: 1 [554112/702208 (79%)]	Loss: 0.234678Train Epoch: 1 [555008/702208 (79%)]	Loss: 0.140223Train Epoch: 1 [556032/702208 (79%)]	Loss: 0.076982Train Epoch: 1 [557056/702208 (79%)]	Loss: 0.099635Train Epoch: 1 [558080/702208 (79%)]	Loss: 0.054693Train Epoch: 1 [559104/702208 (80%)]	Loss: 0.144143Train Epoch: 1 [560000/702208 (80%)]	Loss: 0.085367Train Epoch: 1 [560128/702208 (80%)]	Loss: 0.138606Train Epoch: 1 [561024/702208 (80%)]	Loss: 0.276357Train Epoch: 1 [562048/702208 (80%)]	Loss: 0.089020Train Epoch: 1 [563072/702208 (80%)]	Loss: 0.100318Train Epoch: 1 [564096/702208 (80%)]	Loss: 0.116647Train Epoch: 1 [565120/702208 (80%)]	Loss: 0.185818Train Epoch: 1 [566016/702208 (81%)]	Loss: 0.083613Train Epoch: 1 [567040/702208 (81%)]	Loss: 0.091504Train Epoch: 1 [568064/702208 (81%)]	Loss: 0.156739Train Epoch: 1 [569088/702208 (81%)]	Loss: 0.138514Train Epoch: 1 [570112/702208 (81%)]	Loss: 0.094246Train Epoch: 1 [571008/702208 (81%)]	Loss: 0.119115Train Epoch: 1 [572032/702208 (81%)]	Loss: 0.125863Train Epoch: 1 [573056/702208 (82%)]	Loss: 0.246928Train Epoch: 1 [574080/702208 (82%)]	Loss: 0.180222Train Epoch: 1 [575104/702208 (82%)]	Loss: 0.056065
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7898 / 8283] 95 %
Accuracy of the network on test loader class  1: [4479 / 4517] 99 %

Writing model: iterations-575104-total-96.7-class0-95.35-class1-99.16
Train Epoch: 1 [576000/702208 (82%)]	Loss: 0.053842Train Epoch: 1 [576128/702208 (82%)]	Loss: 0.177100Train Epoch: 1 [577024/702208 (82%)]	Loss: 0.130116Train Epoch: 1 [578048/702208 (82%)]	Loss: 0.075979Train Epoch: 1 [579072/702208 (82%)]	Loss: 0.128507Train Epoch: 1 [580096/702208 (83%)]	Loss: 0.100476Train Epoch: 1 [581120/702208 (83%)]	Loss: 0.072524Train Epoch: 1 [582016/702208 (83%)]	Loss: 0.223529Train Epoch: 1 [583040/702208 (83%)]	Loss: 0.206013Train Epoch: 1 [584064/702208 (83%)]	Loss: 0.200876Train Epoch: 1 [585088/702208 (83%)]	Loss: 0.043326Train Epoch: 1 [586112/702208 (83%)]	Loss: 0.135053Train Epoch: 1 [587008/702208 (84%)]	Loss: 0.120253Train Epoch: 1 [588032/702208 (84%)]	Loss: 0.114688Train Epoch: 1 [589056/702208 (84%)]	Loss: 0.112718Train Epoch: 1 [590080/702208 (84%)]	Loss: 0.107027Train Epoch: 1 [591104/702208 (84%)]	Loss: 0.099354Train Epoch: 1 [592000/702208 (84%)]	Loss: 0.150246Train Epoch: 1 [592128/702208 (84%)]	Loss: 0.090125Train Epoch: 1 [593024/702208 (84%)]	Loss: 0.112378Train Epoch: 1 [594048/702208 (85%)]	Loss: 0.087471Train Epoch: 1 [595072/702208 (85%)]	Loss: 0.183633Train Epoch: 1 [596096/702208 (85%)]	Loss: 0.114236Train Epoch: 1 [597120/702208 (85%)]	Loss: 0.152833Train Epoch: 1 [598016/702208 (85%)]	Loss: 0.104775Train Epoch: 1 [599040/702208 (85%)]	Loss: 0.121443Train Epoch: 1 [600064/702208 (85%)]	Loss: 0.122443
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7837 / 8283] 94 %
Accuracy of the network on test loader class  1: [4469 / 4517] 98 %

Writing model: iterations-600064-total-96.14-class0-94.62-class1-98.94

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 91 %
Accuracy of the network on train loader class  0: [11615 / 12833] 90 %
Accuracy of the network on train loader class  1: [6659 / 7135] 93 %
Train Epoch: 1 [601088/702208 (86%)]	Loss: 0.115788Train Epoch: 1 [602112/702208 (86%)]	Loss: 0.209066Train Epoch: 1 [603008/702208 (86%)]	Loss: 0.088169Train Epoch: 1 [604032/702208 (86%)]	Loss: 0.130325Train Epoch: 1 [605056/702208 (86%)]	Loss: 0.100336Train Epoch: 1 [606080/702208 (86%)]	Loss: 0.077322Train Epoch: 1 [607104/702208 (86%)]	Loss: 0.120018Train Epoch: 1 [608000/702208 (87%)]	Loss: 0.097558Train Epoch: 1 [608128/702208 (87%)]	Loss: 0.108099Train Epoch: 1 [609024/702208 (87%)]	Loss: 0.187436Train Epoch: 1 [610048/702208 (87%)]	Loss: 0.083985Train Epoch: 1 [611072/702208 (87%)]	Loss: 0.079287Train Epoch: 1 [612096/702208 (87%)]	Loss: 0.049894Train Epoch: 1 [613120/702208 (87%)]	Loss: 0.081129Train Epoch: 1 [614016/702208 (87%)]	Loss: 0.071758Train Epoch: 1 [615040/702208 (88%)]	Loss: 0.091321Train Epoch: 1 [616064/702208 (88%)]	Loss: 0.115613Train Epoch: 1 [617088/702208 (88%)]	Loss: 0.079104Train Epoch: 1 [618112/702208 (88%)]	Loss: 0.173454Train Epoch: 1 [619008/702208 (88%)]	Loss: 0.107141Train Epoch: 1 [620032/702208 (88%)]	Loss: 0.074886Train Epoch: 1 [621056/702208 (88%)]	Loss: 0.063199Train Epoch: 1 [622080/702208 (89%)]	Loss: 0.086297Train Epoch: 1 [623104/702208 (89%)]	Loss: 0.120401Train Epoch: 1 [624000/702208 (89%)]	Loss: 0.052343Train Epoch: 1 [624128/702208 (89%)]	Loss: 0.172352Train Epoch: 1 [625024/702208 (89%)]	Loss: 0.078397
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8036 / 8283] 97 %
Accuracy of the network on test loader class  1: [4438 / 4517] 98 %

Writing model: iterations-625024-total-97.45-class0-97.02-class1-98.25
Train Epoch: 1 [626048/702208 (89%)]	Loss: 0.090217Train Epoch: 1 [627072/702208 (89%)]	Loss: 0.115300Train Epoch: 1 [628096/702208 (89%)]	Loss: 0.097882Train Epoch: 1 [629120/702208 (90%)]	Loss: 0.088296Train Epoch: 1 [630016/702208 (90%)]	Loss: 0.112028Train Epoch: 1 [631040/702208 (90%)]	Loss: 0.078958Train Epoch: 1 [632064/702208 (90%)]	Loss: 0.142201Train Epoch: 1 [633088/702208 (90%)]	Loss: 0.066677Train Epoch: 1 [634112/702208 (90%)]	Loss: 0.119996Train Epoch: 1 [635008/702208 (90%)]	Loss: 0.097357Train Epoch: 1 [636032/702208 (91%)]	Loss: 0.060977Train Epoch: 1 [637056/702208 (91%)]	Loss: 0.102314Train Epoch: 1 [638080/702208 (91%)]	Loss: 0.116504Train Epoch: 1 [639104/702208 (91%)]	Loss: 0.097097Train Epoch: 1 [640000/702208 (91%)]	Loss: 0.140460Train Epoch: 1 [640128/702208 (91%)]	Loss: 0.118621Train Epoch: 1 [641024/702208 (91%)]	Loss: 0.062619Train Epoch: 1 [642048/702208 (91%)]	Loss: 0.049192Train Epoch: 1 [643072/702208 (92%)]	Loss: 0.052126Train Epoch: 1 [644096/702208 (92%)]	Loss: 0.101112Train Epoch: 1 [645120/702208 (92%)]	Loss: 0.086243Train Epoch: 1 [646016/702208 (92%)]	Loss: 0.041642Train Epoch: 1 [647040/702208 (92%)]	Loss: 0.099022Train Epoch: 1 [648064/702208 (92%)]	Loss: 0.091701Train Epoch: 1 [649088/702208 (92%)]	Loss: 0.125521Train Epoch: 1 [650112/702208 (93%)]	Loss: 0.103202
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8078 / 8283] 97 %
Accuracy of the network on test loader class  1: [4462 / 4517] 98 %

Writing model: iterations-650112-total-97.97-class0-97.53-class1-98.78

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12171 / 12833] 94 %
Accuracy of the network on train loader class  1: [6904 / 7135] 96 %
Train Epoch: 1 [651008/702208 (93%)]	Loss: 0.087831Train Epoch: 1 [652032/702208 (93%)]	Loss: 0.112028Train Epoch: 1 [653056/702208 (93%)]	Loss: 0.116675Train Epoch: 1 [654080/702208 (93%)]	Loss: 0.077388Train Epoch: 1 [655104/702208 (93%)]	Loss: 0.175899Train Epoch: 1 [656000/702208 (93%)]	Loss: 0.114975Train Epoch: 1 [656128/702208 (93%)]	Loss: 0.195559Train Epoch: 1 [657024/702208 (94%)]	Loss: 0.080047Train Epoch: 1 [658048/702208 (94%)]	Loss: 0.187458Train Epoch: 1 [659072/702208 (94%)]	Loss: 0.133213Train Epoch: 1 [660096/702208 (94%)]	Loss: 0.189466Train Epoch: 1 [661120/702208 (94%)]	Loss: 0.103832Train Epoch: 1 [662016/702208 (94%)]	Loss: 0.116016Train Epoch: 1 [663040/702208 (94%)]	Loss: 0.105016Train Epoch: 1 [664064/702208 (95%)]	Loss: 0.171733Train Epoch: 1 [665088/702208 (95%)]	Loss: 0.115745Train Epoch: 1 [666112/702208 (95%)]	Loss: 0.111673Train Epoch: 1 [667008/702208 (95%)]	Loss: 0.084868Train Epoch: 1 [668032/702208 (95%)]	Loss: 0.128532Train Epoch: 1 [669056/702208 (95%)]	Loss: 0.108733Train Epoch: 1 [670080/702208 (95%)]	Loss: 0.127736Train Epoch: 1 [671104/702208 (96%)]	Loss: 0.073742Train Epoch: 1 [672000/702208 (96%)]	Loss: 0.190953Train Epoch: 1 [672128/702208 (96%)]	Loss: 0.145459Train Epoch: 1 [673024/702208 (96%)]	Loss: 0.084448Train Epoch: 1 [674048/702208 (96%)]	Loss: 0.071440Train Epoch: 1 [675072/702208 (96%)]	Loss: 0.023696
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8012 / 8283] 96 %
Accuracy of the network on test loader class  1: [4473 / 4517] 99 %

Writing model: iterations-675072-total-97.54-class0-96.73-class1-99.03
Train Epoch: 1 [676096/702208 (96%)]	Loss: 0.139518Train Epoch: 1 [677120/702208 (96%)]	Loss: 0.096718Train Epoch: 1 [678016/702208 (97%)]	Loss: 0.081231Train Epoch: 1 [679040/702208 (97%)]	Loss: 0.218493Train Epoch: 1 [680064/702208 (97%)]	Loss: 0.097608Train Epoch: 1 [681088/702208 (97%)]	Loss: 0.161780Train Epoch: 1 [682112/702208 (97%)]	Loss: 0.058041Train Epoch: 1 [683008/702208 (97%)]	Loss: 0.135690Train Epoch: 1 [684032/702208 (97%)]	Loss: 0.098735Train Epoch: 1 [685056/702208 (98%)]	Loss: 0.154636Train Epoch: 1 [686080/702208 (98%)]	Loss: 0.089560Train Epoch: 1 [687104/702208 (98%)]	Loss: 0.076344Train Epoch: 1 [688000/702208 (98%)]	Loss: 0.180070Train Epoch: 1 [688128/702208 (98%)]	Loss: 0.154944Train Epoch: 1 [689024/702208 (98%)]	Loss: 0.134516Train Epoch: 1 [690048/702208 (98%)]	Loss: 0.066121Train Epoch: 1 [691072/702208 (98%)]	Loss: 0.048197Train Epoch: 1 [692096/702208 (99%)]	Loss: 0.091539Train Epoch: 1 [693120/702208 (99%)]	Loss: 0.107307Train Epoch: 1 [694016/702208 (99%)]	Loss: 0.112489Train Epoch: 1 [695040/702208 (99%)]	Loss: 0.205855Train Epoch: 1 [696064/702208 (99%)]	Loss: 0.066807Train Epoch: 1 [697088/702208 (99%)]	Loss: 0.075468Train Epoch: 1 [698112/702208 (99%)]	Loss: 0.095750Train Epoch: 1 [699008/702208 (100%)]	Loss: 0.208681Train Epoch: 1 [700032/702208 (100%)]	Loss: 0.074442
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7873 / 8283] 95 %
Accuracy of the network on test loader class  1: [4477 / 4517] 99 %

Writing model: iterations-700032-total-96.48-class0-95.05-class1-99.11

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11786 / 12833] 91 %
Accuracy of the network on train loader class  1: [7012 / 7135] 98 %
Train Epoch: 1 [701056/702208 (100%)]	Loss: 0.141795Train Epoch: 1 [702080/702208 (100%)]	Loss: 0.099974
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7824 / 8283] 94 %
Accuracy of the network on test loader class  1: [4493 / 4517] 99 %
Train Epoch: 2 [1024/702208 (0%)]	Loss: 0.108174Train Epoch: 2 [2048/702208 (0%)]	Loss: 0.087725Train Epoch: 2 [3072/702208 (0%)]	Loss: 0.073849Train Epoch: 2 [4096/702208 (1%)]	Loss: 0.079286Train Epoch: 2 [5120/702208 (1%)]	Loss: 0.120972Train Epoch: 2 [6016/702208 (1%)]	Loss: 0.188793Train Epoch: 2 [7040/702208 (1%)]	Loss: 0.133652Train Epoch: 2 [8064/702208 (1%)]	Loss: 0.116116Train Epoch: 2 [9088/702208 (1%)]	Loss: 0.067049Train Epoch: 2 [10112/702208 (1%)]	Loss: 0.140516Train Epoch: 2 [11008/702208 (2%)]	Loss: 0.123123Train Epoch: 2 [12032/702208 (2%)]	Loss: 0.140520Train Epoch: 2 [13056/702208 (2%)]	Loss: 0.087196Train Epoch: 2 [14080/702208 (2%)]	Loss: 0.126344Train Epoch: 2 [15104/702208 (2%)]	Loss: 0.069986Train Epoch: 2 [16000/702208 (2%)]	Loss: 0.104064Train Epoch: 2 [16128/702208 (2%)]	Loss: 0.068551Train Epoch: 2 [17024/702208 (2%)]	Loss: 0.106357Train Epoch: 2 [18048/702208 (3%)]	Loss: 0.129574Train Epoch: 2 [19072/702208 (3%)]	Loss: 0.101346Train Epoch: 2 [20096/702208 (3%)]	Loss: 0.087176Train Epoch: 2 [21120/702208 (3%)]	Loss: 0.033882Train Epoch: 2 [22016/702208 (3%)]	Loss: 0.119986Train Epoch: 2 [23040/702208 (3%)]	Loss: 0.103380Train Epoch: 2 [24064/702208 (3%)]	Loss: 0.123888Train Epoch: 2 [25088/702208 (4%)]	Loss: 0.076752
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7905 / 8283] 95 %
Accuracy of the network on test loader class  1: [4484 / 4517] 99 %

Writing model: iterations-727296-total-96.78999999999999-class0-95.44-class1-99.27
Train Epoch: 2 [26112/702208 (4%)]	Loss: 0.073882Train Epoch: 2 [27008/702208 (4%)]	Loss: 0.075446Train Epoch: 2 [28032/702208 (4%)]	Loss: 0.074862Train Epoch: 2 [29056/702208 (4%)]	Loss: 0.130670Train Epoch: 2 [30080/702208 (4%)]	Loss: 0.077213Train Epoch: 2 [31104/702208 (4%)]	Loss: 0.156492Train Epoch: 2 [32000/702208 (5%)]	Loss: 0.077861Train Epoch: 2 [32128/702208 (5%)]	Loss: 0.090670Train Epoch: 2 [33024/702208 (5%)]	Loss: 0.069244Train Epoch: 2 [34048/702208 (5%)]	Loss: 0.096330Train Epoch: 2 [35072/702208 (5%)]	Loss: 0.062604Train Epoch: 2 [36096/702208 (5%)]	Loss: 0.138770Train Epoch: 2 [37120/702208 (5%)]	Loss: 0.193798Train Epoch: 2 [38016/702208 (5%)]	Loss: 0.085377Train Epoch: 2 [39040/702208 (6%)]	Loss: 0.138282Train Epoch: 2 [40064/702208 (6%)]	Loss: 0.112612Train Epoch: 2 [41088/702208 (6%)]	Loss: 0.116294Train Epoch: 2 [42112/702208 (6%)]	Loss: 0.116551Train Epoch: 2 [43008/702208 (6%)]	Loss: 0.068240Train Epoch: 2 [44032/702208 (6%)]	Loss: 0.106969Train Epoch: 2 [45056/702208 (6%)]	Loss: 0.147254Train Epoch: 2 [46080/702208 (7%)]	Loss: 0.041564Train Epoch: 2 [47104/702208 (7%)]	Loss: 0.104966Train Epoch: 2 [48000/702208 (7%)]	Loss: 0.096651Train Epoch: 2 [48128/702208 (7%)]	Loss: 0.094333Train Epoch: 2 [49024/702208 (7%)]	Loss: 0.131582Train Epoch: 2 [50048/702208 (7%)]	Loss: 0.096067
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7847 / 8283] 94 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-752256-total-96.46000000000001-class0-94.74000000000001-class1-99.62

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 91 %
Accuracy of the network on train loader class  0: [11183 / 12833] 87 %
Accuracy of the network on train loader class  1: [7028 / 7135] 98 %
Train Epoch: 2 [51072/702208 (7%)]	Loss: 0.110362Train Epoch: 2 [52096/702208 (7%)]	Loss: 0.101839Train Epoch: 2 [53120/702208 (8%)]	Loss: 0.086170Train Epoch: 2 [54016/702208 (8%)]	Loss: 0.085824Train Epoch: 2 [55040/702208 (8%)]	Loss: 0.116165Train Epoch: 2 [56064/702208 (8%)]	Loss: 0.091484Train Epoch: 2 [57088/702208 (8%)]	Loss: 0.102335Train Epoch: 2 [58112/702208 (8%)]	Loss: 0.055136Train Epoch: 2 [59008/702208 (8%)]	Loss: 0.098487Train Epoch: 2 [60032/702208 (9%)]	Loss: 0.117191Train Epoch: 2 [61056/702208 (9%)]	Loss: 0.140751Train Epoch: 2 [62080/702208 (9%)]	Loss: 0.114389Train Epoch: 2 [63104/702208 (9%)]	Loss: 0.047509Train Epoch: 2 [64000/702208 (9%)]	Loss: 0.121730Train Epoch: 2 [64128/702208 (9%)]	Loss: 0.091505Train Epoch: 2 [65024/702208 (9%)]	Loss: 0.081706Train Epoch: 2 [66048/702208 (9%)]	Loss: 0.114354Train Epoch: 2 [67072/702208 (10%)]	Loss: 0.117766Train Epoch: 2 [68096/702208 (10%)]	Loss: 0.129144Train Epoch: 2 [69120/702208 (10%)]	Loss: 0.085683Train Epoch: 2 [70016/702208 (10%)]	Loss: 0.104843Train Epoch: 2 [71040/702208 (10%)]	Loss: 0.072607Train Epoch: 2 [72064/702208 (10%)]	Loss: 0.103868Train Epoch: 2 [73088/702208 (10%)]	Loss: 0.059654Train Epoch: 2 [74112/702208 (11%)]	Loss: 0.062448Train Epoch: 2 [75008/702208 (11%)]	Loss: 0.134116
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8027 / 8283] 96 %
Accuracy of the network on test loader class  1: [4477 / 4517] 99 %

Writing model: iterations-777216-total-97.69-class0-96.91-class1-99.11
Train Epoch: 2 [76032/702208 (11%)]	Loss: 0.132512Train Epoch: 2 [77056/702208 (11%)]	Loss: 0.055564Train Epoch: 2 [78080/702208 (11%)]	Loss: 0.070986Train Epoch: 2 [79104/702208 (11%)]	Loss: 0.065285Train Epoch: 2 [80000/702208 (11%)]	Loss: 0.068121Train Epoch: 2 [80128/702208 (11%)]	Loss: 0.121620Train Epoch: 2 [81024/702208 (12%)]	Loss: 0.096388Train Epoch: 2 [82048/702208 (12%)]	Loss: 0.061486Train Epoch: 2 [83072/702208 (12%)]	Loss: 0.139256Train Epoch: 2 [84096/702208 (12%)]	Loss: 0.101825Train Epoch: 2 [85120/702208 (12%)]	Loss: 0.143026Train Epoch: 2 [86016/702208 (12%)]	Loss: 0.070209Train Epoch: 2 [87040/702208 (12%)]	Loss: 0.050665Train Epoch: 2 [88064/702208 (13%)]	Loss: 0.140963Train Epoch: 2 [89088/702208 (13%)]	Loss: 0.148853Train Epoch: 2 [90112/702208 (13%)]	Loss: 0.070036Train Epoch: 2 [91008/702208 (13%)]	Loss: 0.118573Train Epoch: 2 [92032/702208 (13%)]	Loss: 0.151849Train Epoch: 2 [93056/702208 (13%)]	Loss: 0.093927Train Epoch: 2 [94080/702208 (13%)]	Loss: 0.135150Train Epoch: 2 [95104/702208 (14%)]	Loss: 0.087863Train Epoch: 2 [96000/702208 (14%)]	Loss: 0.128733Train Epoch: 2 [96128/702208 (14%)]	Loss: 0.066827Train Epoch: 2 [97024/702208 (14%)]	Loss: 0.082798Train Epoch: 2 [98048/702208 (14%)]	Loss: 0.075592Train Epoch: 2 [99072/702208 (14%)]	Loss: 0.108775Train Epoch: 2 [100096/702208 (14%)]	Loss: 0.131287
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8035 / 8283] 97 %
Accuracy of the network on test loader class  1: [4463 / 4517] 98 %

Writing model: iterations-802304-total-97.64-class0-97.00999999999999-class1-98.8

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11880 / 12833] 92 %
Accuracy of the network on train loader class  1: [7027 / 7135] 98 %
Train Epoch: 2 [101120/702208 (14%)]	Loss: 0.088141Train Epoch: 2 [102016/702208 (15%)]	Loss: 0.067859Train Epoch: 2 [103040/702208 (15%)]	Loss: 0.064597Train Epoch: 2 [104064/702208 (15%)]	Loss: 0.088885Train Epoch: 2 [105088/702208 (15%)]	Loss: 0.030714Train Epoch: 2 [106112/702208 (15%)]	Loss: 0.211425Train Epoch: 2 [107008/702208 (15%)]	Loss: 0.188528Train Epoch: 2 [108032/702208 (15%)]	Loss: 0.063509Train Epoch: 2 [109056/702208 (16%)]	Loss: 0.066690Train Epoch: 2 [110080/702208 (16%)]	Loss: 0.125084Train Epoch: 2 [111104/702208 (16%)]	Loss: 0.134445Train Epoch: 2 [112000/702208 (16%)]	Loss: 0.089266Train Epoch: 2 [112128/702208 (16%)]	Loss: 0.136564Train Epoch: 2 [113024/702208 (16%)]	Loss: 0.065674Train Epoch: 2 [114048/702208 (16%)]	Loss: 0.088803Train Epoch: 2 [115072/702208 (16%)]	Loss: 0.248523Train Epoch: 2 [116096/702208 (17%)]	Loss: 0.231277Train Epoch: 2 [117120/702208 (17%)]	Loss: 0.090866Train Epoch: 2 [118016/702208 (17%)]	Loss: 0.061406Train Epoch: 2 [119040/702208 (17%)]	Loss: 0.130482Train Epoch: 2 [120064/702208 (17%)]	Loss: 0.195285Train Epoch: 2 [121088/702208 (17%)]	Loss: 0.171993Train Epoch: 2 [122112/702208 (17%)]	Loss: 0.135617Train Epoch: 2 [123008/702208 (18%)]	Loss: 0.085000Train Epoch: 2 [124032/702208 (18%)]	Loss: 0.130463Train Epoch: 2 [125056/702208 (18%)]	Loss: 0.094846
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7914 / 8283] 95 %
Accuracy of the network on test loader class  1: [4488 / 4517] 99 %

Writing model: iterations-827264-total-96.89-class0-95.55-class1-99.36
Train Epoch: 2 [126080/702208 (18%)]	Loss: 0.085770Train Epoch: 2 [127104/702208 (18%)]	Loss: 0.158637Train Epoch: 2 [128000/702208 (18%)]	Loss: 0.040482Train Epoch: 2 [128128/702208 (18%)]	Loss: 0.126757Train Epoch: 2 [129024/702208 (18%)]	Loss: 0.120440Train Epoch: 2 [130048/702208 (19%)]	Loss: 0.077982Train Epoch: 2 [131072/702208 (19%)]	Loss: 0.115353Train Epoch: 2 [132096/702208 (19%)]	Loss: 0.053218Train Epoch: 2 [133120/702208 (19%)]	Loss: 0.104237Train Epoch: 2 [134016/702208 (19%)]	Loss: 0.217452Train Epoch: 2 [135040/702208 (19%)]	Loss: 0.065346Train Epoch: 2 [136064/702208 (19%)]	Loss: 0.101182Train Epoch: 2 [137088/702208 (20%)]	Loss: 0.070985Train Epoch: 2 [138112/702208 (20%)]	Loss: 0.105651Train Epoch: 2 [139008/702208 (20%)]	Loss: 0.110926Train Epoch: 2 [140032/702208 (20%)]	Loss: 0.200089Train Epoch: 2 [141056/702208 (20%)]	Loss: 0.091036Train Epoch: 2 [142080/702208 (20%)]	Loss: 0.095643Train Epoch: 2 [143104/702208 (20%)]	Loss: 0.125725Train Epoch: 2 [144000/702208 (21%)]	Loss: 0.125040Train Epoch: 2 [144128/702208 (21%)]	Loss: 0.107136Train Epoch: 2 [145024/702208 (21%)]	Loss: 0.096519Train Epoch: 2 [146048/702208 (21%)]	Loss: 0.145216Train Epoch: 2 [147072/702208 (21%)]	Loss: 0.094154Train Epoch: 2 [148096/702208 (21%)]	Loss: 0.127169Train Epoch: 2 [149120/702208 (21%)]	Loss: 0.175637Train Epoch: 2 [150016/702208 (21%)]	Loss: 0.102442
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8052 / 8283] 97 %
Accuracy of the network on test loader class  1: [4467 / 4517] 98 %

Writing model: iterations-852224-total-97.8-class0-97.21-class1-98.89

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12127 / 12833] 94 %
Accuracy of the network on train loader class  1: [6972 / 7135] 97 %
Train Epoch: 2 [151040/702208 (22%)]	Loss: 0.074386Train Epoch: 2 [152064/702208 (22%)]	Loss: 0.079246Train Epoch: 2 [153088/702208 (22%)]	Loss: 0.141868Train Epoch: 2 [154112/702208 (22%)]	Loss: 0.138303Train Epoch: 2 [155008/702208 (22%)]	Loss: 0.094595Train Epoch: 2 [156032/702208 (22%)]	Loss: 0.080115Train Epoch: 2 [157056/702208 (22%)]	Loss: 0.080833Train Epoch: 2 [158080/702208 (23%)]	Loss: 0.149486Train Epoch: 2 [159104/702208 (23%)]	Loss: 0.065944Train Epoch: 2 [160000/702208 (23%)]	Loss: 0.157946Train Epoch: 2 [160128/702208 (23%)]	Loss: 0.082411Train Epoch: 2 [161024/702208 (23%)]	Loss: 0.142144Train Epoch: 2 [162048/702208 (23%)]	Loss: 0.140830Train Epoch: 2 [163072/702208 (23%)]	Loss: 0.095873Train Epoch: 2 [164096/702208 (23%)]	Loss: 0.115696Train Epoch: 2 [165120/702208 (24%)]	Loss: 0.060095Train Epoch: 2 [166016/702208 (24%)]	Loss: 0.117362Train Epoch: 2 [167040/702208 (24%)]	Loss: 0.071125Train Epoch: 2 [168064/702208 (24%)]	Loss: 0.129415Train Epoch: 2 [169088/702208 (24%)]	Loss: 0.115938Train Epoch: 2 [170112/702208 (24%)]	Loss: 0.077628Train Epoch: 2 [171008/702208 (24%)]	Loss: 0.064442Train Epoch: 2 [172032/702208 (24%)]	Loss: 0.071318Train Epoch: 2 [173056/702208 (25%)]	Loss: 0.120241Train Epoch: 2 [174080/702208 (25%)]	Loss: 0.058018Train Epoch: 2 [175104/702208 (25%)]	Loss: 0.072367
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8008 / 8283] 96 %
Accuracy of the network on test loader class  1: [4486 / 4517] 99 %

Writing model: iterations-877312-total-97.61-class0-96.67999999999999-class1-99.31
Train Epoch: 2 [176000/702208 (25%)]	Loss: 0.150900Train Epoch: 2 [176128/702208 (25%)]	Loss: 0.095413Train Epoch: 2 [177024/702208 (25%)]	Loss: 0.085785Train Epoch: 2 [178048/702208 (25%)]	Loss: 0.075553Train Epoch: 2 [179072/702208 (26%)]	Loss: 0.091611Train Epoch: 2 [180096/702208 (26%)]	Loss: 0.109374Train Epoch: 2 [181120/702208 (26%)]	Loss: 0.072017Train Epoch: 2 [182016/702208 (26%)]	Loss: 0.141758Train Epoch: 2 [183040/702208 (26%)]	Loss: 0.041223Train Epoch: 2 [184064/702208 (26%)]	Loss: 0.115772Train Epoch: 2 [185088/702208 (26%)]	Loss: 0.129155Train Epoch: 2 [186112/702208 (27%)]	Loss: 0.058276Train Epoch: 2 [187008/702208 (27%)]	Loss: 0.064108Train Epoch: 2 [188032/702208 (27%)]	Loss: 0.103372Train Epoch: 2 [189056/702208 (27%)]	Loss: 0.058544Train Epoch: 2 [190080/702208 (27%)]	Loss: 0.051043Train Epoch: 2 [191104/702208 (27%)]	Loss: 0.258369Train Epoch: 2 [192000/702208 (27%)]	Loss: 0.133398Train Epoch: 2 [192128/702208 (27%)]	Loss: 0.162927Train Epoch: 2 [193024/702208 (27%)]	Loss: 0.074364Train Epoch: 2 [194048/702208 (28%)]	Loss: 0.103517Train Epoch: 2 [195072/702208 (28%)]	Loss: 0.086440Train Epoch: 2 [196096/702208 (28%)]	Loss: 0.148408Train Epoch: 2 [197120/702208 (28%)]	Loss: 0.129240Train Epoch: 2 [198016/702208 (28%)]	Loss: 0.086878Train Epoch: 2 [199040/702208 (28%)]	Loss: 0.134514Train Epoch: 2 [200064/702208 (28%)]	Loss: 0.098974
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7935 / 8283] 95 %
Accuracy of the network on test loader class  1: [4485 / 4517] 99 %

Writing model: iterations-902272-total-97.03-class0-95.8-class1-99.29

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 93 %
Accuracy of the network on train loader class  0: [11844 / 12833] 92 %
Accuracy of the network on train loader class  1: [6924 / 7135] 97 %
Train Epoch: 2 [201088/702208 (29%)]	Loss: 0.121193Train Epoch: 2 [202112/702208 (29%)]	Loss: 0.073257Train Epoch: 2 [203008/702208 (29%)]	Loss: 0.111153Train Epoch: 2 [204032/702208 (29%)]	Loss: 0.134413Train Epoch: 2 [205056/702208 (29%)]	Loss: 0.107214Train Epoch: 2 [206080/702208 (29%)]	Loss: 0.064110Train Epoch: 2 [207104/702208 (29%)]	Loss: 0.050782Train Epoch: 2 [208000/702208 (30%)]	Loss: 0.079426Train Epoch: 2 [208128/702208 (30%)]	Loss: 0.097145Train Epoch: 2 [209024/702208 (30%)]	Loss: 0.223655Train Epoch: 2 [210048/702208 (30%)]	Loss: 0.145078Train Epoch: 2 [211072/702208 (30%)]	Loss: 0.089996Train Epoch: 2 [212096/702208 (30%)]	Loss: 0.064715Train Epoch: 2 [213120/702208 (30%)]	Loss: 0.049605Train Epoch: 2 [214016/702208 (30%)]	Loss: 0.066735Train Epoch: 2 [215040/702208 (31%)]	Loss: 0.126060Train Epoch: 2 [216064/702208 (31%)]	Loss: 0.088404Train Epoch: 2 [217088/702208 (31%)]	Loss: 0.085439Train Epoch: 2 [218112/702208 (31%)]	Loss: 0.122542Train Epoch: 2 [219008/702208 (31%)]	Loss: 0.079396Train Epoch: 2 [220032/702208 (31%)]	Loss: 0.056526Train Epoch: 2 [221056/702208 (31%)]	Loss: 0.045315Train Epoch: 2 [222080/702208 (32%)]	Loss: 0.121982Train Epoch: 2 [223104/702208 (32%)]	Loss: 0.093813Train Epoch: 2 [224000/702208 (32%)]	Loss: 0.080833Train Epoch: 2 [224128/702208 (32%)]	Loss: 0.057835Train Epoch: 2 [225024/702208 (32%)]	Loss: 0.045954
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7959 / 8283] 96 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-927232-total-97.28999999999999-class0-96.09-class1-99.49
Train Epoch: 2 [226048/702208 (32%)]	Loss: 0.084823Train Epoch: 2 [227072/702208 (32%)]	Loss: 0.126530Train Epoch: 2 [228096/702208 (32%)]	Loss: 0.129545Train Epoch: 2 [229120/702208 (33%)]	Loss: 0.095633Train Epoch: 2 [230016/702208 (33%)]	Loss: 0.126170Train Epoch: 2 [231040/702208 (33%)]	Loss: 0.180334Train Epoch: 2 [232064/702208 (33%)]	Loss: 0.058333Train Epoch: 2 [233088/702208 (33%)]	Loss: 0.097159Train Epoch: 2 [234112/702208 (33%)]	Loss: 0.059212Train Epoch: 2 [235008/702208 (33%)]	Loss: 0.094799Train Epoch: 2 [236032/702208 (34%)]	Loss: 0.105552Train Epoch: 2 [237056/702208 (34%)]	Loss: 0.067762Train Epoch: 2 [238080/702208 (34%)]	Loss: 0.112266Train Epoch: 2 [239104/702208 (34%)]	Loss: 0.082242Train Epoch: 2 [240000/702208 (34%)]	Loss: 0.092669Train Epoch: 2 [240128/702208 (34%)]	Loss: 0.117297Train Epoch: 2 [241024/702208 (34%)]	Loss: 0.172733Train Epoch: 2 [242048/702208 (34%)]	Loss: 0.064822Train Epoch: 2 [243072/702208 (35%)]	Loss: 0.061110Train Epoch: 2 [244096/702208 (35%)]	Loss: 0.091983Train Epoch: 2 [245120/702208 (35%)]	Loss: 0.119762Train Epoch: 2 [246016/702208 (35%)]	Loss: 0.054285Train Epoch: 2 [247040/702208 (35%)]	Loss: 0.133464Train Epoch: 2 [248064/702208 (35%)]	Loss: 0.060566Train Epoch: 2 [249088/702208 (35%)]	Loss: 0.081065Train Epoch: 2 [250112/702208 (36%)]	Loss: 0.095406
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7958 / 8283] 96 %
Accuracy of the network on test loader class  1: [4488 / 4517] 99 %

Writing model: iterations-952320-total-97.23-class0-96.08-class1-99.36

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 93 %
Accuracy of the network on train loader class  0: [11684 / 12833] 91 %
Accuracy of the network on train loader class  1: [6963 / 7135] 97 %
Train Epoch: 2 [251008/702208 (36%)]	Loss: 0.120503Train Epoch: 2 [252032/702208 (36%)]	Loss: 0.081530Train Epoch: 2 [253056/702208 (36%)]	Loss: 0.166049Train Epoch: 2 [254080/702208 (36%)]	Loss: 0.116004Train Epoch: 2 [255104/702208 (36%)]	Loss: 0.071898Train Epoch: 2 [256000/702208 (36%)]	Loss: 0.090468Train Epoch: 2 [256128/702208 (36%)]	Loss: 0.083245Train Epoch: 2 [257024/702208 (37%)]	Loss: 0.131967Train Epoch: 2 [258048/702208 (37%)]	Loss: 0.101348Train Epoch: 2 [259072/702208 (37%)]	Loss: 0.055028Train Epoch: 2 [260096/702208 (37%)]	Loss: 0.089155Train Epoch: 2 [261120/702208 (37%)]	Loss: 0.069122Train Epoch: 2 [262016/702208 (37%)]	Loss: 0.096525Train Epoch: 2 [263040/702208 (37%)]	Loss: 0.103001Train Epoch: 2 [264064/702208 (38%)]	Loss: 0.097727Train Epoch: 2 [265088/702208 (38%)]	Loss: 0.056303Train Epoch: 2 [266112/702208 (38%)]	Loss: 0.139093Train Epoch: 2 [267008/702208 (38%)]	Loss: 0.110657Train Epoch: 2 [268032/702208 (38%)]	Loss: 0.198084Train Epoch: 2 [269056/702208 (38%)]	Loss: 0.130653Train Epoch: 2 [270080/702208 (38%)]	Loss: 0.189217Train Epoch: 2 [271104/702208 (39%)]	Loss: 0.239569Train Epoch: 2 [272000/702208 (39%)]	Loss: 0.035605Train Epoch: 2 [272128/702208 (39%)]	Loss: 0.104709Train Epoch: 2 [273024/702208 (39%)]	Loss: 0.092120Train Epoch: 2 [274048/702208 (39%)]	Loss: 0.191127Train Epoch: 2 [275072/702208 (39%)]	Loss: 0.125101
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8050 / 8283] 97 %
Accuracy of the network on test loader class  1: [4476 / 4517] 99 %

Writing model: iterations-977280-total-97.86-class0-97.19-class1-99.09
Train Epoch: 2 [276096/702208 (39%)]	Loss: 0.045821Train Epoch: 2 [277120/702208 (39%)]	Loss: 0.081418Train Epoch: 2 [278016/702208 (40%)]	Loss: 0.083324Train Epoch: 2 [279040/702208 (40%)]	Loss: 0.052648Train Epoch: 2 [280064/702208 (40%)]	Loss: 0.075478Train Epoch: 2 [281088/702208 (40%)]	Loss: 0.104320Train Epoch: 2 [282112/702208 (40%)]	Loss: 0.069049Train Epoch: 2 [283008/702208 (40%)]	Loss: 0.081796Train Epoch: 2 [284032/702208 (40%)]	Loss: 0.089165Train Epoch: 2 [285056/702208 (41%)]	Loss: 0.070207Train Epoch: 2 [286080/702208 (41%)]	Loss: 0.054533Train Epoch: 2 [287104/702208 (41%)]	Loss: 0.099637Train Epoch: 2 [288000/702208 (41%)]	Loss: 0.094359Train Epoch: 2 [288128/702208 (41%)]	Loss: 0.134775Train Epoch: 2 [289024/702208 (41%)]	Loss: 0.054921Train Epoch: 2 [290048/702208 (41%)]	Loss: 0.128201Train Epoch: 2 [291072/702208 (41%)]	Loss: 0.067121Train Epoch: 2 [292096/702208 (42%)]	Loss: 0.090752Train Epoch: 2 [293120/702208 (42%)]	Loss: 0.114557Train Epoch: 2 [294016/702208 (42%)]	Loss: 0.054266Train Epoch: 2 [295040/702208 (42%)]	Loss: 0.104202Train Epoch: 2 [296064/702208 (42%)]	Loss: 0.091644Train Epoch: 2 [297088/702208 (42%)]	Loss: 0.074786Train Epoch: 2 [298112/702208 (42%)]	Loss: 0.068728Train Epoch: 2 [299008/702208 (43%)]	Loss: 0.094109Train Epoch: 2 [300032/702208 (43%)]	Loss: 0.096572
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8094 / 8283] 97 %
Accuracy of the network on test loader class  1: [4453 / 4517] 98 %

Writing model: iterations-1002240-total-98.02-class0-97.72-class1-98.58

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 92 %
Accuracy of the network on train loader class  0: [11814 / 12833] 92 %
Accuracy of the network on train loader class  1: [6665 / 7135] 93 %
Train Epoch: 2 [301056/702208 (43%)]	Loss: 0.161540Train Epoch: 2 [302080/702208 (43%)]	Loss: 0.046514Train Epoch: 2 [303104/702208 (43%)]	Loss: 0.072447Train Epoch: 2 [304000/702208 (43%)]	Loss: 0.157666Train Epoch: 2 [304128/702208 (43%)]	Loss: 0.051383Train Epoch: 2 [305024/702208 (43%)]	Loss: 0.099297Train Epoch: 2 [306048/702208 (44%)]	Loss: 0.082906Train Epoch: 2 [307072/702208 (44%)]	Loss: 0.143540Train Epoch: 2 [308096/702208 (44%)]	Loss: 0.061954Train Epoch: 2 [309120/702208 (44%)]	Loss: 0.113142Train Epoch: 2 [310016/702208 (44%)]	Loss: 0.066599Train Epoch: 2 [311040/702208 (44%)]	Loss: 0.109649Train Epoch: 2 [312064/702208 (44%)]	Loss: 0.100064Train Epoch: 2 [313088/702208 (45%)]	Loss: 0.099947Train Epoch: 2 [314112/702208 (45%)]	Loss: 0.127280Train Epoch: 2 [315008/702208 (45%)]	Loss: 0.043923Train Epoch: 2 [316032/702208 (45%)]	Loss: 0.176669Train Epoch: 2 [317056/702208 (45%)]	Loss: 0.110226Train Epoch: 2 [318080/702208 (45%)]	Loss: 0.079794Train Epoch: 2 [319104/702208 (45%)]	Loss: 0.118555Train Epoch: 2 [320000/702208 (46%)]	Loss: 0.091740Train Epoch: 2 [320128/702208 (46%)]	Loss: 0.065336Train Epoch: 2 [321024/702208 (46%)]	Loss: 0.074051Train Epoch: 2 [322048/702208 (46%)]	Loss: 0.119649Train Epoch: 2 [323072/702208 (46%)]	Loss: 0.124143Train Epoch: 2 [324096/702208 (46%)]	Loss: 0.120102Train Epoch: 2 [325120/702208 (46%)]	Loss: 0.070113
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7867 / 8283] 94 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-1027328-total-96.57-class0-94.98-class1-99.49
Train Epoch: 2 [326016/702208 (46%)]	Loss: 0.177086Train Epoch: 2 [327040/702208 (47%)]	Loss: 0.071756Train Epoch: 2 [328064/702208 (47%)]	Loss: 0.101890Train Epoch: 2 [329088/702208 (47%)]	Loss: 0.094657Train Epoch: 2 [330112/702208 (47%)]	Loss: 0.075322Train Epoch: 2 [331008/702208 (47%)]	Loss: 0.056886Train Epoch: 2 [332032/702208 (47%)]	Loss: 0.087658Train Epoch: 2 [333056/702208 (47%)]	Loss: 0.041145Train Epoch: 2 [334080/702208 (48%)]	Loss: 0.093639Train Epoch: 2 [335104/702208 (48%)]	Loss: 0.131468Train Epoch: 2 [336000/702208 (48%)]	Loss: 0.153360Train Epoch: 2 [336128/702208 (48%)]	Loss: 0.177145Train Epoch: 2 [337024/702208 (48%)]	Loss: 0.093351Train Epoch: 2 [338048/702208 (48%)]	Loss: 0.079740Train Epoch: 2 [339072/702208 (48%)]	Loss: 0.090453Train Epoch: 2 [340096/702208 (48%)]	Loss: 0.043439Train Epoch: 2 [341120/702208 (49%)]	Loss: 0.040532Train Epoch: 2 [342016/702208 (49%)]	Loss: 0.040702Train Epoch: 2 [343040/702208 (49%)]	Loss: 0.127237Train Epoch: 2 [344064/702208 (49%)]	Loss: 0.088542Train Epoch: 2 [345088/702208 (49%)]	Loss: 0.059692Train Epoch: 2 [346112/702208 (49%)]	Loss: 0.048477Train Epoch: 2 [347008/702208 (49%)]	Loss: 0.037296Train Epoch: 2 [348032/702208 (50%)]	Loss: 0.072585Train Epoch: 2 [349056/702208 (50%)]	Loss: 0.112180Train Epoch: 2 [350080/702208 (50%)]	Loss: 0.044036
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7932 / 8283] 95 %
Accuracy of the network on test loader class  1: [4485 / 4517] 99 %

Writing model: iterations-1052288-total-97.00999999999999-class0-95.76-class1-99.29

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11861 / 12833] 92 %
Accuracy of the network on train loader class  1: [7037 / 7135] 98 %
Train Epoch: 2 [351104/702208 (50%)]	Loss: 0.056356Train Epoch: 2 [352000/702208 (50%)]	Loss: 0.136700Train Epoch: 2 [352128/702208 (50%)]	Loss: 0.140744Train Epoch: 2 [353024/702208 (50%)]	Loss: 0.211506Train Epoch: 2 [354048/702208 (50%)]	Loss: 0.071862Train Epoch: 2 [355072/702208 (51%)]	Loss: 0.085242Train Epoch: 2 [356096/702208 (51%)]	Loss: 0.052597Train Epoch: 2 [357120/702208 (51%)]	Loss: 0.094866Train Epoch: 2 [358016/702208 (51%)]	Loss: 0.145614Train Epoch: 2 [359040/702208 (51%)]	Loss: 0.075759Train Epoch: 2 [360064/702208 (51%)]	Loss: 0.087135Train Epoch: 2 [361088/702208 (51%)]	Loss: 0.184130Train Epoch: 2 [362112/702208 (52%)]	Loss: 0.081407Train Epoch: 2 [363008/702208 (52%)]	Loss: 0.112437Train Epoch: 2 [364032/702208 (52%)]	Loss: 0.039499Train Epoch: 2 [365056/702208 (52%)]	Loss: 0.082600Train Epoch: 2 [366080/702208 (52%)]	Loss: 0.077663Train Epoch: 2 [367104/702208 (52%)]	Loss: 0.092919Train Epoch: 2 [368000/702208 (52%)]	Loss: 0.033084Train Epoch: 2 [368128/702208 (52%)]	Loss: 0.106456Train Epoch: 2 [369024/702208 (53%)]	Loss: 0.076497Train Epoch: 2 [370048/702208 (53%)]	Loss: 0.089613Train Epoch: 2 [371072/702208 (53%)]	Loss: 0.077560Train Epoch: 2 [372096/702208 (53%)]	Loss: 0.128057Train Epoch: 2 [373120/702208 (53%)]	Loss: 0.085918Train Epoch: 2 [374016/702208 (53%)]	Loss: 0.116251Train Epoch: 2 [375040/702208 (53%)]	Loss: 0.082169
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7985 / 8283] 96 %
Accuracy of the network on test loader class  1: [4478 / 4517] 99 %

Writing model: iterations-1077248-total-97.37-class0-96.39999999999999-class1-99.14
Train Epoch: 2 [376064/702208 (54%)]	Loss: 0.042198Train Epoch: 2 [377088/702208 (54%)]	Loss: 0.055385Train Epoch: 2 [378112/702208 (54%)]	Loss: 0.145785Train Epoch: 2 [379008/702208 (54%)]	Loss: 0.082491Train Epoch: 2 [380032/702208 (54%)]	Loss: 0.088671Train Epoch: 2 [381056/702208 (54%)]	Loss: 0.063835Train Epoch: 2 [382080/702208 (54%)]	Loss: 0.053666Train Epoch: 2 [383104/702208 (55%)]	Loss: 0.088765Train Epoch: 2 [384000/702208 (55%)]	Loss: 0.056307Train Epoch: 2 [384128/702208 (55%)]	Loss: 0.074947Train Epoch: 2 [385024/702208 (55%)]	Loss: 0.145918Train Epoch: 2 [386048/702208 (55%)]	Loss: 0.130196Train Epoch: 2 [387072/702208 (55%)]	Loss: 0.126591Train Epoch: 2 [388096/702208 (55%)]	Loss: 0.127569Train Epoch: 2 [389120/702208 (55%)]	Loss: 0.134848Train Epoch: 2 [390016/702208 (56%)]	Loss: 0.046296Train Epoch: 2 [391040/702208 (56%)]	Loss: 0.091318Train Epoch: 2 [392064/702208 (56%)]	Loss: 0.084903Train Epoch: 2 [393088/702208 (56%)]	Loss: 0.120915Train Epoch: 2 [394112/702208 (56%)]	Loss: 0.040206Train Epoch: 2 [395008/702208 (56%)]	Loss: 0.124181Train Epoch: 2 [396032/702208 (56%)]	Loss: 0.060678Train Epoch: 2 [397056/702208 (57%)]	Loss: 0.060042Train Epoch: 2 [398080/702208 (57%)]	Loss: 0.080644Train Epoch: 2 [399104/702208 (57%)]	Loss: 0.083760Train Epoch: 2 [400000/702208 (57%)]	Loss: 0.116732
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7861 / 8283] 94 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-1102208-total-96.57-class0-94.91000000000001-class1-99.62

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 93 %
Accuracy of the network on train loader class  0: [11647 / 12833] 90 %
Accuracy of the network on train loader class  1: [6976 / 7135] 97 %
Train Epoch: 2 [400128/702208 (57%)]	Loss: 0.126096
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7852 / 8283] 94 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %

Writing model: iterations-1102336-total-96.52-class0-94.8-class1-99.67

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11920 / 12833] 92 %
Accuracy of the network on train loader class  1: [7037 / 7135] 98 %
Train Epoch: 2 [401024/702208 (57%)]	Loss: 0.130074Train Epoch: 2 [402048/702208 (57%)]	Loss: 0.152822Train Epoch: 2 [403072/702208 (57%)]	Loss: 0.044210Train Epoch: 2 [404096/702208 (58%)]	Loss: 0.059991Train Epoch: 2 [405120/702208 (58%)]	Loss: 0.162469Train Epoch: 2 [406016/702208 (58%)]	Loss: 0.076210Train Epoch: 2 [407040/702208 (58%)]	Loss: 0.054880Train Epoch: 2 [408064/702208 (58%)]	Loss: 0.127544Train Epoch: 2 [409088/702208 (58%)]	Loss: 0.051208Train Epoch: 2 [410112/702208 (58%)]	Loss: 0.051076Train Epoch: 2 [411008/702208 (59%)]	Loss: 0.089948Train Epoch: 2 [412032/702208 (59%)]	Loss: 0.082745Train Epoch: 2 [413056/702208 (59%)]	Loss: 0.042845Train Epoch: 2 [414080/702208 (59%)]	Loss: 0.109794Train Epoch: 2 [415104/702208 (59%)]	Loss: 0.151407Train Epoch: 2 [416000/702208 (59%)]	Loss: 0.095029Train Epoch: 2 [416128/702208 (59%)]	Loss: 0.158677Train Epoch: 2 [417024/702208 (59%)]	Loss: 0.081296Train Epoch: 2 [418048/702208 (60%)]	Loss: 0.099328Train Epoch: 2 [419072/702208 (60%)]	Loss: 0.093512Train Epoch: 2 [420096/702208 (60%)]	Loss: 0.124497Train Epoch: 2 [421120/702208 (60%)]	Loss: 0.111503Train Epoch: 2 [422016/702208 (60%)]	Loss: 0.088090Train Epoch: 2 [423040/702208 (60%)]	Loss: 0.084337Train Epoch: 2 [424064/702208 (60%)]	Loss: 0.079914Train Epoch: 2 [425088/702208 (61%)]	Loss: 0.112801
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8101 / 8283] 97 %
Accuracy of the network on test loader class  1: [4451 / 4517] 98 %

Writing model: iterations-1127296-total-98.06-class0-97.8-class1-98.54
Train Epoch: 2 [426112/702208 (61%)]	Loss: 0.079962Train Epoch: 2 [427008/702208 (61%)]	Loss: 0.063243Train Epoch: 2 [428032/702208 (61%)]	Loss: 0.237640Train Epoch: 2 [429056/702208 (61%)]	Loss: 0.043225Train Epoch: 2 [430080/702208 (61%)]	Loss: 0.158899Train Epoch: 2 [431104/702208 (61%)]	Loss: 0.077776Train Epoch: 2 [432000/702208 (62%)]	Loss: 0.093763Train Epoch: 2 [432128/702208 (62%)]	Loss: 0.036092Train Epoch: 2 [433024/702208 (62%)]	Loss: 0.061789Train Epoch: 2 [434048/702208 (62%)]	Loss: 0.262324Train Epoch: 2 [435072/702208 (62%)]	Loss: 0.055313Train Epoch: 2 [436096/702208 (62%)]	Loss: 0.105415Train Epoch: 2 [437120/702208 (62%)]	Loss: 0.069366Train Epoch: 2 [438016/702208 (62%)]	Loss: 0.067412Train Epoch: 2 [439040/702208 (63%)]	Loss: 0.279332Train Epoch: 2 [440064/702208 (63%)]	Loss: 0.217121Train Epoch: 2 [441088/702208 (63%)]	Loss: 0.140466Train Epoch: 2 [442112/702208 (63%)]	Loss: 0.058716Train Epoch: 2 [443008/702208 (63%)]	Loss: 0.231986Train Epoch: 2 [444032/702208 (63%)]	Loss: 0.067614Train Epoch: 2 [445056/702208 (63%)]	Loss: 0.057553Train Epoch: 2 [446080/702208 (64%)]	Loss: 0.050033Train Epoch: 2 [447104/702208 (64%)]	Loss: 0.093800Train Epoch: 2 [448000/702208 (64%)]	Loss: 0.179239Train Epoch: 2 [448128/702208 (64%)]	Loss: 0.088771Train Epoch: 2 [449024/702208 (64%)]	Loss: 0.082205Train Epoch: 2 [450048/702208 (64%)]	Loss: 0.114704
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7891 / 8283] 95 %
Accuracy of the network on test loader class  1: [4488 / 4517] 99 %

Writing model: iterations-1152256-total-96.71-class0-95.27-class1-99.36

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 93 %
Accuracy of the network on train loader class  0: [11712 / 12833] 91 %
Accuracy of the network on train loader class  1: [6953 / 7135] 97 %
Train Epoch: 2 [451072/702208 (64%)]	Loss: 0.065934Train Epoch: 2 [452096/702208 (64%)]	Loss: 0.069040Train Epoch: 2 [453120/702208 (65%)]	Loss: 0.105085Train Epoch: 2 [454016/702208 (65%)]	Loss: 0.067577Train Epoch: 2 [455040/702208 (65%)]	Loss: 0.084512Train Epoch: 2 [456064/702208 (65%)]	Loss: 0.042416Train Epoch: 2 [457088/702208 (65%)]	Loss: 0.147483Train Epoch: 2 [458112/702208 (65%)]	Loss: 0.139400Train Epoch: 2 [459008/702208 (65%)]	Loss: 0.054792Train Epoch: 2 [460032/702208 (66%)]	Loss: 0.051686Train Epoch: 2 [461056/702208 (66%)]	Loss: 0.055614Train Epoch: 2 [462080/702208 (66%)]	Loss: 0.130612Train Epoch: 2 [463104/702208 (66%)]	Loss: 0.030895Train Epoch: 2 [464000/702208 (66%)]	Loss: 0.058128Train Epoch: 2 [464128/702208 (66%)]	Loss: 0.040377Train Epoch: 2 [465024/702208 (66%)]	Loss: 0.084317Train Epoch: 2 [466048/702208 (66%)]	Loss: 0.076838Train Epoch: 2 [467072/702208 (67%)]	Loss: 0.038356Train Epoch: 2 [468096/702208 (67%)]	Loss: 0.106373Train Epoch: 2 [469120/702208 (67%)]	Loss: 0.096784Train Epoch: 2 [470016/702208 (67%)]	Loss: 0.093318Train Epoch: 2 [471040/702208 (67%)]	Loss: 0.048047Train Epoch: 2 [472064/702208 (67%)]	Loss: 0.118801Train Epoch: 2 [473088/702208 (67%)]	Loss: 0.116436Train Epoch: 2 [474112/702208 (68%)]	Loss: 0.086415Train Epoch: 2 [475008/702208 (68%)]	Loss: 0.094783
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7944 / 8283] 95 %
Accuracy of the network on test loader class  1: [4493 / 4517] 99 %

Writing model: iterations-1177216-total-97.16-class0-95.91-class1-99.47
Train Epoch: 2 [476032/702208 (68%)]	Loss: 0.069224Train Epoch: 2 [477056/702208 (68%)]	Loss: 0.145352Train Epoch: 2 [478080/702208 (68%)]	Loss: 0.097293Train Epoch: 2 [479104/702208 (68%)]	Loss: 0.125950Train Epoch: 2 [480000/702208 (68%)]	Loss: 0.051009Train Epoch: 2 [480128/702208 (68%)]	Loss: 0.098580Train Epoch: 2 [481024/702208 (69%)]	Loss: 0.061228Train Epoch: 2 [482048/702208 (69%)]	Loss: 0.088503Train Epoch: 2 [483072/702208 (69%)]	Loss: 0.064845Train Epoch: 2 [484096/702208 (69%)]	Loss: 0.185185Train Epoch: 2 [485120/702208 (69%)]	Loss: 0.111003Train Epoch: 2 [486016/702208 (69%)]	Loss: 0.064241Train Epoch: 2 [487040/702208 (69%)]	Loss: 0.156744Train Epoch: 2 [488064/702208 (70%)]	Loss: 0.075887Train Epoch: 2 [489088/702208 (70%)]	Loss: 0.070800Train Epoch: 2 [490112/702208 (70%)]	Loss: 0.135006Train Epoch: 2 [491008/702208 (70%)]	Loss: 0.181464Train Epoch: 2 [492032/702208 (70%)]	Loss: 0.064947Train Epoch: 2 [493056/702208 (70%)]	Loss: 0.104109Train Epoch: 2 [494080/702208 (70%)]	Loss: 0.087198Train Epoch: 2 [495104/702208 (71%)]	Loss: 0.135089Train Epoch: 2 [496000/702208 (71%)]	Loss: 0.041905Train Epoch: 2 [496128/702208 (71%)]	Loss: 0.214235Train Epoch: 2 [497024/702208 (71%)]	Loss: 0.116584Train Epoch: 2 [498048/702208 (71%)]	Loss: 0.072420Train Epoch: 2 [499072/702208 (71%)]	Loss: 0.174357Train Epoch: 2 [500096/702208 (71%)]	Loss: 0.138668
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7994 / 8283] 96 %
Accuracy of the network on test loader class  1: [4486 / 4517] 99 %

Writing model: iterations-1202304-total-97.5-class0-96.50999999999999-class1-99.31

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [12136 / 12833] 94 %
Accuracy of the network on train loader class  1: [6645 / 7135] 93 %
Train Epoch: 2 [501120/702208 (71%)]	Loss: 0.159975Train Epoch: 2 [502016/702208 (71%)]	Loss: 0.067865Train Epoch: 2 [503040/702208 (72%)]	Loss: 0.117686Train Epoch: 2 [504064/702208 (72%)]	Loss: 0.054663Train Epoch: 2 [505088/702208 (72%)]	Loss: 0.066224Train Epoch: 2 [506112/702208 (72%)]	Loss: 0.115820Train Epoch: 2 [507008/702208 (72%)]	Loss: 0.100801Train Epoch: 2 [508032/702208 (72%)]	Loss: 0.089625Train Epoch: 2 [509056/702208 (72%)]	Loss: 0.125586Train Epoch: 2 [510080/702208 (73%)]	Loss: 0.125274Train Epoch: 2 [511104/702208 (73%)]	Loss: 0.072141Train Epoch: 2 [512000/702208 (73%)]	Loss: 0.107375Train Epoch: 2 [512128/702208 (73%)]	Loss: 0.140800Train Epoch: 2 [513024/702208 (73%)]	Loss: 0.111042Train Epoch: 2 [514048/702208 (73%)]	Loss: 0.140276Train Epoch: 2 [515072/702208 (73%)]	Loss: 0.062944Train Epoch: 2 [516096/702208 (73%)]	Loss: 0.067098Train Epoch: 2 [517120/702208 (74%)]	Loss: 0.114952Train Epoch: 2 [518016/702208 (74%)]	Loss: 0.082613Train Epoch: 2 [519040/702208 (74%)]	Loss: 0.093122Train Epoch: 2 [520064/702208 (74%)]	Loss: 0.111855Train Epoch: 2 [521088/702208 (74%)]	Loss: 0.048560Train Epoch: 2 [522112/702208 (74%)]	Loss: 0.148635Train Epoch: 2 [523008/702208 (74%)]	Loss: 0.058358Train Epoch: 2 [524032/702208 (75%)]	Loss: 0.124636Train Epoch: 2 [525056/702208 (75%)]	Loss: 0.092848
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8012 / 8283] 96 %
Accuracy of the network on test loader class  1: [4479 / 4517] 99 %

Writing model: iterations-1227264-total-97.59-class0-96.73-class1-99.16
Train Epoch: 2 [526080/702208 (75%)]	Loss: 0.099115Train Epoch: 2 [527104/702208 (75%)]	Loss: 0.048844Train Epoch: 2 [528000/702208 (75%)]	Loss: 0.042204Train Epoch: 2 [528128/702208 (75%)]	Loss: 0.070689Train Epoch: 2 [529024/702208 (75%)]	Loss: 0.112899Train Epoch: 2 [530048/702208 (75%)]	Loss: 0.116055Train Epoch: 2 [531072/702208 (76%)]	Loss: 0.102364Train Epoch: 2 [532096/702208 (76%)]	Loss: 0.096545Train Epoch: 2 [533120/702208 (76%)]	Loss: 0.076737Train Epoch: 2 [534016/702208 (76%)]	Loss: 0.037647Train Epoch: 2 [535040/702208 (76%)]	Loss: 0.107432Train Epoch: 2 [536064/702208 (76%)]	Loss: 0.046572Train Epoch: 2 [537088/702208 (76%)]	Loss: 0.111465Train Epoch: 2 [538112/702208 (77%)]	Loss: 0.124179Train Epoch: 2 [539008/702208 (77%)]	Loss: 0.050174Train Epoch: 2 [540032/702208 (77%)]	Loss: 0.095754Train Epoch: 2 [541056/702208 (77%)]	Loss: 0.081911Train Epoch: 2 [542080/702208 (77%)]	Loss: 0.068365Train Epoch: 2 [543104/702208 (77%)]	Loss: 0.109878Train Epoch: 2 [544000/702208 (77%)]	Loss: 0.104053Train Epoch: 2 [544128/702208 (77%)]	Loss: 0.111201Train Epoch: 2 [545024/702208 (78%)]	Loss: 0.192913Train Epoch: 2 [546048/702208 (78%)]	Loss: 0.104157Train Epoch: 2 [547072/702208 (78%)]	Loss: 0.168825Train Epoch: 2 [548096/702208 (78%)]	Loss: 0.070564Train Epoch: 2 [549120/702208 (78%)]	Loss: 0.099503Train Epoch: 2 [550016/702208 (78%)]	Loss: 0.122886
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7833 / 8283] 94 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-1252224-total-96.39999999999999-class0-94.57-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12001 / 12833] 93 %
Accuracy of the network on train loader class  1: [6995 / 7135] 98 %
Train Epoch: 2 [551040/702208 (78%)]	Loss: 0.122602Train Epoch: 2 [552064/702208 (79%)]	Loss: 0.137240Train Epoch: 2 [553088/702208 (79%)]	Loss: 0.071638Train Epoch: 2 [554112/702208 (79%)]	Loss: 0.103364Train Epoch: 2 [555008/702208 (79%)]	Loss: 0.036586Train Epoch: 2 [556032/702208 (79%)]	Loss: 0.121817Train Epoch: 2 [557056/702208 (79%)]	Loss: 0.082790Train Epoch: 2 [558080/702208 (79%)]	Loss: 0.150965Train Epoch: 2 [559104/702208 (80%)]	Loss: 0.037821Train Epoch: 2 [560000/702208 (80%)]	Loss: 0.050209Train Epoch: 2 [560128/702208 (80%)]	Loss: 0.117774Train Epoch: 2 [561024/702208 (80%)]	Loss: 0.059646Train Epoch: 2 [562048/702208 (80%)]	Loss: 0.089303Train Epoch: 2 [563072/702208 (80%)]	Loss: 0.117117Train Epoch: 2 [564096/702208 (80%)]	Loss: 0.123570Train Epoch: 2 [565120/702208 (80%)]	Loss: 0.170212Train Epoch: 2 [566016/702208 (81%)]	Loss: 0.035817Train Epoch: 2 [567040/702208 (81%)]	Loss: 0.060753Train Epoch: 2 [568064/702208 (81%)]	Loss: 0.065341Train Epoch: 2 [569088/702208 (81%)]	Loss: 0.040567Train Epoch: 2 [570112/702208 (81%)]	Loss: 0.074016Train Epoch: 2 [571008/702208 (81%)]	Loss: 0.089543Train Epoch: 2 [572032/702208 (81%)]	Loss: 0.072259Train Epoch: 2 [573056/702208 (82%)]	Loss: 0.050596Train Epoch: 2 [574080/702208 (82%)]	Loss: 0.070431Train Epoch: 2 [575104/702208 (82%)]	Loss: 0.091291
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7947 / 8283] 95 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-1277312-total-97.2-class0-95.94-class1-99.51
Train Epoch: 2 [576000/702208 (82%)]	Loss: 0.051526Train Epoch: 2 [576128/702208 (82%)]	Loss: 0.056106Train Epoch: 2 [577024/702208 (82%)]	Loss: 0.121339Train Epoch: 2 [578048/702208 (82%)]	Loss: 0.199519Train Epoch: 2 [579072/702208 (82%)]	Loss: 0.044892Train Epoch: 2 [580096/702208 (83%)]	Loss: 0.064668Train Epoch: 2 [581120/702208 (83%)]	Loss: 0.111784Train Epoch: 2 [582016/702208 (83%)]	Loss: 0.057319Train Epoch: 2 [583040/702208 (83%)]	Loss: 0.165296Train Epoch: 2 [584064/702208 (83%)]	Loss: 0.039796Train Epoch: 2 [585088/702208 (83%)]	Loss: 0.054838Train Epoch: 2 [586112/702208 (83%)]	Loss: 0.056289Train Epoch: 2 [587008/702208 (84%)]	Loss: 0.088252Train Epoch: 2 [588032/702208 (84%)]	Loss: 0.028564Train Epoch: 2 [589056/702208 (84%)]	Loss: 0.118477Train Epoch: 2 [590080/702208 (84%)]	Loss: 0.113458Train Epoch: 2 [591104/702208 (84%)]	Loss: 0.051861Train Epoch: 2 [592000/702208 (84%)]	Loss: 0.103335Train Epoch: 2 [592128/702208 (84%)]	Loss: 0.095771Train Epoch: 2 [593024/702208 (84%)]	Loss: 0.082272Train Epoch: 2 [594048/702208 (85%)]	Loss: 0.063333Train Epoch: 2 [595072/702208 (85%)]	Loss: 0.113012Train Epoch: 2 [596096/702208 (85%)]	Loss: 0.066010Train Epoch: 2 [597120/702208 (85%)]	Loss: 0.073482Train Epoch: 2 [598016/702208 (85%)]	Loss: 0.113315Train Epoch: 2 [599040/702208 (85%)]	Loss: 0.073554Train Epoch: 2 [600064/702208 (85%)]	Loss: 0.062792
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8041 / 8283] 97 %
Accuracy of the network on test loader class  1: [4476 / 4517] 99 %

Writing model: iterations-1302272-total-97.78999999999999-class0-97.08-class1-99.09

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 90 %
Accuracy of the network on train loader class  0: [11375 / 12833] 88 %
Accuracy of the network on train loader class  1: [6711 / 7135] 94 %
Train Epoch: 2 [601088/702208 (86%)]	Loss: 0.107849Train Epoch: 2 [602112/702208 (86%)]	Loss: 0.066792Train Epoch: 2 [603008/702208 (86%)]	Loss: 0.059237Train Epoch: 2 [604032/702208 (86%)]	Loss: 0.118174Train Epoch: 2 [605056/702208 (86%)]	Loss: 0.115933Train Epoch: 2 [606080/702208 (86%)]	Loss: 0.108028Train Epoch: 2 [607104/702208 (86%)]	Loss: 0.067435Train Epoch: 2 [608000/702208 (87%)]	Loss: 0.101715Train Epoch: 2 [608128/702208 (87%)]	Loss: 0.070322Train Epoch: 2 [609024/702208 (87%)]	Loss: 0.063331Train Epoch: 2 [610048/702208 (87%)]	Loss: 0.083268Train Epoch: 2 [611072/702208 (87%)]	Loss: 0.119568Train Epoch: 2 [612096/702208 (87%)]	Loss: 0.091153Train Epoch: 2 [613120/702208 (87%)]	Loss: 0.122739Train Epoch: 2 [614016/702208 (87%)]	Loss: 0.101056Train Epoch: 2 [615040/702208 (88%)]	Loss: 0.051399Train Epoch: 2 [616064/702208 (88%)]	Loss: 0.063479Train Epoch: 2 [617088/702208 (88%)]	Loss: 0.058817Train Epoch: 2 [618112/702208 (88%)]	Loss: 0.083632Train Epoch: 2 [619008/702208 (88%)]	Loss: 0.065107Train Epoch: 2 [620032/702208 (88%)]	Loss: 0.063004Train Epoch: 2 [621056/702208 (88%)]	Loss: 0.032492Train Epoch: 2 [622080/702208 (89%)]	Loss: 0.039230Train Epoch: 2 [623104/702208 (89%)]	Loss: 0.159048Train Epoch: 2 [624000/702208 (89%)]	Loss: 0.077745Train Epoch: 2 [624128/702208 (89%)]	Loss: 0.076045Train Epoch: 2 [625024/702208 (89%)]	Loss: 0.144568
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8045 / 8283] 97 %
Accuracy of the network on test loader class  1: [4457 / 4517] 98 %

Writing model: iterations-1327232-total-97.67-class0-97.13000000000001-class1-98.67
Train Epoch: 2 [626048/702208 (89%)]	Loss: 0.062460Train Epoch: 2 [627072/702208 (89%)]	Loss: 0.146244Train Epoch: 2 [628096/702208 (89%)]	Loss: 0.120863Train Epoch: 2 [629120/702208 (90%)]	Loss: 0.105978Train Epoch: 2 [630016/702208 (90%)]	Loss: 0.149017Train Epoch: 2 [631040/702208 (90%)]	Loss: 0.116103Train Epoch: 2 [632064/702208 (90%)]	Loss: 0.042741Train Epoch: 2 [633088/702208 (90%)]	Loss: 0.089094Train Epoch: 2 [634112/702208 (90%)]	Loss: 0.112808Train Epoch: 2 [635008/702208 (90%)]	Loss: 0.102196Train Epoch: 2 [636032/702208 (91%)]	Loss: 0.057038Train Epoch: 2 [637056/702208 (91%)]	Loss: 0.059450Train Epoch: 2 [638080/702208 (91%)]	Loss: 0.078680Train Epoch: 2 [639104/702208 (91%)]	Loss: 0.077302Train Epoch: 2 [640000/702208 (91%)]	Loss: 0.093868Train Epoch: 2 [640128/702208 (91%)]	Loss: 0.104419Train Epoch: 2 [641024/702208 (91%)]	Loss: 0.086078Train Epoch: 2 [642048/702208 (91%)]	Loss: 0.034371Train Epoch: 2 [643072/702208 (92%)]	Loss: 0.113380Train Epoch: 2 [644096/702208 (92%)]	Loss: 0.186717Train Epoch: 2 [645120/702208 (92%)]	Loss: 0.035992Train Epoch: 2 [646016/702208 (92%)]	Loss: 0.093871Train Epoch: 2 [647040/702208 (92%)]	Loss: 0.059892Train Epoch: 2 [648064/702208 (92%)]	Loss: 0.088302Train Epoch: 2 [649088/702208 (92%)]	Loss: 0.130811Train Epoch: 2 [650112/702208 (93%)]	Loss: 0.046341
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7930 / 8283] 95 %
Accuracy of the network on test loader class  1: [4496 / 4517] 99 %

Writing model: iterations-1352320-total-97.08-class0-95.74000000000001-class1-99.53999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12050 / 12833] 93 %
Accuracy of the network on train loader class  1: [7025 / 7135] 98 %
Train Epoch: 2 [651008/702208 (93%)]	Loss: 0.102403Train Epoch: 2 [652032/702208 (93%)]	Loss: 0.146355Train Epoch: 2 [653056/702208 (93%)]	Loss: 0.130413Train Epoch: 2 [654080/702208 (93%)]	Loss: 0.118760Train Epoch: 2 [655104/702208 (93%)]	Loss: 0.090650Train Epoch: 2 [656000/702208 (93%)]	Loss: 0.074558Train Epoch: 2 [656128/702208 (93%)]	Loss: 0.118581Train Epoch: 2 [657024/702208 (94%)]	Loss: 0.153212Train Epoch: 2 [658048/702208 (94%)]	Loss: 0.139396Train Epoch: 2 [659072/702208 (94%)]	Loss: 0.164693Train Epoch: 2 [660096/702208 (94%)]	Loss: 0.084758Train Epoch: 2 [661120/702208 (94%)]	Loss: 0.057620Train Epoch: 2 [662016/702208 (94%)]	Loss: 0.097939Train Epoch: 2 [663040/702208 (94%)]	Loss: 0.042733Train Epoch: 2 [664064/702208 (95%)]	Loss: 0.088107Train Epoch: 2 [665088/702208 (95%)]	Loss: 0.078671Train Epoch: 2 [666112/702208 (95%)]	Loss: 0.056054Train Epoch: 2 [667008/702208 (95%)]	Loss: 0.071321Train Epoch: 2 [668032/702208 (95%)]	Loss: 0.111073Train Epoch: 2 [669056/702208 (95%)]	Loss: 0.091567Train Epoch: 2 [670080/702208 (95%)]	Loss: 0.091784Train Epoch: 2 [671104/702208 (96%)]	Loss: 0.045501Train Epoch: 2 [672000/702208 (96%)]	Loss: 0.039285Train Epoch: 2 [672128/702208 (96%)]	Loss: 0.095962Train Epoch: 2 [673024/702208 (96%)]	Loss: 0.057501Train Epoch: 2 [674048/702208 (96%)]	Loss: 0.106742Train Epoch: 2 [675072/702208 (96%)]	Loss: 0.082390
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7916 / 8283] 95 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-1377280-total-96.96000000000001-class0-95.57-class1-99.51
Train Epoch: 2 [676096/702208 (96%)]	Loss: 0.042381Train Epoch: 2 [677120/702208 (96%)]	Loss: 0.061173Train Epoch: 2 [678016/702208 (97%)]	Loss: 0.051524Train Epoch: 2 [679040/702208 (97%)]	Loss: 0.098675Train Epoch: 2 [680064/702208 (97%)]	Loss: 0.054295Train Epoch: 2 [681088/702208 (97%)]	Loss: 0.043625Train Epoch: 2 [682112/702208 (97%)]	Loss: 0.084477Train Epoch: 2 [683008/702208 (97%)]	Loss: 0.060468Train Epoch: 2 [684032/702208 (97%)]	Loss: 0.101708Train Epoch: 2 [685056/702208 (98%)]	Loss: 0.059726Train Epoch: 2 [686080/702208 (98%)]	Loss: 0.065218Train Epoch: 2 [687104/702208 (98%)]	Loss: 0.078251Train Epoch: 2 [688000/702208 (98%)]	Loss: 0.051263Train Epoch: 2 [688128/702208 (98%)]	Loss: 0.051899Train Epoch: 2 [689024/702208 (98%)]	Loss: 0.054882Train Epoch: 2 [690048/702208 (98%)]	Loss: 0.122147Train Epoch: 2 [691072/702208 (98%)]	Loss: 0.029152Train Epoch: 2 [692096/702208 (99%)]	Loss: 0.028926Train Epoch: 2 [693120/702208 (99%)]	Loss: 0.117686Train Epoch: 2 [694016/702208 (99%)]	Loss: 0.085269Train Epoch: 2 [695040/702208 (99%)]	Loss: 0.061427Train Epoch: 2 [696064/702208 (99%)]	Loss: 0.139039Train Epoch: 2 [697088/702208 (99%)]	Loss: 0.077392Train Epoch: 2 [698112/702208 (99%)]	Loss: 0.069245Train Epoch: 2 [699008/702208 (100%)]	Loss: 0.046827Train Epoch: 2 [700032/702208 (100%)]	Loss: 0.114392
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7755 / 8283] 93 %
Accuracy of the network on test loader class  1: [4493 / 4517] 99 %

Writing model: iterations-1402240-total-95.69-class0-93.63-class1-99.47

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 91 %
Accuracy of the network on train loader class  0: [11422 / 12833] 89 %
Accuracy of the network on train loader class  1: [6773 / 7135] 94 %
Train Epoch: 2 [701056/702208 (100%)]	Loss: 0.063814Train Epoch: 2 [702080/702208 (100%)]	Loss: 0.060717
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7996 / 8283] 96 %
Accuracy of the network on test loader class  1: [4437 / 4517] 98 %
Train Epoch: 3 [1024/702208 (0%)]	Loss: 0.094347Train Epoch: 3 [2048/702208 (0%)]	Loss: 0.076403Train Epoch: 3 [3072/702208 (0%)]	Loss: 0.050034Train Epoch: 3 [4096/702208 (1%)]	Loss: 0.069699Train Epoch: 3 [5120/702208 (1%)]	Loss: 0.087339Train Epoch: 3 [6016/702208 (1%)]	Loss: 0.118351Train Epoch: 3 [7040/702208 (1%)]	Loss: 0.060490Train Epoch: 3 [8064/702208 (1%)]	Loss: 0.053828Train Epoch: 3 [9088/702208 (1%)]	Loss: 0.090871Train Epoch: 3 [10112/702208 (1%)]	Loss: 0.108518Train Epoch: 3 [11008/702208 (2%)]	Loss: 0.096238Train Epoch: 3 [12032/702208 (2%)]	Loss: 0.093029Train Epoch: 3 [13056/702208 (2%)]	Loss: 0.090965Train Epoch: 3 [14080/702208 (2%)]	Loss: 0.100671Train Epoch: 3 [15104/702208 (2%)]	Loss: 0.113189Train Epoch: 3 [16000/702208 (2%)]	Loss: 0.044533Train Epoch: 3 [16128/702208 (2%)]	Loss: 0.194139Train Epoch: 3 [17024/702208 (2%)]	Loss: 0.061891Train Epoch: 3 [18048/702208 (3%)]	Loss: 0.036995Train Epoch: 3 [19072/702208 (3%)]	Loss: 0.113317Train Epoch: 3 [20096/702208 (3%)]	Loss: 0.119132Train Epoch: 3 [21120/702208 (3%)]	Loss: 0.121383Train Epoch: 3 [22016/702208 (3%)]	Loss: 0.060322Train Epoch: 3 [23040/702208 (3%)]	Loss: 0.119711Train Epoch: 3 [24064/702208 (3%)]	Loss: 0.103904Train Epoch: 3 [25088/702208 (4%)]	Loss: 0.108900
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7908 / 8283] 95 %
Accuracy of the network on test loader class  1: [4499 / 4517] 99 %

Writing model: iterations-1429504-total-96.93-class0-95.47-class1-99.6
Train Epoch: 3 [26112/702208 (4%)]	Loss: 0.157981Train Epoch: 3 [27008/702208 (4%)]	Loss: 0.061494Train Epoch: 3 [28032/702208 (4%)]	Loss: 0.139015Train Epoch: 3 [29056/702208 (4%)]	Loss: 0.092933Train Epoch: 3 [30080/702208 (4%)]	Loss: 0.135111Train Epoch: 3 [31104/702208 (4%)]	Loss: 0.049463Train Epoch: 3 [32000/702208 (5%)]	Loss: 0.080637Train Epoch: 3 [32128/702208 (5%)]	Loss: 0.105778Train Epoch: 3 [33024/702208 (5%)]	Loss: 0.050583Train Epoch: 3 [34048/702208 (5%)]	Loss: 0.137683Train Epoch: 3 [35072/702208 (5%)]	Loss: 0.080597Train Epoch: 3 [36096/702208 (5%)]	Loss: 0.094004Train Epoch: 3 [37120/702208 (5%)]	Loss: 0.116315Train Epoch: 3 [38016/702208 (5%)]	Loss: 0.107587Train Epoch: 3 [39040/702208 (6%)]	Loss: 0.059077Train Epoch: 3 [40064/702208 (6%)]	Loss: 0.154299Train Epoch: 3 [41088/702208 (6%)]	Loss: 0.096616Train Epoch: 3 [42112/702208 (6%)]	Loss: 0.050430Train Epoch: 3 [43008/702208 (6%)]	Loss: 0.161707Train Epoch: 3 [44032/702208 (6%)]	Loss: 0.079200Train Epoch: 3 [45056/702208 (6%)]	Loss: 0.171726Train Epoch: 3 [46080/702208 (7%)]	Loss: 0.100164Train Epoch: 3 [47104/702208 (7%)]	Loss: 0.077967Train Epoch: 3 [48000/702208 (7%)]	Loss: 0.042395Train Epoch: 3 [48128/702208 (7%)]	Loss: 0.128596Train Epoch: 3 [49024/702208 (7%)]	Loss: 0.051982Train Epoch: 3 [50048/702208 (7%)]	Loss: 0.073563
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8025 / 8283] 96 %
Accuracy of the network on test loader class  1: [4478 / 4517] 99 %

Writing model: iterations-1454464-total-97.68-class0-96.89-class1-99.14

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11913 / 12833] 92 %
Accuracy of the network on train loader class  1: [6895 / 7135] 96 %
Train Epoch: 3 [51072/702208 (7%)]	Loss: 0.070630Train Epoch: 3 [52096/702208 (7%)]	Loss: 0.080661Train Epoch: 3 [53120/702208 (8%)]	Loss: 0.045747Train Epoch: 3 [54016/702208 (8%)]	Loss: 0.069051Train Epoch: 3 [55040/702208 (8%)]	Loss: 0.097381Train Epoch: 3 [56064/702208 (8%)]	Loss: 0.036496Train Epoch: 3 [57088/702208 (8%)]	Loss: 0.117656Train Epoch: 3 [58112/702208 (8%)]	Loss: 0.058896Train Epoch: 3 [59008/702208 (8%)]	Loss: 0.099876Train Epoch: 3 [60032/702208 (9%)]	Loss: 0.057736Train Epoch: 3 [61056/702208 (9%)]	Loss: 0.159213Train Epoch: 3 [62080/702208 (9%)]	Loss: 0.128045Train Epoch: 3 [63104/702208 (9%)]	Loss: 0.103961Train Epoch: 3 [64000/702208 (9%)]	Loss: 0.137002Train Epoch: 3 [64128/702208 (9%)]	Loss: 0.053477Train Epoch: 3 [65024/702208 (9%)]	Loss: 0.150328Train Epoch: 3 [66048/702208 (9%)]	Loss: 0.057772Train Epoch: 3 [67072/702208 (10%)]	Loss: 0.058781Train Epoch: 3 [68096/702208 (10%)]	Loss: 0.118180Train Epoch: 3 [69120/702208 (10%)]	Loss: 0.132613Train Epoch: 3 [70016/702208 (10%)]	Loss: 0.154405Train Epoch: 3 [71040/702208 (10%)]	Loss: 0.055077Train Epoch: 3 [72064/702208 (10%)]	Loss: 0.097856Train Epoch: 3 [73088/702208 (10%)]	Loss: 0.042017Train Epoch: 3 [74112/702208 (11%)]	Loss: 0.069282Train Epoch: 3 [75008/702208 (11%)]	Loss: 0.127582
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7969 / 8283] 96 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-1479424-total-97.38-class0-96.21-class1-99.51
Train Epoch: 3 [76032/702208 (11%)]	Loss: 0.111677Train Epoch: 3 [77056/702208 (11%)]	Loss: 0.102480Train Epoch: 3 [78080/702208 (11%)]	Loss: 0.077558Train Epoch: 3 [79104/702208 (11%)]	Loss: 0.122727Train Epoch: 3 [80000/702208 (11%)]	Loss: 0.062262Train Epoch: 3 [80128/702208 (11%)]	Loss: 0.164063Train Epoch: 3 [81024/702208 (12%)]	Loss: 0.063185Train Epoch: 3 [82048/702208 (12%)]	Loss: 0.111683Train Epoch: 3 [83072/702208 (12%)]	Loss: 0.082056Train Epoch: 3 [84096/702208 (12%)]	Loss: 0.106019Train Epoch: 3 [85120/702208 (12%)]	Loss: 0.062740Train Epoch: 3 [86016/702208 (12%)]	Loss: 0.052040Train Epoch: 3 [87040/702208 (12%)]	Loss: 0.046442Train Epoch: 3 [88064/702208 (13%)]	Loss: 0.102334Train Epoch: 3 [89088/702208 (13%)]	Loss: 0.057344Train Epoch: 3 [90112/702208 (13%)]	Loss: 0.107368Train Epoch: 3 [91008/702208 (13%)]	Loss: 0.052355Train Epoch: 3 [92032/702208 (13%)]	Loss: 0.092073Train Epoch: 3 [93056/702208 (13%)]	Loss: 0.122581Train Epoch: 3 [94080/702208 (13%)]	Loss: 0.116261Train Epoch: 3 [95104/702208 (14%)]	Loss: 0.104125Train Epoch: 3 [96000/702208 (14%)]	Loss: 0.083038Train Epoch: 3 [96128/702208 (14%)]	Loss: 0.070734Train Epoch: 3 [97024/702208 (14%)]	Loss: 0.104674Train Epoch: 3 [98048/702208 (14%)]	Loss: 0.118388Train Epoch: 3 [99072/702208 (14%)]	Loss: 0.038168Train Epoch: 3 [100096/702208 (14%)]	Loss: 0.076460
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8037 / 8283] 97 %
Accuracy of the network on test loader class  1: [4489 / 4517] 99 %

Writing model: iterations-1504512-total-97.86-class0-97.03-class1-99.38

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12194 / 12833] 95 %
Accuracy of the network on train loader class  1: [6961 / 7135] 97 %
Train Epoch: 3 [101120/702208 (14%)]	Loss: 0.080522Train Epoch: 3 [102016/702208 (15%)]	Loss: 0.139132Train Epoch: 3 [103040/702208 (15%)]	Loss: 0.128010Train Epoch: 3 [104064/702208 (15%)]	Loss: 0.083197Train Epoch: 3 [105088/702208 (15%)]	Loss: 0.133658Train Epoch: 3 [106112/702208 (15%)]	Loss: 0.081844Train Epoch: 3 [107008/702208 (15%)]	Loss: 0.039729Train Epoch: 3 [108032/702208 (15%)]	Loss: 0.033878Train Epoch: 3 [109056/702208 (16%)]	Loss: 0.165261Train Epoch: 3 [110080/702208 (16%)]	Loss: 0.125677Train Epoch: 3 [111104/702208 (16%)]	Loss: 0.129095Train Epoch: 3 [112000/702208 (16%)]	Loss: 0.085866Train Epoch: 3 [112128/702208 (16%)]	Loss: 0.140050Train Epoch: 3 [113024/702208 (16%)]	Loss: 0.052039Train Epoch: 3 [114048/702208 (16%)]	Loss: 0.097345Train Epoch: 3 [115072/702208 (16%)]	Loss: 0.092901Train Epoch: 3 [116096/702208 (17%)]	Loss: 0.098092Train Epoch: 3 [117120/702208 (17%)]	Loss: 0.052414Train Epoch: 3 [118016/702208 (17%)]	Loss: 0.062266Train Epoch: 3 [119040/702208 (17%)]	Loss: 0.095740Train Epoch: 3 [120064/702208 (17%)]	Loss: 0.085198Train Epoch: 3 [121088/702208 (17%)]	Loss: 0.061254Train Epoch: 3 [122112/702208 (17%)]	Loss: 0.076647Train Epoch: 3 [123008/702208 (18%)]	Loss: 0.082732Train Epoch: 3 [124032/702208 (18%)]	Loss: 0.063583Train Epoch: 3 [125056/702208 (18%)]	Loss: 0.048111
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7964 / 8283] 96 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-1529472-total-97.34-class0-96.15-class1-99.51
Train Epoch: 3 [126080/702208 (18%)]	Loss: 0.130872Train Epoch: 3 [127104/702208 (18%)]	Loss: 0.044909Train Epoch: 3 [128000/702208 (18%)]	Loss: 0.054667Train Epoch: 3 [128128/702208 (18%)]	Loss: 0.120910Train Epoch: 3 [129024/702208 (18%)]	Loss: 0.057066Train Epoch: 3 [130048/702208 (19%)]	Loss: 0.096928Train Epoch: 3 [131072/702208 (19%)]	Loss: 0.144432Train Epoch: 3 [132096/702208 (19%)]	Loss: 0.062505Train Epoch: 3 [133120/702208 (19%)]	Loss: 0.079157Train Epoch: 3 [134016/702208 (19%)]	Loss: 0.051667Train Epoch: 3 [135040/702208 (19%)]	Loss: 0.058029Train Epoch: 3 [136064/702208 (19%)]	Loss: 0.088900Train Epoch: 3 [137088/702208 (20%)]	Loss: 0.251813Train Epoch: 3 [138112/702208 (20%)]	Loss: 0.044085Train Epoch: 3 [139008/702208 (20%)]	Loss: 0.060913Train Epoch: 3 [140032/702208 (20%)]	Loss: 0.085779Train Epoch: 3 [141056/702208 (20%)]	Loss: 0.070403Train Epoch: 3 [142080/702208 (20%)]	Loss: 0.173037Train Epoch: 3 [143104/702208 (20%)]	Loss: 0.119770Train Epoch: 3 [144000/702208 (21%)]	Loss: 0.125036Train Epoch: 3 [144128/702208 (21%)]	Loss: 0.204585Train Epoch: 3 [145024/702208 (21%)]	Loss: 0.115458Train Epoch: 3 [146048/702208 (21%)]	Loss: 0.069813Train Epoch: 3 [147072/702208 (21%)]	Loss: 0.058197Train Epoch: 3 [148096/702208 (21%)]	Loss: 0.052748Train Epoch: 3 [149120/702208 (21%)]	Loss: 0.083338Train Epoch: 3 [150016/702208 (21%)]	Loss: 0.086952
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7810 / 8283] 94 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-1554432-total-96.22-class0-94.28999999999999-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11763 / 12833] 91 %
Accuracy of the network on train loader class  1: [7086 / 7135] 99 %
Train Epoch: 3 [151040/702208 (22%)]	Loss: 0.055817Train Epoch: 3 [152064/702208 (22%)]	Loss: 0.147785Train Epoch: 3 [153088/702208 (22%)]	Loss: 0.110898Train Epoch: 3 [154112/702208 (22%)]	Loss: 0.081095Train Epoch: 3 [155008/702208 (22%)]	Loss: 0.069324Train Epoch: 3 [156032/702208 (22%)]	Loss: 0.126148Train Epoch: 3 [157056/702208 (22%)]	Loss: 0.135738Train Epoch: 3 [158080/702208 (23%)]	Loss: 0.085964Train Epoch: 3 [159104/702208 (23%)]	Loss: 0.078036Train Epoch: 3 [160000/702208 (23%)]	Loss: 0.118706Train Epoch: 3 [160128/702208 (23%)]	Loss: 0.191051Train Epoch: 3 [161024/702208 (23%)]	Loss: 0.102412Train Epoch: 3 [162048/702208 (23%)]	Loss: 0.113151Train Epoch: 3 [163072/702208 (23%)]	Loss: 0.071133Train Epoch: 3 [164096/702208 (23%)]	Loss: 0.052124Train Epoch: 3 [165120/702208 (24%)]	Loss: 0.070740Train Epoch: 3 [166016/702208 (24%)]	Loss: 0.073079Train Epoch: 3 [167040/702208 (24%)]	Loss: 0.115338Train Epoch: 3 [168064/702208 (24%)]	Loss: 0.075719Train Epoch: 3 [169088/702208 (24%)]	Loss: 0.056142Train Epoch: 3 [170112/702208 (24%)]	Loss: 0.173855Train Epoch: 3 [171008/702208 (24%)]	Loss: 0.052845Train Epoch: 3 [172032/702208 (24%)]	Loss: 0.156263Train Epoch: 3 [173056/702208 (25%)]	Loss: 0.108943Train Epoch: 3 [174080/702208 (25%)]	Loss: 0.059794Train Epoch: 3 [175104/702208 (25%)]	Loss: 0.037672
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8006 / 8283] 96 %
Accuracy of the network on test loader class  1: [4487 / 4517] 99 %

Writing model: iterations-1579520-total-97.6-class0-96.66-class1-99.33999999999999
Train Epoch: 3 [176000/702208 (25%)]	Loss: 0.052402Train Epoch: 3 [176128/702208 (25%)]	Loss: 0.073167Train Epoch: 3 [177024/702208 (25%)]	Loss: 0.068038Train Epoch: 3 [178048/702208 (25%)]	Loss: 0.080532Train Epoch: 3 [179072/702208 (26%)]	Loss: 0.172089Train Epoch: 3 [180096/702208 (26%)]	Loss: 0.058834Train Epoch: 3 [181120/702208 (26%)]	Loss: 0.116186Train Epoch: 3 [182016/702208 (26%)]	Loss: 0.071945Train Epoch: 3 [183040/702208 (26%)]	Loss: 0.076614Train Epoch: 3 [184064/702208 (26%)]	Loss: 0.108715Train Epoch: 3 [185088/702208 (26%)]	Loss: 0.121469Train Epoch: 3 [186112/702208 (27%)]	Loss: 0.108844Train Epoch: 3 [187008/702208 (27%)]	Loss: 0.109628Train Epoch: 3 [188032/702208 (27%)]	Loss: 0.052114Train Epoch: 3 [189056/702208 (27%)]	Loss: 0.054695Train Epoch: 3 [190080/702208 (27%)]	Loss: 0.104971Train Epoch: 3 [191104/702208 (27%)]	Loss: 0.054785Train Epoch: 3 [192000/702208 (27%)]	Loss: 0.115870Train Epoch: 3 [192128/702208 (27%)]	Loss: 0.061680Train Epoch: 3 [193024/702208 (27%)]	Loss: 0.100682Train Epoch: 3 [194048/702208 (28%)]	Loss: 0.031086Train Epoch: 3 [195072/702208 (28%)]	Loss: 0.069485Train Epoch: 3 [196096/702208 (28%)]	Loss: 0.078411Train Epoch: 3 [197120/702208 (28%)]	Loss: 0.049803Train Epoch: 3 [198016/702208 (28%)]	Loss: 0.048190Train Epoch: 3 [199040/702208 (28%)]	Loss: 0.072897Train Epoch: 3 [200064/702208 (28%)]	Loss: 0.030989
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8052 / 8283] 97 %
Accuracy of the network on test loader class  1: [4486 / 4517] 99 %

Writing model: iterations-1604480-total-97.95-class0-97.21-class1-99.31

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12316 / 12833] 95 %
Accuracy of the network on train loader class  1: [7003 / 7135] 98 %
Train Epoch: 3 [201088/702208 (29%)]	Loss: 0.100232Train Epoch: 3 [202112/702208 (29%)]	Loss: 0.089791Train Epoch: 3 [203008/702208 (29%)]	Loss: 0.061197Train Epoch: 3 [204032/702208 (29%)]	Loss: 0.057437Train Epoch: 3 [205056/702208 (29%)]	Loss: 0.042455Train Epoch: 3 [206080/702208 (29%)]	Loss: 0.064294Train Epoch: 3 [207104/702208 (29%)]	Loss: 0.051727Train Epoch: 3 [208000/702208 (30%)]	Loss: 0.091074Train Epoch: 3 [208128/702208 (30%)]	Loss: 0.129537Train Epoch: 3 [209024/702208 (30%)]	Loss: 0.037491Train Epoch: 3 [210048/702208 (30%)]	Loss: 0.040507Train Epoch: 3 [211072/702208 (30%)]	Loss: 0.060683Train Epoch: 3 [212096/702208 (30%)]	Loss: 0.068554Train Epoch: 3 [213120/702208 (30%)]	Loss: 0.090398Train Epoch: 3 [214016/702208 (30%)]	Loss: 0.037100Train Epoch: 3 [215040/702208 (31%)]	Loss: 0.098959Train Epoch: 3 [216064/702208 (31%)]	Loss: 0.138416Train Epoch: 3 [217088/702208 (31%)]	Loss: 0.065414Train Epoch: 3 [218112/702208 (31%)]	Loss: 0.053926Train Epoch: 3 [219008/702208 (31%)]	Loss: 0.082140Train Epoch: 3 [220032/702208 (31%)]	Loss: 0.064026Train Epoch: 3 [221056/702208 (31%)]	Loss: 0.097583Train Epoch: 3 [222080/702208 (32%)]	Loss: 0.088941Train Epoch: 3 [223104/702208 (32%)]	Loss: 0.081128Train Epoch: 3 [224000/702208 (32%)]	Loss: 0.123819Train Epoch: 3 [224128/702208 (32%)]	Loss: 0.042622Train Epoch: 3 [225024/702208 (32%)]	Loss: 0.033510
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7858 / 8283] 94 %
Accuracy of the network on test loader class  1: [4501 / 4517] 99 %

Writing model: iterations-1629440-total-96.55-class0-94.87-class1-99.65
Train Epoch: 3 [226048/702208 (32%)]	Loss: 0.053919Train Epoch: 3 [227072/702208 (32%)]	Loss: 0.137449Train Epoch: 3 [228096/702208 (32%)]	Loss: 0.091710Train Epoch: 3 [229120/702208 (33%)]	Loss: 0.064834Train Epoch: 3 [230016/702208 (33%)]	Loss: 0.044313Train Epoch: 3 [231040/702208 (33%)]	Loss: 0.111088Train Epoch: 3 [232064/702208 (33%)]	Loss: 0.087616Train Epoch: 3 [233088/702208 (33%)]	Loss: 0.088939Train Epoch: 3 [234112/702208 (33%)]	Loss: 0.188248Train Epoch: 3 [235008/702208 (33%)]	Loss: 0.027202Train Epoch: 3 [236032/702208 (34%)]	Loss: 0.078750Train Epoch: 3 [237056/702208 (34%)]	Loss: 0.065587Train Epoch: 3 [238080/702208 (34%)]	Loss: 0.098361Train Epoch: 3 [239104/702208 (34%)]	Loss: 0.062500Train Epoch: 3 [240000/702208 (34%)]	Loss: 0.061559Train Epoch: 3 [240128/702208 (34%)]	Loss: 0.080988Train Epoch: 3 [241024/702208 (34%)]	Loss: 0.070034Train Epoch: 3 [242048/702208 (34%)]	Loss: 0.059441Train Epoch: 3 [243072/702208 (35%)]	Loss: 0.153167Train Epoch: 3 [244096/702208 (35%)]	Loss: 0.020755Train Epoch: 3 [245120/702208 (35%)]	Loss: 0.044935Train Epoch: 3 [246016/702208 (35%)]	Loss: 0.089077Train Epoch: 3 [247040/702208 (35%)]	Loss: 0.138195Train Epoch: 3 [248064/702208 (35%)]	Loss: 0.058270Train Epoch: 3 [249088/702208 (35%)]	Loss: 0.086108Train Epoch: 3 [250112/702208 (36%)]	Loss: 0.127886
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7932 / 8283] 95 %
Accuracy of the network on test loader class  1: [4501 / 4517] 99 %

Writing model: iterations-1654528-total-97.13000000000001-class0-95.76-class1-99.65

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12180 / 12833] 94 %
Accuracy of the network on train loader class  1: [7048 / 7135] 98 %
Train Epoch: 3 [251008/702208 (36%)]	Loss: 0.057108Train Epoch: 3 [252032/702208 (36%)]	Loss: 0.100720Train Epoch: 3 [253056/702208 (36%)]	Loss: 0.031340Train Epoch: 3 [254080/702208 (36%)]	Loss: 0.141080Train Epoch: 3 [255104/702208 (36%)]	Loss: 0.050962Train Epoch: 3 [256000/702208 (36%)]	Loss: 0.042882Train Epoch: 3 [256128/702208 (36%)]	Loss: 0.097496Train Epoch: 3 [257024/702208 (37%)]	Loss: 0.028222Train Epoch: 3 [258048/702208 (37%)]	Loss: 0.087156Train Epoch: 3 [259072/702208 (37%)]	Loss: 0.018794Train Epoch: 3 [260096/702208 (37%)]	Loss: 0.203486Train Epoch: 3 [261120/702208 (37%)]	Loss: 0.059068Train Epoch: 3 [262016/702208 (37%)]	Loss: 0.070046Train Epoch: 3 [263040/702208 (37%)]	Loss: 0.048821Train Epoch: 3 [264064/702208 (38%)]	Loss: 0.096474Train Epoch: 3 [265088/702208 (38%)]	Loss: 0.209734Train Epoch: 3 [266112/702208 (38%)]	Loss: 0.057559Train Epoch: 3 [267008/702208 (38%)]	Loss: 0.067751Train Epoch: 3 [268032/702208 (38%)]	Loss: 0.055809Train Epoch: 3 [269056/702208 (38%)]	Loss: 0.131959Train Epoch: 3 [270080/702208 (38%)]	Loss: 0.137154Train Epoch: 3 [271104/702208 (39%)]	Loss: 0.069927Train Epoch: 3 [272000/702208 (39%)]	Loss: 0.048616Train Epoch: 3 [272128/702208 (39%)]	Loss: 0.168636Train Epoch: 3 [273024/702208 (39%)]	Loss: 0.075968Train Epoch: 3 [274048/702208 (39%)]	Loss: 0.069851Train Epoch: 3 [275072/702208 (39%)]	Loss: 0.093253
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7948 / 8283] 95 %
Accuracy of the network on test loader class  1: [4496 / 4517] 99 %

Writing model: iterations-1679488-total-97.22-class0-95.96000000000001-class1-99.53999999999999
Train Epoch: 3 [276096/702208 (39%)]	Loss: 0.095518Train Epoch: 3 [277120/702208 (39%)]	Loss: 0.058751Train Epoch: 3 [278016/702208 (40%)]	Loss: 0.057573Train Epoch: 3 [279040/702208 (40%)]	Loss: 0.095270Train Epoch: 3 [280064/702208 (40%)]	Loss: 0.072457Train Epoch: 3 [281088/702208 (40%)]	Loss: 0.042693Train Epoch: 3 [282112/702208 (40%)]	Loss: 0.024812Train Epoch: 3 [283008/702208 (40%)]	Loss: 0.019373Train Epoch: 3 [284032/702208 (40%)]	Loss: 0.090834Train Epoch: 3 [285056/702208 (41%)]	Loss: 0.111678Train Epoch: 3 [286080/702208 (41%)]	Loss: 0.158260Train Epoch: 3 [287104/702208 (41%)]	Loss: 0.048225Train Epoch: 3 [288000/702208 (41%)]	Loss: 0.015916Train Epoch: 3 [288128/702208 (41%)]	Loss: 0.179490Train Epoch: 3 [289024/702208 (41%)]	Loss: 0.057855Train Epoch: 3 [290048/702208 (41%)]	Loss: 0.172857Train Epoch: 3 [291072/702208 (41%)]	Loss: 0.127980Train Epoch: 3 [292096/702208 (42%)]	Loss: 0.082948Train Epoch: 3 [293120/702208 (42%)]	Loss: 0.126083Train Epoch: 3 [294016/702208 (42%)]	Loss: 0.026096Train Epoch: 3 [295040/702208 (42%)]	Loss: 0.074998Train Epoch: 3 [296064/702208 (42%)]	Loss: 0.087748Train Epoch: 3 [297088/702208 (42%)]	Loss: 0.093524Train Epoch: 3 [298112/702208 (42%)]	Loss: 0.139539Train Epoch: 3 [299008/702208 (43%)]	Loss: 0.133273Train Epoch: 3 [300032/702208 (43%)]	Loss: 0.046261
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8074 / 8283] 97 %
Accuracy of the network on test loader class  1: [4484 / 4517] 99 %

Writing model: iterations-1704448-total-98.11-class0-97.48-class1-99.27

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12174 / 12833] 94 %
Accuracy of the network on train loader class  1: [7060 / 7135] 98 %
Train Epoch: 3 [301056/702208 (43%)]	Loss: 0.030329Train Epoch: 3 [302080/702208 (43%)]	Loss: 0.077575Train Epoch: 3 [303104/702208 (43%)]	Loss: 0.070758Train Epoch: 3 [304000/702208 (43%)]	Loss: 0.079953Train Epoch: 3 [304128/702208 (43%)]	Loss: 0.051313Train Epoch: 3 [305024/702208 (43%)]	Loss: 0.094108Train Epoch: 3 [306048/702208 (44%)]	Loss: 0.118386Train Epoch: 3 [307072/702208 (44%)]	Loss: 0.032222Train Epoch: 3 [308096/702208 (44%)]	Loss: 0.080022Train Epoch: 3 [309120/702208 (44%)]	Loss: 0.104005Train Epoch: 3 [310016/702208 (44%)]	Loss: 0.041654Train Epoch: 3 [311040/702208 (44%)]	Loss: 0.090266Train Epoch: 3 [312064/702208 (44%)]	Loss: 0.063950Train Epoch: 3 [313088/702208 (45%)]	Loss: 0.104234Train Epoch: 3 [314112/702208 (45%)]	Loss: 0.082950Train Epoch: 3 [315008/702208 (45%)]	Loss: 0.019375Train Epoch: 3 [316032/702208 (45%)]	Loss: 0.085343Train Epoch: 3 [317056/702208 (45%)]	Loss: 0.086554Train Epoch: 3 [318080/702208 (45%)]	Loss: 0.054749Train Epoch: 3 [319104/702208 (45%)]	Loss: 0.073736Train Epoch: 3 [320000/702208 (46%)]	Loss: 0.054889Train Epoch: 3 [320128/702208 (46%)]	Loss: 0.043426Train Epoch: 3 [321024/702208 (46%)]	Loss: 0.028713Train Epoch: 3 [322048/702208 (46%)]	Loss: 0.057552Train Epoch: 3 [323072/702208 (46%)]	Loss: 0.059918Train Epoch: 3 [324096/702208 (46%)]	Loss: 0.079287Train Epoch: 3 [325120/702208 (46%)]	Loss: 0.045156
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7981 / 8283] 96 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-1729536-total-97.47-class0-96.35000000000001-class1-99.51
Train Epoch: 3 [326016/702208 (46%)]	Loss: 0.059780Train Epoch: 3 [327040/702208 (47%)]	Loss: 0.058668Train Epoch: 3 [328064/702208 (47%)]	Loss: 0.118599Train Epoch: 3 [329088/702208 (47%)]	Loss: 0.095885Train Epoch: 3 [330112/702208 (47%)]	Loss: 0.148255Train Epoch: 3 [331008/702208 (47%)]	Loss: 0.080723Train Epoch: 3 [332032/702208 (47%)]	Loss: 0.088307Train Epoch: 3 [333056/702208 (47%)]	Loss: 0.080521Train Epoch: 3 [334080/702208 (48%)]	Loss: 0.073569Train Epoch: 3 [335104/702208 (48%)]	Loss: 0.070039Train Epoch: 3 [336000/702208 (48%)]	Loss: 0.071414Train Epoch: 3 [336128/702208 (48%)]	Loss: 0.065001Train Epoch: 3 [337024/702208 (48%)]	Loss: 0.057844Train Epoch: 3 [338048/702208 (48%)]	Loss: 0.141586Train Epoch: 3 [339072/702208 (48%)]	Loss: 0.108516Train Epoch: 3 [340096/702208 (48%)]	Loss: 0.063075Train Epoch: 3 [341120/702208 (49%)]	Loss: 0.092505Train Epoch: 3 [342016/702208 (49%)]	Loss: 0.102431Train Epoch: 3 [343040/702208 (49%)]	Loss: 0.067424Train Epoch: 3 [344064/702208 (49%)]	Loss: 0.080001Train Epoch: 3 [345088/702208 (49%)]	Loss: 0.149078Train Epoch: 3 [346112/702208 (49%)]	Loss: 0.073656Train Epoch: 3 [347008/702208 (49%)]	Loss: 0.139541Train Epoch: 3 [348032/702208 (50%)]	Loss: 0.062332Train Epoch: 3 [349056/702208 (50%)]	Loss: 0.067250Train Epoch: 3 [350080/702208 (50%)]	Loss: 0.068989
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7742 / 8283] 93 %
Accuracy of the network on test loader class  1: [4497 / 4517] 99 %

Writing model: iterations-1754496-total-95.62-class0-93.47-class1-99.56

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12128 / 12833] 94 %
Accuracy of the network on train loader class  1: [7021 / 7135] 98 %
Train Epoch: 3 [351104/702208 (50%)]	Loss: 0.126712Train Epoch: 3 [352000/702208 (50%)]	Loss: 0.070840Train Epoch: 3 [352128/702208 (50%)]	Loss: 0.065369Train Epoch: 3 [353024/702208 (50%)]	Loss: 0.049575Train Epoch: 3 [354048/702208 (50%)]	Loss: 0.113015Train Epoch: 3 [355072/702208 (51%)]	Loss: 0.117076Train Epoch: 3 [356096/702208 (51%)]	Loss: 0.069409Train Epoch: 3 [357120/702208 (51%)]	Loss: 0.039678Train Epoch: 3 [358016/702208 (51%)]	Loss: 0.139620Train Epoch: 3 [359040/702208 (51%)]	Loss: 0.093286Train Epoch: 3 [360064/702208 (51%)]	Loss: 0.145834Train Epoch: 3 [361088/702208 (51%)]	Loss: 0.057808Train Epoch: 3 [362112/702208 (52%)]	Loss: 0.065715Train Epoch: 3 [363008/702208 (52%)]	Loss: 0.033806Train Epoch: 3 [364032/702208 (52%)]	Loss: 0.065373Train Epoch: 3 [365056/702208 (52%)]	Loss: 0.022915Train Epoch: 3 [366080/702208 (52%)]	Loss: 0.085920Train Epoch: 3 [367104/702208 (52%)]	Loss: 0.133083Train Epoch: 3 [368000/702208 (52%)]	Loss: 0.090680Train Epoch: 3 [368128/702208 (52%)]	Loss: 0.057484Train Epoch: 3 [369024/702208 (53%)]	Loss: 0.145722Train Epoch: 3 [370048/702208 (53%)]	Loss: 0.043645Train Epoch: 3 [371072/702208 (53%)]	Loss: 0.064808Train Epoch: 3 [372096/702208 (53%)]	Loss: 0.067075Train Epoch: 3 [373120/702208 (53%)]	Loss: 0.054531Train Epoch: 3 [374016/702208 (53%)]	Loss: 0.063815Train Epoch: 3 [375040/702208 (53%)]	Loss: 0.117875
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7965 / 8283] 96 %
Accuracy of the network on test loader class  1: [4497 / 4517] 99 %

Writing model: iterations-1779456-total-97.36-class0-96.16-class1-99.56
Train Epoch: 3 [376064/702208 (54%)]	Loss: 0.059648Train Epoch: 3 [377088/702208 (54%)]	Loss: 0.063199Train Epoch: 3 [378112/702208 (54%)]	Loss: 0.050098Train Epoch: 3 [379008/702208 (54%)]	Loss: 0.056796Train Epoch: 3 [380032/702208 (54%)]	Loss: 0.056222Train Epoch: 3 [381056/702208 (54%)]	Loss: 0.090102Train Epoch: 3 [382080/702208 (54%)]	Loss: 0.088900Train Epoch: 3 [383104/702208 (55%)]	Loss: 0.094284Train Epoch: 3 [384000/702208 (55%)]	Loss: 0.060164Train Epoch: 3 [384128/702208 (55%)]	Loss: 0.094366Train Epoch: 3 [385024/702208 (55%)]	Loss: 0.100637Train Epoch: 3 [386048/702208 (55%)]	Loss: 0.034084Train Epoch: 3 [387072/702208 (55%)]	Loss: 0.048746Train Epoch: 3 [388096/702208 (55%)]	Loss: 0.058702Train Epoch: 3 [389120/702208 (55%)]	Loss: 0.091214Train Epoch: 3 [390016/702208 (56%)]	Loss: 0.029403Train Epoch: 3 [391040/702208 (56%)]	Loss: 0.086952Train Epoch: 3 [392064/702208 (56%)]	Loss: 0.052041Train Epoch: 3 [393088/702208 (56%)]	Loss: 0.063494Train Epoch: 3 [394112/702208 (56%)]	Loss: 0.030334Train Epoch: 3 [395008/702208 (56%)]	Loss: 0.026329Train Epoch: 3 [396032/702208 (56%)]	Loss: 0.076240Train Epoch: 3 [397056/702208 (57%)]	Loss: 0.060514Train Epoch: 3 [398080/702208 (57%)]	Loss: 0.112207Train Epoch: 3 [399104/702208 (57%)]	Loss: 0.062687Train Epoch: 3 [400000/702208 (57%)]	Loss: 0.043842
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8003 / 8283] 96 %
Accuracy of the network on test loader class  1: [4491 / 4517] 99 %

Writing model: iterations-1804416-total-97.61-class0-96.61999999999999-class1-99.42

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12196 / 12833] 95 %
Accuracy of the network on train loader class  1: [6925 / 7135] 97 %
Train Epoch: 3 [400128/702208 (57%)]	Loss: 0.085638
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7990 / 8283] 96 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-1804544-total-97.53-class0-96.46000000000001-class1-99.49

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12186 / 12833] 94 %
Accuracy of the network on train loader class  1: [6985 / 7135] 97 %
Train Epoch: 3 [401024/702208 (57%)]	Loss: 0.078525Train Epoch: 3 [402048/702208 (57%)]	Loss: 0.087351Train Epoch: 3 [403072/702208 (57%)]	Loss: 0.034479Train Epoch: 3 [404096/702208 (58%)]	Loss: 0.050853Train Epoch: 3 [405120/702208 (58%)]	Loss: 0.102738Train Epoch: 3 [406016/702208 (58%)]	Loss: 0.073355Train Epoch: 3 [407040/702208 (58%)]	Loss: 0.070202Train Epoch: 3 [408064/702208 (58%)]	Loss: 0.023809Train Epoch: 3 [409088/702208 (58%)]	Loss: 0.068340Train Epoch: 3 [410112/702208 (58%)]	Loss: 0.083116Train Epoch: 3 [411008/702208 (59%)]	Loss: 0.068816Train Epoch: 3 [412032/702208 (59%)]	Loss: 0.153724Train Epoch: 3 [413056/702208 (59%)]	Loss: 0.109494Train Epoch: 3 [414080/702208 (59%)]	Loss: 0.165065Train Epoch: 3 [415104/702208 (59%)]	Loss: 0.062625Train Epoch: 3 [416000/702208 (59%)]	Loss: 0.128650Train Epoch: 3 [416128/702208 (59%)]	Loss: 0.089306Train Epoch: 3 [417024/702208 (59%)]	Loss: 0.048596Train Epoch: 3 [418048/702208 (60%)]	Loss: 0.083703Train Epoch: 3 [419072/702208 (60%)]	Loss: 0.207761Train Epoch: 3 [420096/702208 (60%)]	Loss: 0.155417Train Epoch: 3 [421120/702208 (60%)]	Loss: 0.076488Train Epoch: 3 [422016/702208 (60%)]	Loss: 0.074384Train Epoch: 3 [423040/702208 (60%)]	Loss: 0.137079Train Epoch: 3 [424064/702208 (60%)]	Loss: 0.050949Train Epoch: 3 [425088/702208 (61%)]	Loss: 0.043359
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7892 / 8283] 95 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %

Writing model: iterations-1829504-total-96.83-class0-95.28-class1-99.67
Train Epoch: 3 [426112/702208 (61%)]	Loss: 0.070901Train Epoch: 3 [427008/702208 (61%)]	Loss: 0.153926Train Epoch: 3 [428032/702208 (61%)]	Loss: 0.102158Train Epoch: 3 [429056/702208 (61%)]	Loss: 0.049146Train Epoch: 3 [430080/702208 (61%)]	Loss: 0.098757Train Epoch: 3 [431104/702208 (61%)]	Loss: 0.046854Train Epoch: 3 [432000/702208 (62%)]	Loss: 0.034539Train Epoch: 3 [432128/702208 (62%)]	Loss: 0.046705Train Epoch: 3 [433024/702208 (62%)]	Loss: 0.069510Train Epoch: 3 [434048/702208 (62%)]	Loss: 0.088006Train Epoch: 3 [435072/702208 (62%)]	Loss: 0.084000Train Epoch: 3 [436096/702208 (62%)]	Loss: 0.050239Train Epoch: 3 [437120/702208 (62%)]	Loss: 0.092075Train Epoch: 3 [438016/702208 (62%)]	Loss: 0.058789Train Epoch: 3 [439040/702208 (63%)]	Loss: 0.094844Train Epoch: 3 [440064/702208 (63%)]	Loss: 0.058362Train Epoch: 3 [441088/702208 (63%)]	Loss: 0.090724Train Epoch: 3 [442112/702208 (63%)]	Loss: 0.056373Train Epoch: 3 [443008/702208 (63%)]	Loss: 0.067993Train Epoch: 3 [444032/702208 (63%)]	Loss: 0.139854Train Epoch: 3 [445056/702208 (63%)]	Loss: 0.161221Train Epoch: 3 [446080/702208 (64%)]	Loss: 0.045744Train Epoch: 3 [447104/702208 (64%)]	Loss: 0.064698Train Epoch: 3 [448000/702208 (64%)]	Loss: 0.066453Train Epoch: 3 [448128/702208 (64%)]	Loss: 0.081955Train Epoch: 3 [449024/702208 (64%)]	Loss: 0.034298Train Epoch: 3 [450048/702208 (64%)]	Loss: 0.088370
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8080 / 8283] 97 %
Accuracy of the network on test loader class  1: [4482 / 4517] 99 %

Writing model: iterations-1854464-total-98.14-class0-97.55-class1-99.22999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12125 / 12833] 94 %
Accuracy of the network on train loader class  1: [7065 / 7135] 99 %
Train Epoch: 3 [451072/702208 (64%)]	Loss: 0.189247Train Epoch: 3 [452096/702208 (64%)]	Loss: 0.142820Train Epoch: 3 [453120/702208 (65%)]	Loss: 0.095842Train Epoch: 3 [454016/702208 (65%)]	Loss: 0.109882Train Epoch: 3 [455040/702208 (65%)]	Loss: 0.108911Train Epoch: 3 [456064/702208 (65%)]	Loss: 0.103422Train Epoch: 3 [457088/702208 (65%)]	Loss: 0.048452Train Epoch: 3 [458112/702208 (65%)]	Loss: 0.075944Train Epoch: 3 [459008/702208 (65%)]	Loss: 0.091215Train Epoch: 3 [460032/702208 (66%)]	Loss: 0.051846Train Epoch: 3 [461056/702208 (66%)]	Loss: 0.088556Train Epoch: 3 [462080/702208 (66%)]	Loss: 0.127625Train Epoch: 3 [463104/702208 (66%)]	Loss: 0.089091Train Epoch: 3 [464000/702208 (66%)]	Loss: 0.055225Train Epoch: 3 [464128/702208 (66%)]	Loss: 0.085067Train Epoch: 3 [465024/702208 (66%)]	Loss: 0.052165Train Epoch: 3 [466048/702208 (66%)]	Loss: 0.051179Train Epoch: 3 [467072/702208 (67%)]	Loss: 0.116936Train Epoch: 3 [468096/702208 (67%)]	Loss: 0.089201Train Epoch: 3 [469120/702208 (67%)]	Loss: 0.147084Train Epoch: 3 [470016/702208 (67%)]	Loss: 0.071110Train Epoch: 3 [471040/702208 (67%)]	Loss: 0.102953Train Epoch: 3 [472064/702208 (67%)]	Loss: 0.077846Train Epoch: 3 [473088/702208 (67%)]	Loss: 0.055771Train Epoch: 3 [474112/702208 (68%)]	Loss: 0.051171Train Epoch: 3 [475008/702208 (68%)]	Loss: 0.066600
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7993 / 8283] 96 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-1879424-total-97.56-class0-96.5-class1-99.51
Train Epoch: 3 [476032/702208 (68%)]	Loss: 0.134814Train Epoch: 3 [477056/702208 (68%)]	Loss: 0.131731Train Epoch: 3 [478080/702208 (68%)]	Loss: 0.240665Train Epoch: 3 [479104/702208 (68%)]	Loss: 0.102089Train Epoch: 3 [480000/702208 (68%)]	Loss: 0.031660Train Epoch: 3 [480128/702208 (68%)]	Loss: 0.119429Train Epoch: 3 [481024/702208 (69%)]	Loss: 0.126583Train Epoch: 3 [482048/702208 (69%)]	Loss: 0.100834Train Epoch: 3 [483072/702208 (69%)]	Loss: 0.067919Train Epoch: 3 [484096/702208 (69%)]	Loss: 0.093075Train Epoch: 3 [485120/702208 (69%)]	Loss: 0.069371Train Epoch: 3 [486016/702208 (69%)]	Loss: 0.129151Train Epoch: 3 [487040/702208 (69%)]	Loss: 0.049376Train Epoch: 3 [488064/702208 (70%)]	Loss: 0.085807Train Epoch: 3 [489088/702208 (70%)]	Loss: 0.108682Train Epoch: 3 [490112/702208 (70%)]	Loss: 0.101994Train Epoch: 3 [491008/702208 (70%)]	Loss: 0.038532Train Epoch: 3 [492032/702208 (70%)]	Loss: 0.047075Train Epoch: 3 [493056/702208 (70%)]	Loss: 0.080428Train Epoch: 3 [494080/702208 (70%)]	Loss: 0.049297Train Epoch: 3 [495104/702208 (71%)]	Loss: 0.131151Train Epoch: 3 [496000/702208 (71%)]	Loss: 0.105739Train Epoch: 3 [496128/702208 (71%)]	Loss: 0.034954Train Epoch: 3 [497024/702208 (71%)]	Loss: 0.045611Train Epoch: 3 [498048/702208 (71%)]	Loss: 0.086442Train Epoch: 3 [499072/702208 (71%)]	Loss: 0.036408Train Epoch: 3 [500096/702208 (71%)]	Loss: 0.122424
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8072 / 8283] 97 %
Accuracy of the network on test loader class  1: [4462 / 4517] 98 %

Writing model: iterations-1904512-total-97.92-class0-97.45-class1-98.78

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12198 / 12833] 95 %
Accuracy of the network on train loader class  1: [6956 / 7135] 97 %
Train Epoch: 3 [501120/702208 (71%)]	Loss: 0.013668Train Epoch: 3 [502016/702208 (71%)]	Loss: 0.036062Train Epoch: 3 [503040/702208 (72%)]	Loss: 0.085346Train Epoch: 3 [504064/702208 (72%)]	Loss: 0.050804Train Epoch: 3 [505088/702208 (72%)]	Loss: 0.118535Train Epoch: 3 [506112/702208 (72%)]	Loss: 0.048307Train Epoch: 3 [507008/702208 (72%)]	Loss: 0.068315Train Epoch: 3 [508032/702208 (72%)]	Loss: 0.041135Train Epoch: 3 [509056/702208 (72%)]	Loss: 0.055549Train Epoch: 3 [510080/702208 (73%)]	Loss: 0.053687Train Epoch: 3 [511104/702208 (73%)]	Loss: 0.038347Train Epoch: 3 [512000/702208 (73%)]	Loss: 0.089804Train Epoch: 3 [512128/702208 (73%)]	Loss: 0.056199Train Epoch: 3 [513024/702208 (73%)]	Loss: 0.060442Train Epoch: 3 [514048/702208 (73%)]	Loss: 0.123811Train Epoch: 3 [515072/702208 (73%)]	Loss: 0.066841Train Epoch: 3 [516096/702208 (73%)]	Loss: 0.102475Train Epoch: 3 [517120/702208 (74%)]	Loss: 0.044522Train Epoch: 3 [518016/702208 (74%)]	Loss: 0.101354Train Epoch: 3 [519040/702208 (74%)]	Loss: 0.102279Train Epoch: 3 [520064/702208 (74%)]	Loss: 0.055663Train Epoch: 3 [521088/702208 (74%)]	Loss: 0.081290Train Epoch: 3 [522112/702208 (74%)]	Loss: 0.064149Train Epoch: 3 [523008/702208 (74%)]	Loss: 0.030018Train Epoch: 3 [524032/702208 (75%)]	Loss: 0.098702Train Epoch: 3 [525056/702208 (75%)]	Loss: 0.067932
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8071 / 8283] 97 %
Accuracy of the network on test loader class  1: [4480 / 4517] 99 %

Writing model: iterations-1929472-total-98.05-class0-97.44-class1-99.18
Train Epoch: 3 [526080/702208 (75%)]	Loss: 0.059450Train Epoch: 3 [527104/702208 (75%)]	Loss: 0.062452Train Epoch: 3 [528000/702208 (75%)]	Loss: 0.089920Train Epoch: 3 [528128/702208 (75%)]	Loss: 0.037497Train Epoch: 3 [529024/702208 (75%)]	Loss: 0.028309Train Epoch: 3 [530048/702208 (75%)]	Loss: 0.049078Train Epoch: 3 [531072/702208 (76%)]	Loss: 0.077444Train Epoch: 3 [532096/702208 (76%)]	Loss: 0.080066Train Epoch: 3 [533120/702208 (76%)]	Loss: 0.115615Train Epoch: 3 [534016/702208 (76%)]	Loss: 0.080343Train Epoch: 3 [535040/702208 (76%)]	Loss: 0.237311Train Epoch: 3 [536064/702208 (76%)]	Loss: 0.123598Train Epoch: 3 [537088/702208 (76%)]	Loss: 0.042485Train Epoch: 3 [538112/702208 (77%)]	Loss: 0.100442Train Epoch: 3 [539008/702208 (77%)]	Loss: 0.068601Train Epoch: 3 [540032/702208 (77%)]	Loss: 0.064781Train Epoch: 3 [541056/702208 (77%)]	Loss: 0.080422Train Epoch: 3 [542080/702208 (77%)]	Loss: 0.135750Train Epoch: 3 [543104/702208 (77%)]	Loss: 0.113985Train Epoch: 3 [544000/702208 (77%)]	Loss: 0.073704Train Epoch: 3 [544128/702208 (77%)]	Loss: 0.078110Train Epoch: 3 [545024/702208 (78%)]	Loss: 0.083000Train Epoch: 3 [546048/702208 (78%)]	Loss: 0.090611Train Epoch: 3 [547072/702208 (78%)]	Loss: 0.029901Train Epoch: 3 [548096/702208 (78%)]	Loss: 0.069982Train Epoch: 3 [549120/702208 (78%)]	Loss: 0.132700Train Epoch: 3 [550016/702208 (78%)]	Loss: 0.063572
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8008 / 8283] 96 %
Accuracy of the network on test loader class  1: [4492 / 4517] 99 %

Writing model: iterations-1954432-total-97.66-class0-96.67999999999999-class1-99.45

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12117 / 12833] 94 %
Accuracy of the network on train loader class  1: [7059 / 7135] 98 %
Train Epoch: 3 [551040/702208 (78%)]	Loss: 0.053591Train Epoch: 3 [552064/702208 (79%)]	Loss: 0.075784Train Epoch: 3 [553088/702208 (79%)]	Loss: 0.146493Train Epoch: 3 [554112/702208 (79%)]	Loss: 0.078435Train Epoch: 3 [555008/702208 (79%)]	Loss: 0.081050Train Epoch: 3 [556032/702208 (79%)]	Loss: 0.088275Train Epoch: 3 [557056/702208 (79%)]	Loss: 0.066242Train Epoch: 3 [558080/702208 (79%)]	Loss: 0.048455Train Epoch: 3 [559104/702208 (80%)]	Loss: 0.125053Train Epoch: 3 [560000/702208 (80%)]	Loss: 0.081936Train Epoch: 3 [560128/702208 (80%)]	Loss: 0.070032Train Epoch: 3 [561024/702208 (80%)]	Loss: 0.057674Train Epoch: 3 [562048/702208 (80%)]	Loss: 0.082240Train Epoch: 3 [563072/702208 (80%)]	Loss: 0.071939Train Epoch: 3 [564096/702208 (80%)]	Loss: 0.089227Train Epoch: 3 [565120/702208 (80%)]	Loss: 0.105733Train Epoch: 3 [566016/702208 (81%)]	Loss: 0.133079Train Epoch: 3 [567040/702208 (81%)]	Loss: 0.024165Train Epoch: 3 [568064/702208 (81%)]	Loss: 0.059836Train Epoch: 3 [569088/702208 (81%)]	Loss: 0.058459Train Epoch: 3 [570112/702208 (81%)]	Loss: 0.064863Train Epoch: 3 [571008/702208 (81%)]	Loss: 0.187079Train Epoch: 3 [572032/702208 (81%)]	Loss: 0.103307Train Epoch: 3 [573056/702208 (82%)]	Loss: 0.081483Train Epoch: 3 [574080/702208 (82%)]	Loss: 0.069291Train Epoch: 3 [575104/702208 (82%)]	Loss: 0.086765
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8093 / 8283] 97 %
Accuracy of the network on test loader class  1: [4486 / 4517] 99 %

Writing model: iterations-1979520-total-98.27-class0-97.71-class1-99.31
Train Epoch: 3 [576000/702208 (82%)]	Loss: 0.060224Train Epoch: 3 [576128/702208 (82%)]	Loss: 0.058000Train Epoch: 3 [577024/702208 (82%)]	Loss: 0.093945Train Epoch: 3 [578048/702208 (82%)]	Loss: 0.140189Train Epoch: 3 [579072/702208 (82%)]	Loss: 0.087519Train Epoch: 3 [580096/702208 (83%)]	Loss: 0.105869Train Epoch: 3 [581120/702208 (83%)]	Loss: 0.088956Train Epoch: 3 [582016/702208 (83%)]	Loss: 0.051162Train Epoch: 3 [583040/702208 (83%)]	Loss: 0.117812Train Epoch: 3 [584064/702208 (83%)]	Loss: 0.100942Train Epoch: 3 [585088/702208 (83%)]	Loss: 0.055777Train Epoch: 3 [586112/702208 (83%)]	Loss: 0.102002Train Epoch: 3 [587008/702208 (84%)]	Loss: 0.129764Train Epoch: 3 [588032/702208 (84%)]	Loss: 0.055880Train Epoch: 3 [589056/702208 (84%)]	Loss: 0.060332Train Epoch: 3 [590080/702208 (84%)]	Loss: 0.072285Train Epoch: 3 [591104/702208 (84%)]	Loss: 0.051719Train Epoch: 3 [592000/702208 (84%)]	Loss: 0.045049Train Epoch: 3 [592128/702208 (84%)]	Loss: 0.068750Train Epoch: 3 [593024/702208 (84%)]	Loss: 0.131387Train Epoch: 3 [594048/702208 (85%)]	Loss: 0.085840Train Epoch: 3 [595072/702208 (85%)]	Loss: 0.177536Train Epoch: 3 [596096/702208 (85%)]	Loss: 0.166643Train Epoch: 3 [597120/702208 (85%)]	Loss: 0.056266Train Epoch: 3 [598016/702208 (85%)]	Loss: 0.069036Train Epoch: 3 [599040/702208 (85%)]	Loss: 0.068671Train Epoch: 3 [600064/702208 (85%)]	Loss: 0.084152
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 93 %
Accuracy of the network on test loader class  0: [7508 / 8283] 90 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-2004480-total-93.89999999999999-class0-90.64-class1-99.87

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12135 / 12833] 94 %
Accuracy of the network on train loader class  1: [6981 / 7135] 97 %
Train Epoch: 3 [601088/702208 (86%)]	Loss: 0.119609Train Epoch: 3 [602112/702208 (86%)]	Loss: 0.028870Train Epoch: 3 [603008/702208 (86%)]	Loss: 0.090854Train Epoch: 3 [604032/702208 (86%)]	Loss: 0.030066Train Epoch: 3 [605056/702208 (86%)]	Loss: 0.057011Train Epoch: 3 [606080/702208 (86%)]	Loss: 0.046191Train Epoch: 3 [607104/702208 (86%)]	Loss: 0.092173Train Epoch: 3 [608000/702208 (87%)]	Loss: 0.054699Train Epoch: 3 [608128/702208 (87%)]	Loss: 0.049415Train Epoch: 3 [609024/702208 (87%)]	Loss: 0.072302Train Epoch: 3 [610048/702208 (87%)]	Loss: 0.109168Train Epoch: 3 [611072/702208 (87%)]	Loss: 0.085214Train Epoch: 3 [612096/702208 (87%)]	Loss: 0.094472Train Epoch: 3 [613120/702208 (87%)]	Loss: 0.058349Train Epoch: 3 [614016/702208 (87%)]	Loss: 0.122208Train Epoch: 3 [615040/702208 (88%)]	Loss: 0.039196Train Epoch: 3 [616064/702208 (88%)]	Loss: 0.080824Train Epoch: 3 [617088/702208 (88%)]	Loss: 0.084460Train Epoch: 3 [618112/702208 (88%)]	Loss: 0.064983Train Epoch: 3 [619008/702208 (88%)]	Loss: 0.086560Train Epoch: 3 [620032/702208 (88%)]	Loss: 0.079348Train Epoch: 3 [621056/702208 (88%)]	Loss: 0.027447Train Epoch: 3 [622080/702208 (89%)]	Loss: 0.066434Train Epoch: 3 [623104/702208 (89%)]	Loss: 0.038346Train Epoch: 3 [624000/702208 (89%)]	Loss: 0.088956Train Epoch: 3 [624128/702208 (89%)]	Loss: 0.106593Train Epoch: 3 [625024/702208 (89%)]	Loss: 0.052670
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7926 / 8283] 95 %
Accuracy of the network on test loader class  1: [4497 / 4517] 99 %

Writing model: iterations-2029440-total-97.05-class0-95.69-class1-99.56
Train Epoch: 3 [626048/702208 (89%)]	Loss: 0.042608Train Epoch: 3 [627072/702208 (89%)]	Loss: 0.056802Train Epoch: 3 [628096/702208 (89%)]	Loss: 0.150966Train Epoch: 3 [629120/702208 (90%)]	Loss: 0.125422Train Epoch: 3 [630016/702208 (90%)]	Loss: 0.075458Train Epoch: 3 [631040/702208 (90%)]	Loss: 0.081987Train Epoch: 3 [632064/702208 (90%)]	Loss: 0.066156Train Epoch: 3 [633088/702208 (90%)]	Loss: 0.039556Train Epoch: 3 [634112/702208 (90%)]	Loss: 0.052362Train Epoch: 3 [635008/702208 (90%)]	Loss: 0.031638Train Epoch: 3 [636032/702208 (91%)]	Loss: 0.146573Train Epoch: 3 [637056/702208 (91%)]	Loss: 0.057048Train Epoch: 3 [638080/702208 (91%)]	Loss: 0.143140Train Epoch: 3 [639104/702208 (91%)]	Loss: 0.096878Train Epoch: 3 [640000/702208 (91%)]	Loss: 0.070908Train Epoch: 3 [640128/702208 (91%)]	Loss: 0.061403Train Epoch: 3 [641024/702208 (91%)]	Loss: 0.058768Train Epoch: 3 [642048/702208 (91%)]	Loss: 0.139879Train Epoch: 3 [643072/702208 (92%)]	Loss: 0.064934Train Epoch: 3 [644096/702208 (92%)]	Loss: 0.095379Train Epoch: 3 [645120/702208 (92%)]	Loss: 0.072455Train Epoch: 3 [646016/702208 (92%)]	Loss: 0.054123Train Epoch: 3 [647040/702208 (92%)]	Loss: 0.098903Train Epoch: 3 [648064/702208 (92%)]	Loss: 0.122284Train Epoch: 3 [649088/702208 (92%)]	Loss: 0.047372Train Epoch: 3 [650112/702208 (93%)]	Loss: 0.146573
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7992 / 8283] 96 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-2054528-total-97.55-class0-96.49-class1-99.49

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12204 / 12833] 95 %
Accuracy of the network on train loader class  1: [7059 / 7135] 98 %
Train Epoch: 3 [651008/702208 (93%)]	Loss: 0.072140Train Epoch: 3 [652032/702208 (93%)]	Loss: 0.173895Train Epoch: 3 [653056/702208 (93%)]	Loss: 0.035846Train Epoch: 3 [654080/702208 (93%)]	Loss: 0.073905Train Epoch: 3 [655104/702208 (93%)]	Loss: 0.131284Train Epoch: 3 [656000/702208 (93%)]	Loss: 0.176322Train Epoch: 3 [656128/702208 (93%)]	Loss: 0.108005Train Epoch: 3 [657024/702208 (94%)]	Loss: 0.051368Train Epoch: 3 [658048/702208 (94%)]	Loss: 0.091214Train Epoch: 3 [659072/702208 (94%)]	Loss: 0.031965Train Epoch: 3 [660096/702208 (94%)]	Loss: 0.025839Train Epoch: 3 [661120/702208 (94%)]	Loss: 0.093817Train Epoch: 3 [662016/702208 (94%)]	Loss: 0.199135Train Epoch: 3 [663040/702208 (94%)]	Loss: 0.074143Train Epoch: 3 [664064/702208 (95%)]	Loss: 0.078837Train Epoch: 3 [665088/702208 (95%)]	Loss: 0.162676Train Epoch: 3 [666112/702208 (95%)]	Loss: 0.047815Train Epoch: 3 [667008/702208 (95%)]	Loss: 0.077651Train Epoch: 3 [668032/702208 (95%)]	Loss: 0.095715Train Epoch: 3 [669056/702208 (95%)]	Loss: 0.070573Train Epoch: 3 [670080/702208 (95%)]	Loss: 0.038601Train Epoch: 3 [671104/702208 (96%)]	Loss: 0.078825Train Epoch: 3 [672000/702208 (96%)]	Loss: 0.065754Train Epoch: 3 [672128/702208 (96%)]	Loss: 0.060868Train Epoch: 3 [673024/702208 (96%)]	Loss: 0.073349Train Epoch: 3 [674048/702208 (96%)]	Loss: 0.146561Train Epoch: 3 [675072/702208 (96%)]	Loss: 0.041485
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8060 / 8283] 97 %
Accuracy of the network on test loader class  1: [4486 / 4517] 99 %

Writing model: iterations-2079488-total-98.02-class0-97.31-class1-99.31
Train Epoch: 3 [676096/702208 (96%)]	Loss: 0.085905Train Epoch: 3 [677120/702208 (96%)]	Loss: 0.049171Train Epoch: 3 [678016/702208 (97%)]	Loss: 0.033150Train Epoch: 3 [679040/702208 (97%)]	Loss: 0.033366Train Epoch: 3 [680064/702208 (97%)]	Loss: 0.135321Train Epoch: 3 [681088/702208 (97%)]	Loss: 0.064136Train Epoch: 3 [682112/702208 (97%)]	Loss: 0.029682Train Epoch: 3 [683008/702208 (97%)]	Loss: 0.111953Train Epoch: 3 [684032/702208 (97%)]	Loss: 0.072728Train Epoch: 3 [685056/702208 (98%)]	Loss: 0.062803Train Epoch: 3 [686080/702208 (98%)]	Loss: 0.098339Train Epoch: 3 [687104/702208 (98%)]	Loss: 0.119904Train Epoch: 3 [688000/702208 (98%)]	Loss: 0.084053Train Epoch: 3 [688128/702208 (98%)]	Loss: 0.073176Train Epoch: 3 [689024/702208 (98%)]	Loss: 0.035442Train Epoch: 3 [690048/702208 (98%)]	Loss: 0.052013Train Epoch: 3 [691072/702208 (98%)]	Loss: 0.052292Train Epoch: 3 [692096/702208 (99%)]	Loss: 0.055875Train Epoch: 3 [693120/702208 (99%)]	Loss: 0.104213Train Epoch: 3 [694016/702208 (99%)]	Loss: 0.044476Train Epoch: 3 [695040/702208 (99%)]	Loss: 0.081377Train Epoch: 3 [696064/702208 (99%)]	Loss: 0.032532Train Epoch: 3 [697088/702208 (99%)]	Loss: 0.068578Train Epoch: 3 [698112/702208 (99%)]	Loss: 0.115601Train Epoch: 3 [699008/702208 (100%)]	Loss: 0.050657Train Epoch: 3 [700032/702208 (100%)]	Loss: 0.077460
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8100 / 8283] 97 %
Accuracy of the network on test loader class  1: [4470 / 4517] 98 %

Writing model: iterations-2104448-total-98.2-class0-97.78999999999999-class1-98.96000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12176 / 12833] 94 %
Accuracy of the network on train loader class  1: [7067 / 7135] 99 %
Train Epoch: 3 [701056/702208 (100%)]	Loss: 0.032510Train Epoch: 3 [702080/702208 (100%)]	Loss: 0.055192
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7976 / 8283] 96 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %
Train Epoch: 4 [1024/702208 (0%)]	Loss: 0.081412Train Epoch: 4 [2048/702208 (0%)]	Loss: 0.066464Train Epoch: 4 [3072/702208 (0%)]	Loss: 0.243440Train Epoch: 4 [4096/702208 (1%)]	Loss: 0.085922Train Epoch: 4 [5120/702208 (1%)]	Loss: 0.111342Train Epoch: 4 [6016/702208 (1%)]	Loss: 0.039724Train Epoch: 4 [7040/702208 (1%)]	Loss: 0.067578Train Epoch: 4 [8064/702208 (1%)]	Loss: 0.125635Train Epoch: 4 [9088/702208 (1%)]	Loss: 0.064724Train Epoch: 4 [10112/702208 (1%)]	Loss: 0.073089Train Epoch: 4 [11008/702208 (2%)]	Loss: 0.054259Train Epoch: 4 [12032/702208 (2%)]	Loss: 0.106818Train Epoch: 4 [13056/702208 (2%)]	Loss: 0.041982Train Epoch: 4 [14080/702208 (2%)]	Loss: 0.048764Train Epoch: 4 [15104/702208 (2%)]	Loss: 0.076563Train Epoch: 4 [16000/702208 (2%)]	Loss: 0.090089Train Epoch: 4 [16128/702208 (2%)]	Loss: 0.073878Train Epoch: 4 [17024/702208 (2%)]	Loss: 0.033114Train Epoch: 4 [18048/702208 (3%)]	Loss: 0.054434Train Epoch: 4 [19072/702208 (3%)]	Loss: 0.065379Train Epoch: 4 [20096/702208 (3%)]	Loss: 0.088060Train Epoch: 4 [21120/702208 (3%)]	Loss: 0.040461Train Epoch: 4 [22016/702208 (3%)]	Loss: 0.092377Train Epoch: 4 [23040/702208 (3%)]	Loss: 0.056148Train Epoch: 4 [24064/702208 (3%)]	Loss: 0.076247Train Epoch: 4 [25088/702208 (4%)]	Loss: 0.096560
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8043 / 8283] 97 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-2131712-total-97.95-class0-97.1-class1-99.49
Train Epoch: 4 [26112/702208 (4%)]	Loss: 0.146866Train Epoch: 4 [27008/702208 (4%)]	Loss: 0.098179Train Epoch: 4 [28032/702208 (4%)]	Loss: 0.081525Train Epoch: 4 [29056/702208 (4%)]	Loss: 0.078082Train Epoch: 4 [30080/702208 (4%)]	Loss: 0.155803Train Epoch: 4 [31104/702208 (4%)]	Loss: 0.033756Train Epoch: 4 [32000/702208 (5%)]	Loss: 0.089328Train Epoch: 4 [32128/702208 (5%)]	Loss: 0.062307Train Epoch: 4 [33024/702208 (5%)]	Loss: 0.049727Train Epoch: 4 [34048/702208 (5%)]	Loss: 0.107456Train Epoch: 4 [35072/702208 (5%)]	Loss: 0.062403Train Epoch: 4 [36096/702208 (5%)]	Loss: 0.125128Train Epoch: 4 [37120/702208 (5%)]	Loss: 0.045842Train Epoch: 4 [38016/702208 (5%)]	Loss: 0.058625Train Epoch: 4 [39040/702208 (6%)]	Loss: 0.099463Train Epoch: 4 [40064/702208 (6%)]	Loss: 0.112423Train Epoch: 4 [41088/702208 (6%)]	Loss: 0.082042Train Epoch: 4 [42112/702208 (6%)]	Loss: 0.052000Train Epoch: 4 [43008/702208 (6%)]	Loss: 0.097412Train Epoch: 4 [44032/702208 (6%)]	Loss: 0.207292Train Epoch: 4 [45056/702208 (6%)]	Loss: 0.073151Train Epoch: 4 [46080/702208 (7%)]	Loss: 0.115956Train Epoch: 4 [47104/702208 (7%)]	Loss: 0.022558Train Epoch: 4 [48000/702208 (7%)]	Loss: 0.102129Train Epoch: 4 [48128/702208 (7%)]	Loss: 0.106200Train Epoch: 4 [49024/702208 (7%)]	Loss: 0.053147Train Epoch: 4 [50048/702208 (7%)]	Loss: 0.108144
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7966 / 8283] 96 %
Accuracy of the network on test loader class  1: [4492 / 4517] 99 %

Writing model: iterations-2156672-total-97.33000000000001-class0-96.17-class1-99.45

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12096 / 12833] 94 %
Accuracy of the network on train loader class  1: [7073 / 7135] 99 %
Train Epoch: 4 [51072/702208 (7%)]	Loss: 0.079947Train Epoch: 4 [52096/702208 (7%)]	Loss: 0.064243Train Epoch: 4 [53120/702208 (8%)]	Loss: 0.031749Train Epoch: 4 [54016/702208 (8%)]	Loss: 0.053960Train Epoch: 4 [55040/702208 (8%)]	Loss: 0.063431Train Epoch: 4 [56064/702208 (8%)]	Loss: 0.088918Train Epoch: 4 [57088/702208 (8%)]	Loss: 0.126961Train Epoch: 4 [58112/702208 (8%)]	Loss: 0.078444Train Epoch: 4 [59008/702208 (8%)]	Loss: 0.056172Train Epoch: 4 [60032/702208 (9%)]	Loss: 0.044503Train Epoch: 4 [61056/702208 (9%)]	Loss: 0.046764Train Epoch: 4 [62080/702208 (9%)]	Loss: 0.062146Train Epoch: 4 [63104/702208 (9%)]	Loss: 0.076578Train Epoch: 4 [64000/702208 (9%)]	Loss: 0.047547Train Epoch: 4 [64128/702208 (9%)]	Loss: 0.098581Train Epoch: 4 [65024/702208 (9%)]	Loss: 0.055220Train Epoch: 4 [66048/702208 (9%)]	Loss: 0.076812Train Epoch: 4 [67072/702208 (10%)]	Loss: 0.058224Train Epoch: 4 [68096/702208 (10%)]	Loss: 0.056124Train Epoch: 4 [69120/702208 (10%)]	Loss: 0.108009Train Epoch: 4 [70016/702208 (10%)]	Loss: 0.109247Train Epoch: 4 [71040/702208 (10%)]	Loss: 0.045863Train Epoch: 4 [72064/702208 (10%)]	Loss: 0.075215Train Epoch: 4 [73088/702208 (10%)]	Loss: 0.180473Train Epoch: 4 [74112/702208 (11%)]	Loss: 0.067898Train Epoch: 4 [75008/702208 (11%)]	Loss: 0.116558
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7975 / 8283] 96 %
Accuracy of the network on test loader class  1: [4501 / 4517] 99 %

Writing model: iterations-2181632-total-97.47-class0-96.28-class1-99.65
Train Epoch: 4 [76032/702208 (11%)]	Loss: 0.097189Train Epoch: 4 [77056/702208 (11%)]	Loss: 0.128486Train Epoch: 4 [78080/702208 (11%)]	Loss: 0.041453Train Epoch: 4 [79104/702208 (11%)]	Loss: 0.219372Train Epoch: 4 [80000/702208 (11%)]	Loss: 0.054838Train Epoch: 4 [80128/702208 (11%)]	Loss: 0.020009Train Epoch: 4 [81024/702208 (12%)]	Loss: 0.025989Train Epoch: 4 [82048/702208 (12%)]	Loss: 0.101665Train Epoch: 4 [83072/702208 (12%)]	Loss: 0.038701Train Epoch: 4 [84096/702208 (12%)]	Loss: 0.044853Train Epoch: 4 [85120/702208 (12%)]	Loss: 0.063796Train Epoch: 4 [86016/702208 (12%)]	Loss: 0.067039Train Epoch: 4 [87040/702208 (12%)]	Loss: 0.124809Train Epoch: 4 [88064/702208 (13%)]	Loss: 0.075715Train Epoch: 4 [89088/702208 (13%)]	Loss: 0.118890Train Epoch: 4 [90112/702208 (13%)]	Loss: 0.077059Train Epoch: 4 [91008/702208 (13%)]	Loss: 0.115978Train Epoch: 4 [92032/702208 (13%)]	Loss: 0.103722Train Epoch: 4 [93056/702208 (13%)]	Loss: 0.109410Train Epoch: 4 [94080/702208 (13%)]	Loss: 0.049694Train Epoch: 4 [95104/702208 (14%)]	Loss: 0.082420Train Epoch: 4 [96000/702208 (14%)]	Loss: 0.046773Train Epoch: 4 [96128/702208 (14%)]	Loss: 0.096996Train Epoch: 4 [97024/702208 (14%)]	Loss: 0.041280Train Epoch: 4 [98048/702208 (14%)]	Loss: 0.076902Train Epoch: 4 [99072/702208 (14%)]	Loss: 0.074305Train Epoch: 4 [100096/702208 (14%)]	Loss: 0.032873
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8044 / 8283] 97 %
Accuracy of the network on test loader class  1: [4498 / 4517] 99 %

Writing model: iterations-2206720-total-97.98-class0-97.11-class1-99.58

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12131 / 12833] 94 %
Accuracy of the network on train loader class  1: [7072 / 7135] 99 %
Train Epoch: 4 [101120/702208 (14%)]	Loss: 0.023801Train Epoch: 4 [102016/702208 (15%)]	Loss: 0.058792Train Epoch: 4 [103040/702208 (15%)]	Loss: 0.054103Train Epoch: 4 [104064/702208 (15%)]	Loss: 0.130347Train Epoch: 4 [105088/702208 (15%)]	Loss: 0.070535Train Epoch: 4 [106112/702208 (15%)]	Loss: 0.076732Train Epoch: 4 [107008/702208 (15%)]	Loss: 0.122098Train Epoch: 4 [108032/702208 (15%)]	Loss: 0.023993Train Epoch: 4 [109056/702208 (16%)]	Loss: 0.098288Train Epoch: 4 [110080/702208 (16%)]	Loss: 0.069504Train Epoch: 4 [111104/702208 (16%)]	Loss: 0.144890Train Epoch: 4 [112000/702208 (16%)]	Loss: 0.065444Train Epoch: 4 [112128/702208 (16%)]	Loss: 0.025693Train Epoch: 4 [113024/702208 (16%)]	Loss: 0.081387Train Epoch: 4 [114048/702208 (16%)]	Loss: 0.070131Train Epoch: 4 [115072/702208 (16%)]	Loss: 0.083660Train Epoch: 4 [116096/702208 (17%)]	Loss: 0.066690Train Epoch: 4 [117120/702208 (17%)]	Loss: 0.130650Train Epoch: 4 [118016/702208 (17%)]	Loss: 0.073663Train Epoch: 4 [119040/702208 (17%)]	Loss: 0.057013Train Epoch: 4 [120064/702208 (17%)]	Loss: 0.103242Train Epoch: 4 [121088/702208 (17%)]	Loss: 0.130282Train Epoch: 4 [122112/702208 (17%)]	Loss: 0.050118Train Epoch: 4 [123008/702208 (18%)]	Loss: 0.054657Train Epoch: 4 [124032/702208 (18%)]	Loss: 0.069500Train Epoch: 4 [125056/702208 (18%)]	Loss: 0.051786
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7972 / 8283] 96 %
Accuracy of the network on test loader class  1: [4499 / 4517] 99 %

Writing model: iterations-2231680-total-97.43-class0-96.25-class1-99.6
Train Epoch: 4 [126080/702208 (18%)]	Loss: 0.042457Train Epoch: 4 [127104/702208 (18%)]	Loss: 0.132356Train Epoch: 4 [128000/702208 (18%)]	Loss: 0.071629Train Epoch: 4 [128128/702208 (18%)]	Loss: 0.122224Train Epoch: 4 [129024/702208 (18%)]	Loss: 0.060207Train Epoch: 4 [130048/702208 (19%)]	Loss: 0.054577Train Epoch: 4 [131072/702208 (19%)]	Loss: 0.059126Train Epoch: 4 [132096/702208 (19%)]	Loss: 0.091010Train Epoch: 4 [133120/702208 (19%)]	Loss: 0.044491Train Epoch: 4 [134016/702208 (19%)]	Loss: 0.126957Train Epoch: 4 [135040/702208 (19%)]	Loss: 0.166717Train Epoch: 4 [136064/702208 (19%)]	Loss: 0.186970Train Epoch: 4 [137088/702208 (20%)]	Loss: 0.037091Train Epoch: 4 [138112/702208 (20%)]	Loss: 0.086342Train Epoch: 4 [139008/702208 (20%)]	Loss: 0.060026Train Epoch: 4 [140032/702208 (20%)]	Loss: 0.091982Train Epoch: 4 [141056/702208 (20%)]	Loss: 0.040877Train Epoch: 4 [142080/702208 (20%)]	Loss: 0.075391Train Epoch: 4 [143104/702208 (20%)]	Loss: 0.064627Train Epoch: 4 [144000/702208 (21%)]	Loss: 0.087990Train Epoch: 4 [144128/702208 (21%)]	Loss: 0.117227Train Epoch: 4 [145024/702208 (21%)]	Loss: 0.077880Train Epoch: 4 [146048/702208 (21%)]	Loss: 0.061178Train Epoch: 4 [147072/702208 (21%)]	Loss: 0.094315Train Epoch: 4 [148096/702208 (21%)]	Loss: 0.215690Train Epoch: 4 [149120/702208 (21%)]	Loss: 0.071381Train Epoch: 4 [150016/702208 (21%)]	Loss: 0.049959
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8053 / 8283] 97 %
Accuracy of the network on test loader class  1: [4490 / 4517] 99 %

Writing model: iterations-2256640-total-97.99-class0-97.22-class1-99.4

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12177 / 12833] 94 %
Accuracy of the network on train loader class  1: [7062 / 7135] 98 %
Train Epoch: 4 [151040/702208 (22%)]	Loss: 0.042134Train Epoch: 4 [152064/702208 (22%)]	Loss: 0.043140Train Epoch: 4 [153088/702208 (22%)]	Loss: 0.044670Train Epoch: 4 [154112/702208 (22%)]	Loss: 0.034566Train Epoch: 4 [155008/702208 (22%)]	Loss: 0.121182Train Epoch: 4 [156032/702208 (22%)]	Loss: 0.112197Train Epoch: 4 [157056/702208 (22%)]	Loss: 0.074071Train Epoch: 4 [158080/702208 (23%)]	Loss: 0.074587Train Epoch: 4 [159104/702208 (23%)]	Loss: 0.086623Train Epoch: 4 [160000/702208 (23%)]	Loss: 0.039078Train Epoch: 4 [160128/702208 (23%)]	Loss: 0.107088Train Epoch: 4 [161024/702208 (23%)]	Loss: 0.078264Train Epoch: 4 [162048/702208 (23%)]	Loss: 0.038831Train Epoch: 4 [163072/702208 (23%)]	Loss: 0.029869Train Epoch: 4 [164096/702208 (23%)]	Loss: 0.068480Train Epoch: 4 [165120/702208 (24%)]	Loss: 0.081148Train Epoch: 4 [166016/702208 (24%)]	Loss: 0.045481Train Epoch: 4 [167040/702208 (24%)]	Loss: 0.098475Train Epoch: 4 [168064/702208 (24%)]	Loss: 0.044545Train Epoch: 4 [169088/702208 (24%)]	Loss: 0.070817Train Epoch: 4 [170112/702208 (24%)]	Loss: 0.043427Train Epoch: 4 [171008/702208 (24%)]	Loss: 0.038837Train Epoch: 4 [172032/702208 (24%)]	Loss: 0.082631Train Epoch: 4 [173056/702208 (25%)]	Loss: 0.071966Train Epoch: 4 [174080/702208 (25%)]	Loss: 0.115076Train Epoch: 4 [175104/702208 (25%)]	Loss: 0.072392
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8051 / 8283] 97 %
Accuracy of the network on test loader class  1: [4498 / 4517] 99 %

Writing model: iterations-2281728-total-98.04-class0-97.2-class1-99.58
Train Epoch: 4 [176000/702208 (25%)]	Loss: 0.121426Train Epoch: 4 [176128/702208 (25%)]	Loss: 0.076216Train Epoch: 4 [177024/702208 (25%)]	Loss: 0.075638Train Epoch: 4 [178048/702208 (25%)]	Loss: 0.141301Train Epoch: 4 [179072/702208 (26%)]	Loss: 0.075661Train Epoch: 4 [180096/702208 (26%)]	Loss: 0.056202Train Epoch: 4 [181120/702208 (26%)]	Loss: 0.046947Train Epoch: 4 [182016/702208 (26%)]	Loss: 0.079708Train Epoch: 4 [183040/702208 (26%)]	Loss: 0.094312Train Epoch: 4 [184064/702208 (26%)]	Loss: 0.143236Train Epoch: 4 [185088/702208 (26%)]	Loss: 0.086433Train Epoch: 4 [186112/702208 (27%)]	Loss: 0.101102Train Epoch: 4 [187008/702208 (27%)]	Loss: 0.071096Train Epoch: 4 [188032/702208 (27%)]	Loss: 0.108624Train Epoch: 4 [189056/702208 (27%)]	Loss: 0.088451Train Epoch: 4 [190080/702208 (27%)]	Loss: 0.051200Train Epoch: 4 [191104/702208 (27%)]	Loss: 0.086593Train Epoch: 4 [192000/702208 (27%)]	Loss: 0.062373Train Epoch: 4 [192128/702208 (27%)]	Loss: 0.109265Train Epoch: 4 [193024/702208 (27%)]	Loss: 0.065726Train Epoch: 4 [194048/702208 (28%)]	Loss: 0.080374Train Epoch: 4 [195072/702208 (28%)]	Loss: 0.038599Train Epoch: 4 [196096/702208 (28%)]	Loss: 0.128641Train Epoch: 4 [197120/702208 (28%)]	Loss: 0.039548Train Epoch: 4 [198016/702208 (28%)]	Loss: 0.049478Train Epoch: 4 [199040/702208 (28%)]	Loss: 0.050038Train Epoch: 4 [200064/702208 (28%)]	Loss: 0.086060
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7989 / 8283] 96 %
Accuracy of the network on test loader class  1: [4496 / 4517] 99 %

Writing model: iterations-2306688-total-97.54-class0-96.45-class1-99.53999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12203 / 12833] 95 %
Accuracy of the network on train loader class  1: [7083 / 7135] 99 %
Train Epoch: 4 [201088/702208 (29%)]	Loss: 0.024843Train Epoch: 4 [202112/702208 (29%)]	Loss: 0.034662Train Epoch: 4 [203008/702208 (29%)]	Loss: 0.042860Train Epoch: 4 [204032/702208 (29%)]	Loss: 0.062751Train Epoch: 4 [205056/702208 (29%)]	Loss: 0.103851Train Epoch: 4 [206080/702208 (29%)]	Loss: 0.167468Train Epoch: 4 [207104/702208 (29%)]	Loss: 0.025694Train Epoch: 4 [208000/702208 (30%)]	Loss: 0.052365Train Epoch: 4 [208128/702208 (30%)]	Loss: 0.075791Train Epoch: 4 [209024/702208 (30%)]	Loss: 0.076905Train Epoch: 4 [210048/702208 (30%)]	Loss: 0.062080Train Epoch: 4 [211072/702208 (30%)]	Loss: 0.080026Train Epoch: 4 [212096/702208 (30%)]	Loss: 0.052265Train Epoch: 4 [213120/702208 (30%)]	Loss: 0.056138Train Epoch: 4 [214016/702208 (30%)]	Loss: 0.033434Train Epoch: 4 [215040/702208 (31%)]	Loss: 0.086610Train Epoch: 4 [216064/702208 (31%)]	Loss: 0.070502Train Epoch: 4 [217088/702208 (31%)]	Loss: 0.126883Train Epoch: 4 [218112/702208 (31%)]	Loss: 0.034941Train Epoch: 4 [219008/702208 (31%)]	Loss: 0.043579Train Epoch: 4 [220032/702208 (31%)]	Loss: 0.080885Train Epoch: 4 [221056/702208 (31%)]	Loss: 0.159772Train Epoch: 4 [222080/702208 (32%)]	Loss: 0.040685Train Epoch: 4 [223104/702208 (32%)]	Loss: 0.057541Train Epoch: 4 [224000/702208 (32%)]	Loss: 0.075823Train Epoch: 4 [224128/702208 (32%)]	Loss: 0.075961Train Epoch: 4 [225024/702208 (32%)]	Loss: 0.070856
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8020 / 8283] 96 %
Accuracy of the network on test loader class  1: [4492 / 4517] 99 %

Writing model: iterations-2331648-total-97.75-class0-96.82-class1-99.45
Train Epoch: 4 [226048/702208 (32%)]	Loss: 0.027420Train Epoch: 4 [227072/702208 (32%)]	Loss: 0.128506Train Epoch: 4 [228096/702208 (32%)]	Loss: 0.063819Train Epoch: 4 [229120/702208 (33%)]	Loss: 0.124642Train Epoch: 4 [230016/702208 (33%)]	Loss: 0.091848Train Epoch: 4 [231040/702208 (33%)]	Loss: 0.060252Train Epoch: 4 [232064/702208 (33%)]	Loss: 0.041137Train Epoch: 4 [233088/702208 (33%)]	Loss: 0.085497Train Epoch: 4 [234112/702208 (33%)]	Loss: 0.089275Train Epoch: 4 [235008/702208 (33%)]	Loss: 0.076910Train Epoch: 4 [236032/702208 (34%)]	Loss: 0.073291Train Epoch: 4 [237056/702208 (34%)]	Loss: 0.110715Train Epoch: 4 [238080/702208 (34%)]	Loss: 0.066031Train Epoch: 4 [239104/702208 (34%)]	Loss: 0.043857Train Epoch: 4 [240000/702208 (34%)]	Loss: 0.085201Train Epoch: 4 [240128/702208 (34%)]	Loss: 0.033038Train Epoch: 4 [241024/702208 (34%)]	Loss: 0.061952Train Epoch: 4 [242048/702208 (34%)]	Loss: 0.042933Train Epoch: 4 [243072/702208 (35%)]	Loss: 0.060150Train Epoch: 4 [244096/702208 (35%)]	Loss: 0.147101Train Epoch: 4 [245120/702208 (35%)]	Loss: 0.047995Train Epoch: 4 [246016/702208 (35%)]	Loss: 0.044177Train Epoch: 4 [247040/702208 (35%)]	Loss: 0.097341Train Epoch: 4 [248064/702208 (35%)]	Loss: 0.064806Train Epoch: 4 [249088/702208 (35%)]	Loss: 0.060882Train Epoch: 4 [250112/702208 (36%)]	Loss: 0.028747
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8000 / 8283] 96 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-2356736-total-97.69-class0-96.58-class1-99.71

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [11987 / 12833] 93 %
Accuracy of the network on train loader class  1: [7096 / 7135] 99 %
Train Epoch: 4 [251008/702208 (36%)]	Loss: 0.037475Train Epoch: 4 [252032/702208 (36%)]	Loss: 0.068912Train Epoch: 4 [253056/702208 (36%)]	Loss: 0.055885Train Epoch: 4 [254080/702208 (36%)]	Loss: 0.092833Train Epoch: 4 [255104/702208 (36%)]	Loss: 0.056443Train Epoch: 4 [256000/702208 (36%)]	Loss: 0.092475Train Epoch: 4 [256128/702208 (36%)]	Loss: 0.081985Train Epoch: 4 [257024/702208 (37%)]	Loss: 0.138172Train Epoch: 4 [258048/702208 (37%)]	Loss: 0.082803Train Epoch: 4 [259072/702208 (37%)]	Loss: 0.027979Train Epoch: 4 [260096/702208 (37%)]	Loss: 0.056053Train Epoch: 4 [261120/702208 (37%)]	Loss: 0.095061Train Epoch: 4 [262016/702208 (37%)]	Loss: 0.063936Train Epoch: 4 [263040/702208 (37%)]	Loss: 0.037310Train Epoch: 4 [264064/702208 (38%)]	Loss: 0.071150Train Epoch: 4 [265088/702208 (38%)]	Loss: 0.093767Train Epoch: 4 [266112/702208 (38%)]	Loss: 0.090831Train Epoch: 4 [267008/702208 (38%)]	Loss: 0.037034Train Epoch: 4 [268032/702208 (38%)]	Loss: 0.048151Train Epoch: 4 [269056/702208 (38%)]	Loss: 0.058822Train Epoch: 4 [270080/702208 (38%)]	Loss: 0.100501Train Epoch: 4 [271104/702208 (39%)]	Loss: 0.072006Train Epoch: 4 [272000/702208 (39%)]	Loss: 0.112187Train Epoch: 4 [272128/702208 (39%)]	Loss: 0.111899Train Epoch: 4 [273024/702208 (39%)]	Loss: 0.021809Train Epoch: 4 [274048/702208 (39%)]	Loss: 0.115222Train Epoch: 4 [275072/702208 (39%)]	Loss: 0.098069
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8114 / 8283] 97 %
Accuracy of the network on test loader class  1: [4490 / 4517] 99 %

Writing model: iterations-2381696-total-98.47-class0-97.96000000000001-class1-99.4
Train Epoch: 4 [276096/702208 (39%)]	Loss: 0.083062Train Epoch: 4 [277120/702208 (39%)]	Loss: 0.049143Train Epoch: 4 [278016/702208 (40%)]	Loss: 0.093855Train Epoch: 4 [279040/702208 (40%)]	Loss: 0.155611Train Epoch: 4 [280064/702208 (40%)]	Loss: 0.081751Train Epoch: 4 [281088/702208 (40%)]	Loss: 0.077906Train Epoch: 4 [282112/702208 (40%)]	Loss: 0.063740Train Epoch: 4 [283008/702208 (40%)]	Loss: 0.072667Train Epoch: 4 [284032/702208 (40%)]	Loss: 0.047875Train Epoch: 4 [285056/702208 (41%)]	Loss: 0.057348Train Epoch: 4 [286080/702208 (41%)]	Loss: 0.080591Train Epoch: 4 [287104/702208 (41%)]	Loss: 0.062662Train Epoch: 4 [288000/702208 (41%)]	Loss: 0.074420Train Epoch: 4 [288128/702208 (41%)]	Loss: 0.057086Train Epoch: 4 [289024/702208 (41%)]	Loss: 0.047679Train Epoch: 4 [290048/702208 (41%)]	Loss: 0.097050Train Epoch: 4 [291072/702208 (41%)]	Loss: 0.076725Train Epoch: 4 [292096/702208 (42%)]	Loss: 0.030784Train Epoch: 4 [293120/702208 (42%)]	Loss: 0.115446Train Epoch: 4 [294016/702208 (42%)]	Loss: 0.037545Train Epoch: 4 [295040/702208 (42%)]	Loss: 0.082255Train Epoch: 4 [296064/702208 (42%)]	Loss: 0.092051Train Epoch: 4 [297088/702208 (42%)]	Loss: 0.086431Train Epoch: 4 [298112/702208 (42%)]	Loss: 0.112201Train Epoch: 4 [299008/702208 (43%)]	Loss: 0.103987Train Epoch: 4 [300032/702208 (43%)]	Loss: 0.124543
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7841 / 8283] 94 %
Accuracy of the network on test loader class  1: [4491 / 4517] 99 %

Writing model: iterations-2406656-total-96.34-class0-94.66-class1-99.42

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 89 %
Accuracy of the network on train loader class  0: [10987 / 12833] 85 %
Accuracy of the network on train loader class  1: [6830 / 7135] 95 %
Train Epoch: 4 [301056/702208 (43%)]	Loss: 0.030098Train Epoch: 4 [302080/702208 (43%)]	Loss: 0.107189Train Epoch: 4 [303104/702208 (43%)]	Loss: 0.047177Train Epoch: 4 [304000/702208 (43%)]	Loss: 0.080012Train Epoch: 4 [304128/702208 (43%)]	Loss: 0.041720Train Epoch: 4 [305024/702208 (43%)]	Loss: 0.128651Train Epoch: 4 [306048/702208 (44%)]	Loss: 0.122905Train Epoch: 4 [307072/702208 (44%)]	Loss: 0.154597Train Epoch: 4 [308096/702208 (44%)]	Loss: 0.019602Train Epoch: 4 [309120/702208 (44%)]	Loss: 0.038010Train Epoch: 4 [310016/702208 (44%)]	Loss: 0.033434Train Epoch: 4 [311040/702208 (44%)]	Loss: 0.046901Train Epoch: 4 [312064/702208 (44%)]	Loss: 0.035395Train Epoch: 4 [313088/702208 (45%)]	Loss: 0.045550Train Epoch: 4 [314112/702208 (45%)]	Loss: 0.095891Train Epoch: 4 [315008/702208 (45%)]	Loss: 0.154070Train Epoch: 4 [316032/702208 (45%)]	Loss: 0.024220Train Epoch: 4 [317056/702208 (45%)]	Loss: 0.099644Train Epoch: 4 [318080/702208 (45%)]	Loss: 0.059376Train Epoch: 4 [319104/702208 (45%)]	Loss: 0.086809Train Epoch: 4 [320000/702208 (46%)]	Loss: 0.072057Train Epoch: 4 [320128/702208 (46%)]	Loss: 0.069954Train Epoch: 4 [321024/702208 (46%)]	Loss: 0.072960Train Epoch: 4 [322048/702208 (46%)]	Loss: 0.132981Train Epoch: 4 [323072/702208 (46%)]	Loss: 0.058068Train Epoch: 4 [324096/702208 (46%)]	Loss: 0.041757Train Epoch: 4 [325120/702208 (46%)]	Loss: 0.201625
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8064 / 8283] 97 %
Accuracy of the network on test loader class  1: [4499 / 4517] 99 %

Writing model: iterations-2431744-total-98.15-class0-97.36-class1-99.6
Train Epoch: 4 [326016/702208 (46%)]	Loss: 0.050956Train Epoch: 4 [327040/702208 (47%)]	Loss: 0.064173Train Epoch: 4 [328064/702208 (47%)]	Loss: 0.067906Train Epoch: 4 [329088/702208 (47%)]	Loss: 0.032168Train Epoch: 4 [330112/702208 (47%)]	Loss: 0.056557Train Epoch: 4 [331008/702208 (47%)]	Loss: 0.044525Train Epoch: 4 [332032/702208 (47%)]	Loss: 0.035679Train Epoch: 4 [333056/702208 (47%)]	Loss: 0.023841Train Epoch: 4 [334080/702208 (48%)]	Loss: 0.031813Train Epoch: 4 [335104/702208 (48%)]	Loss: 0.046339Train Epoch: 4 [336000/702208 (48%)]	Loss: 0.120615Train Epoch: 4 [336128/702208 (48%)]	Loss: 0.033753Train Epoch: 4 [337024/702208 (48%)]	Loss: 0.034764Train Epoch: 4 [338048/702208 (48%)]	Loss: 0.081542Train Epoch: 4 [339072/702208 (48%)]	Loss: 0.100148Train Epoch: 4 [340096/702208 (48%)]	Loss: 0.054197Train Epoch: 4 [341120/702208 (49%)]	Loss: 0.066141Train Epoch: 4 [342016/702208 (49%)]	Loss: 0.108765Train Epoch: 4 [343040/702208 (49%)]	Loss: 0.084473Train Epoch: 4 [344064/702208 (49%)]	Loss: 0.089010Train Epoch: 4 [345088/702208 (49%)]	Loss: 0.041406Train Epoch: 4 [346112/702208 (49%)]	Loss: 0.112113Train Epoch: 4 [347008/702208 (49%)]	Loss: 0.039584Train Epoch: 4 [348032/702208 (50%)]	Loss: 0.133337Train Epoch: 4 [349056/702208 (50%)]	Loss: 0.035788Train Epoch: 4 [350080/702208 (50%)]	Loss: 0.077545
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8023 / 8283] 96 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-2456704-total-97.78999999999999-class0-96.86-class1-99.49

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12079 / 12833] 94 %
Accuracy of the network on train loader class  1: [7089 / 7135] 99 %
Train Epoch: 4 [351104/702208 (50%)]	Loss: 0.025150Train Epoch: 4 [352000/702208 (50%)]	Loss: 0.048835Train Epoch: 4 [352128/702208 (50%)]	Loss: 0.148125Train Epoch: 4 [353024/702208 (50%)]	Loss: 0.051030Train Epoch: 4 [354048/702208 (50%)]	Loss: 0.079022Train Epoch: 4 [355072/702208 (51%)]	Loss: 0.041326Train Epoch: 4 [356096/702208 (51%)]	Loss: 0.074403Train Epoch: 4 [357120/702208 (51%)]	Loss: 0.077689Train Epoch: 4 [358016/702208 (51%)]	Loss: 0.054244Train Epoch: 4 [359040/702208 (51%)]	Loss: 0.077284Train Epoch: 4 [360064/702208 (51%)]	Loss: 0.041676Train Epoch: 4 [361088/702208 (51%)]	Loss: 0.057745Train Epoch: 4 [362112/702208 (52%)]	Loss: 0.041602Train Epoch: 4 [363008/702208 (52%)]	Loss: 0.031348Train Epoch: 4 [364032/702208 (52%)]	Loss: 0.115680Train Epoch: 4 [365056/702208 (52%)]	Loss: 0.035583Train Epoch: 4 [366080/702208 (52%)]	Loss: 0.015887Train Epoch: 4 [367104/702208 (52%)]	Loss: 0.081629Train Epoch: 4 [368000/702208 (52%)]	Loss: 0.029484Train Epoch: 4 [368128/702208 (52%)]	Loss: 0.158661Train Epoch: 4 [369024/702208 (53%)]	Loss: 0.129573Train Epoch: 4 [370048/702208 (53%)]	Loss: 0.025520Train Epoch: 4 [371072/702208 (53%)]	Loss: 0.067325Train Epoch: 4 [372096/702208 (53%)]	Loss: 0.042673Train Epoch: 4 [373120/702208 (53%)]	Loss: 0.039190Train Epoch: 4 [374016/702208 (53%)]	Loss: 0.169242Train Epoch: 4 [375040/702208 (53%)]	Loss: 0.091121
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8055 / 8283] 97 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-2481664-total-98.09-class0-97.25-class1-99.62
Train Epoch: 4 [376064/702208 (54%)]	Loss: 0.046365Train Epoch: 4 [377088/702208 (54%)]	Loss: 0.044953Train Epoch: 4 [378112/702208 (54%)]	Loss: 0.041174Train Epoch: 4 [379008/702208 (54%)]	Loss: 0.074935Train Epoch: 4 [380032/702208 (54%)]	Loss: 0.044925Train Epoch: 4 [381056/702208 (54%)]	Loss: 0.091496Train Epoch: 4 [382080/702208 (54%)]	Loss: 0.089413Train Epoch: 4 [383104/702208 (55%)]	Loss: 0.022480Train Epoch: 4 [384000/702208 (55%)]	Loss: 0.077139Train Epoch: 4 [384128/702208 (55%)]	Loss: 0.060706Train Epoch: 4 [385024/702208 (55%)]	Loss: 0.057800Train Epoch: 4 [386048/702208 (55%)]	Loss: 0.111148Train Epoch: 4 [387072/702208 (55%)]	Loss: 0.069921Train Epoch: 4 [388096/702208 (55%)]	Loss: 0.064801Train Epoch: 4 [389120/702208 (55%)]	Loss: 0.090278Train Epoch: 4 [390016/702208 (56%)]	Loss: 0.058608Train Epoch: 4 [391040/702208 (56%)]	Loss: 0.030787Train Epoch: 4 [392064/702208 (56%)]	Loss: 0.093472Train Epoch: 4 [393088/702208 (56%)]	Loss: 0.051505Train Epoch: 4 [394112/702208 (56%)]	Loss: 0.101735Train Epoch: 4 [395008/702208 (56%)]	Loss: 0.137510Train Epoch: 4 [396032/702208 (56%)]	Loss: 0.061627Train Epoch: 4 [397056/702208 (57%)]	Loss: 0.101344Train Epoch: 4 [398080/702208 (57%)]	Loss: 0.043144Train Epoch: 4 [399104/702208 (57%)]	Loss: 0.053990Train Epoch: 4 [400000/702208 (57%)]	Loss: 0.030482
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8012 / 8283] 96 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-2506624-total-97.81-class0-96.73-class1-99.8

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12152 / 12833] 94 %
Accuracy of the network on train loader class  1: [7083 / 7135] 99 %
Train Epoch: 4 [400128/702208 (57%)]	Loss: 0.098068
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7935 / 8283] 95 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-2506752-total-97.22-class0-95.8-class1-99.82

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12111 / 12833] 94 %
Accuracy of the network on train loader class  1: [7086 / 7135] 99 %
Train Epoch: 4 [401024/702208 (57%)]	Loss: 0.059388Train Epoch: 4 [402048/702208 (57%)]	Loss: 0.044476Train Epoch: 4 [403072/702208 (57%)]	Loss: 0.031879Train Epoch: 4 [404096/702208 (58%)]	Loss: 0.057698Train Epoch: 4 [405120/702208 (58%)]	Loss: 0.100713Train Epoch: 4 [406016/702208 (58%)]	Loss: 0.104227Train Epoch: 4 [407040/702208 (58%)]	Loss: 0.031477Train Epoch: 4 [408064/702208 (58%)]	Loss: 0.193191Train Epoch: 4 [409088/702208 (58%)]	Loss: 0.039477Train Epoch: 4 [410112/702208 (58%)]	Loss: 0.058903Train Epoch: 4 [411008/702208 (59%)]	Loss: 0.058755Train Epoch: 4 [412032/702208 (59%)]	Loss: 0.086959Train Epoch: 4 [413056/702208 (59%)]	Loss: 0.090185Train Epoch: 4 [414080/702208 (59%)]	Loss: 0.051782Train Epoch: 4 [415104/702208 (59%)]	Loss: 0.042845Train Epoch: 4 [416000/702208 (59%)]	Loss: 0.146120Train Epoch: 4 [416128/702208 (59%)]	Loss: 0.023514Train Epoch: 4 [417024/702208 (59%)]	Loss: 0.140574Train Epoch: 4 [418048/702208 (60%)]	Loss: 0.042907Train Epoch: 4 [419072/702208 (60%)]	Loss: 0.124293Train Epoch: 4 [420096/702208 (60%)]	Loss: 0.127184Train Epoch: 4 [421120/702208 (60%)]	Loss: 0.086443Train Epoch: 4 [422016/702208 (60%)]	Loss: 0.066042Train Epoch: 4 [423040/702208 (60%)]	Loss: 0.115970Train Epoch: 4 [424064/702208 (60%)]	Loss: 0.107650Train Epoch: 4 [425088/702208 (61%)]	Loss: 0.066824
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8073 / 8283] 97 %
Accuracy of the network on test loader class  1: [4498 / 4517] 99 %

Writing model: iterations-2531712-total-98.21-class0-97.46000000000001-class1-99.58
Train Epoch: 4 [426112/702208 (61%)]	Loss: 0.100970Train Epoch: 4 [427008/702208 (61%)]	Loss: 0.064288Train Epoch: 4 [428032/702208 (61%)]	Loss: 0.045781Train Epoch: 4 [429056/702208 (61%)]	Loss: 0.060871Train Epoch: 4 [430080/702208 (61%)]	Loss: 0.058649Train Epoch: 4 [431104/702208 (61%)]	Loss: 0.054626Train Epoch: 4 [432000/702208 (62%)]	Loss: 0.038375Train Epoch: 4 [432128/702208 (62%)]	Loss: 0.076578Train Epoch: 4 [433024/702208 (62%)]	Loss: 0.080352Train Epoch: 4 [434048/702208 (62%)]	Loss: 0.054230Train Epoch: 4 [435072/702208 (62%)]	Loss: 0.035551Train Epoch: 4 [436096/702208 (62%)]	Loss: 0.083067Train Epoch: 4 [437120/702208 (62%)]	Loss: 0.040291Train Epoch: 4 [438016/702208 (62%)]	Loss: 0.086299Train Epoch: 4 [439040/702208 (63%)]	Loss: 0.030582Train Epoch: 4 [440064/702208 (63%)]	Loss: 0.040908Train Epoch: 4 [441088/702208 (63%)]	Loss: 0.071257Train Epoch: 4 [442112/702208 (63%)]	Loss: 0.054442Train Epoch: 4 [443008/702208 (63%)]	Loss: 0.077801Train Epoch: 4 [444032/702208 (63%)]	Loss: 0.027653Train Epoch: 4 [445056/702208 (63%)]	Loss: 0.043344Train Epoch: 4 [446080/702208 (64%)]	Loss: 0.037828Train Epoch: 4 [447104/702208 (64%)]	Loss: 0.057621Train Epoch: 4 [448000/702208 (64%)]	Loss: 0.051050Train Epoch: 4 [448128/702208 (64%)]	Loss: 0.096779Train Epoch: 4 [449024/702208 (64%)]	Loss: 0.056865Train Epoch: 4 [450048/702208 (64%)]	Loss: 0.069605
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7978 / 8283] 96 %
Accuracy of the network on test loader class  1: [4499 / 4517] 99 %

Writing model: iterations-2556672-total-97.48-class0-96.32-class1-99.6

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 90 %
Accuracy of the network on train loader class  0: [11188 / 12833] 87 %
Accuracy of the network on train loader class  1: [6900 / 7135] 96 %
Train Epoch: 4 [451072/702208 (64%)]	Loss: 0.129175Train Epoch: 4 [452096/702208 (64%)]	Loss: 0.028337Train Epoch: 4 [453120/702208 (65%)]	Loss: 0.059847Train Epoch: 4 [454016/702208 (65%)]	Loss: 0.239056Train Epoch: 4 [455040/702208 (65%)]	Loss: 0.034717Train Epoch: 4 [456064/702208 (65%)]	Loss: 0.073084Train Epoch: 4 [457088/702208 (65%)]	Loss: 0.096663Train Epoch: 4 [458112/702208 (65%)]	Loss: 0.071486Train Epoch: 4 [459008/702208 (65%)]	Loss: 0.055430Train Epoch: 4 [460032/702208 (66%)]	Loss: 0.090573Train Epoch: 4 [461056/702208 (66%)]	Loss: 0.118401Train Epoch: 4 [462080/702208 (66%)]	Loss: 0.063871Train Epoch: 4 [463104/702208 (66%)]	Loss: 0.073331Train Epoch: 4 [464000/702208 (66%)]	Loss: 0.026835Train Epoch: 4 [464128/702208 (66%)]	Loss: 0.152120Train Epoch: 4 [465024/702208 (66%)]	Loss: 0.116607Train Epoch: 4 [466048/702208 (66%)]	Loss: 0.095965Train Epoch: 4 [467072/702208 (67%)]	Loss: 0.082828Train Epoch: 4 [468096/702208 (67%)]	Loss: 0.141280Train Epoch: 4 [469120/702208 (67%)]	Loss: 0.033136Train Epoch: 4 [470016/702208 (67%)]	Loss: 0.132805Train Epoch: 4 [471040/702208 (67%)]	Loss: 0.038299Train Epoch: 4 [472064/702208 (67%)]	Loss: 0.107790Train Epoch: 4 [473088/702208 (67%)]	Loss: 0.037724Train Epoch: 4 [474112/702208 (68%)]	Loss: 0.055058Train Epoch: 4 [475008/702208 (68%)]	Loss: 0.039147
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7846 / 8283] 94 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-2581632-total-96.49-class0-94.72-class1-99.72999999999999
Train Epoch: 4 [476032/702208 (68%)]	Loss: 0.183926Train Epoch: 4 [477056/702208 (68%)]	Loss: 0.038088Train Epoch: 4 [478080/702208 (68%)]	Loss: 0.068932Train Epoch: 4 [479104/702208 (68%)]	Loss: 0.047345Train Epoch: 4 [480000/702208 (68%)]	Loss: 0.040316Train Epoch: 4 [480128/702208 (68%)]	Loss: 0.112632Train Epoch: 4 [481024/702208 (69%)]	Loss: 0.066790Train Epoch: 4 [482048/702208 (69%)]	Loss: 0.113953Train Epoch: 4 [483072/702208 (69%)]	Loss: 0.110888Train Epoch: 4 [484096/702208 (69%)]	Loss: 0.044153Train Epoch: 4 [485120/702208 (69%)]	Loss: 0.046906Train Epoch: 4 [486016/702208 (69%)]	Loss: 0.047733Train Epoch: 4 [487040/702208 (69%)]	Loss: 0.039340Train Epoch: 4 [488064/702208 (70%)]	Loss: 0.068235Train Epoch: 4 [489088/702208 (70%)]	Loss: 0.095983Train Epoch: 4 [490112/702208 (70%)]	Loss: 0.054166Train Epoch: 4 [491008/702208 (70%)]	Loss: 0.126074Train Epoch: 4 [492032/702208 (70%)]	Loss: 0.071824Train Epoch: 4 [493056/702208 (70%)]	Loss: 0.082738Train Epoch: 4 [494080/702208 (70%)]	Loss: 0.120171Train Epoch: 4 [495104/702208 (71%)]	Loss: 0.052818Train Epoch: 4 [496000/702208 (71%)]	Loss: 0.043342Train Epoch: 4 [496128/702208 (71%)]	Loss: 0.039062Train Epoch: 4 [497024/702208 (71%)]	Loss: 0.094243Train Epoch: 4 [498048/702208 (71%)]	Loss: 0.063099Train Epoch: 4 [499072/702208 (71%)]	Loss: 0.092472Train Epoch: 4 [500096/702208 (71%)]	Loss: 0.057668
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8047 / 8283] 97 %
Accuracy of the network on test loader class  1: [4488 / 4517] 99 %

Writing model: iterations-2606720-total-97.92999999999999-class0-97.15-class1-99.36

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 93 %
Accuracy of the network on train loader class  0: [11799 / 12833] 91 %
Accuracy of the network on train loader class  1: [6932 / 7135] 97 %
Train Epoch: 4 [501120/702208 (71%)]	Loss: 0.104378Train Epoch: 4 [502016/702208 (71%)]	Loss: 0.022173Train Epoch: 4 [503040/702208 (72%)]	Loss: 0.042029Train Epoch: 4 [504064/702208 (72%)]	Loss: 0.052647Train Epoch: 4 [505088/702208 (72%)]	Loss: 0.085265Train Epoch: 4 [506112/702208 (72%)]	Loss: 0.105546Train Epoch: 4 [507008/702208 (72%)]	Loss: 0.080573Train Epoch: 4 [508032/702208 (72%)]	Loss: 0.064000Train Epoch: 4 [509056/702208 (72%)]	Loss: 0.067093Train Epoch: 4 [510080/702208 (73%)]	Loss: 0.085156Train Epoch: 4 [511104/702208 (73%)]	Loss: 0.163965Train Epoch: 4 [512000/702208 (73%)]	Loss: 0.032986Train Epoch: 4 [512128/702208 (73%)]	Loss: 0.140083Train Epoch: 4 [513024/702208 (73%)]	Loss: 0.064403Train Epoch: 4 [514048/702208 (73%)]	Loss: 0.059034Train Epoch: 4 [515072/702208 (73%)]	Loss: 0.034332Train Epoch: 4 [516096/702208 (73%)]	Loss: 0.114881Train Epoch: 4 [517120/702208 (74%)]	Loss: 0.115141Train Epoch: 4 [518016/702208 (74%)]	Loss: 0.093589Train Epoch: 4 [519040/702208 (74%)]	Loss: 0.090081Train Epoch: 4 [520064/702208 (74%)]	Loss: 0.074598Train Epoch: 4 [521088/702208 (74%)]	Loss: 0.013752Train Epoch: 4 [522112/702208 (74%)]	Loss: 0.032822Train Epoch: 4 [523008/702208 (74%)]	Loss: 0.112448Train Epoch: 4 [524032/702208 (75%)]	Loss: 0.024119Train Epoch: 4 [525056/702208 (75%)]	Loss: 0.128775
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7974 / 8283] 96 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-2631680-total-97.49-class0-96.27-class1-99.72999999999999
Train Epoch: 4 [526080/702208 (75%)]	Loss: 0.092886Train Epoch: 4 [527104/702208 (75%)]	Loss: 0.105598Train Epoch: 4 [528000/702208 (75%)]	Loss: 0.110843Train Epoch: 4 [528128/702208 (75%)]	Loss: 0.094573Train Epoch: 4 [529024/702208 (75%)]	Loss: 0.069593Train Epoch: 4 [530048/702208 (75%)]	Loss: 0.130212Train Epoch: 4 [531072/702208 (76%)]	Loss: 0.109934Train Epoch: 4 [532096/702208 (76%)]	Loss: 0.070004Train Epoch: 4 [533120/702208 (76%)]	Loss: 0.038685Train Epoch: 4 [534016/702208 (76%)]	Loss: 0.072984Train Epoch: 4 [535040/702208 (76%)]	Loss: 0.045633Train Epoch: 4 [536064/702208 (76%)]	Loss: 0.088488Train Epoch: 4 [537088/702208 (76%)]	Loss: 0.055976Train Epoch: 4 [538112/702208 (77%)]	Loss: 0.045599Train Epoch: 4 [539008/702208 (77%)]	Loss: 0.043243Train Epoch: 4 [540032/702208 (77%)]	Loss: 0.092378Train Epoch: 4 [541056/702208 (77%)]	Loss: 0.089569Train Epoch: 4 [542080/702208 (77%)]	Loss: 0.041283Train Epoch: 4 [543104/702208 (77%)]	Loss: 0.075081Train Epoch: 4 [544000/702208 (77%)]	Loss: 0.166859Train Epoch: 4 [544128/702208 (77%)]	Loss: 0.070392Train Epoch: 4 [545024/702208 (78%)]	Loss: 0.075922Train Epoch: 4 [546048/702208 (78%)]	Loss: 0.087827Train Epoch: 4 [547072/702208 (78%)]	Loss: 0.154539Train Epoch: 4 [548096/702208 (78%)]	Loss: 0.085014Train Epoch: 4 [549120/702208 (78%)]	Loss: 0.072588Train Epoch: 4 [550016/702208 (78%)]	Loss: 0.116422
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8077 / 8283] 97 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-2656640-total-98.22-class0-97.50999999999999-class1-99.51

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12220 / 12833] 95 %
Accuracy of the network on train loader class  1: [7083 / 7135] 99 %
Train Epoch: 4 [551040/702208 (78%)]	Loss: 0.024289Train Epoch: 4 [552064/702208 (79%)]	Loss: 0.046857Train Epoch: 4 [553088/702208 (79%)]	Loss: 0.062282Train Epoch: 4 [554112/702208 (79%)]	Loss: 0.038987Train Epoch: 4 [555008/702208 (79%)]	Loss: 0.168150Train Epoch: 4 [556032/702208 (79%)]	Loss: 0.052150Train Epoch: 4 [557056/702208 (79%)]	Loss: 0.150731Train Epoch: 4 [558080/702208 (79%)]	Loss: 0.023175Train Epoch: 4 [559104/702208 (80%)]	Loss: 0.076996Train Epoch: 4 [560000/702208 (80%)]	Loss: 0.116090Train Epoch: 4 [560128/702208 (80%)]	Loss: 0.076063Train Epoch: 4 [561024/702208 (80%)]	Loss: 0.030744Train Epoch: 4 [562048/702208 (80%)]	Loss: 0.057934Train Epoch: 4 [563072/702208 (80%)]	Loss: 0.045598Train Epoch: 4 [564096/702208 (80%)]	Loss: 0.089093Train Epoch: 4 [565120/702208 (80%)]	Loss: 0.063072Train Epoch: 4 [566016/702208 (81%)]	Loss: 0.107263Train Epoch: 4 [567040/702208 (81%)]	Loss: 0.060681Train Epoch: 4 [568064/702208 (81%)]	Loss: 0.038198Train Epoch: 4 [569088/702208 (81%)]	Loss: 0.033743Train Epoch: 4 [570112/702208 (81%)]	Loss: 0.080413Train Epoch: 4 [571008/702208 (81%)]	Loss: 0.012647Train Epoch: 4 [572032/702208 (81%)]	Loss: 0.041822Train Epoch: 4 [573056/702208 (82%)]	Loss: 0.099724Train Epoch: 4 [574080/702208 (82%)]	Loss: 0.035960Train Epoch: 4 [575104/702208 (82%)]	Loss: 0.054363
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 49 %
Accuracy of the network on test loader class  0: [1885 / 8283] 22 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-2681728-total-49.95-class0-22.759999999999998-class1-99.82
Train Epoch: 4 [576000/702208 (82%)]	Loss: 0.030390Train Epoch: 4 [576128/702208 (82%)]	Loss: 0.093971Train Epoch: 4 [577024/702208 (82%)]	Loss: 0.050761Train Epoch: 4 [578048/702208 (82%)]	Loss: 0.046394Train Epoch: 4 [579072/702208 (82%)]	Loss: 0.032165Train Epoch: 4 [580096/702208 (83%)]	Loss: 0.055678Train Epoch: 4 [581120/702208 (83%)]	Loss: 0.098507Train Epoch: 4 [582016/702208 (83%)]	Loss: 0.060575Train Epoch: 4 [583040/702208 (83%)]	Loss: 0.078913Train Epoch: 4 [584064/702208 (83%)]	Loss: 0.074377Train Epoch: 4 [585088/702208 (83%)]	Loss: 0.075277Train Epoch: 4 [586112/702208 (83%)]	Loss: 0.076841Train Epoch: 4 [587008/702208 (84%)]	Loss: 0.085393Train Epoch: 4 [588032/702208 (84%)]	Loss: 0.073395Train Epoch: 4 [589056/702208 (84%)]	Loss: 0.042067Train Epoch: 4 [590080/702208 (84%)]	Loss: 0.027592Train Epoch: 4 [591104/702208 (84%)]	Loss: 0.088824Train Epoch: 4 [592000/702208 (84%)]	Loss: 0.016794Train Epoch: 4 [592128/702208 (84%)]	Loss: 0.080359Train Epoch: 4 [593024/702208 (84%)]	Loss: 0.056438Train Epoch: 4 [594048/702208 (85%)]	Loss: 0.046288Train Epoch: 4 [595072/702208 (85%)]	Loss: 0.045603Train Epoch: 4 [596096/702208 (85%)]	Loss: 0.133404Train Epoch: 4 [597120/702208 (85%)]	Loss: 0.084202Train Epoch: 4 [598016/702208 (85%)]	Loss: 0.066794Train Epoch: 4 [599040/702208 (85%)]	Loss: 0.065698Train Epoch: 4 [600064/702208 (85%)]	Loss: 0.089873
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8023 / 8283] 96 %
Accuracy of the network on test loader class  1: [4501 / 4517] 99 %

Writing model: iterations-2706688-total-97.84-class0-96.86-class1-99.65

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12291 / 12833] 95 %
Accuracy of the network on train loader class  1: [7020 / 7135] 98 %
Train Epoch: 4 [601088/702208 (86%)]	Loss: 0.032801Train Epoch: 4 [602112/702208 (86%)]	Loss: 0.079157Train Epoch: 4 [603008/702208 (86%)]	Loss: 0.065634Train Epoch: 4 [604032/702208 (86%)]	Loss: 0.085782Train Epoch: 4 [605056/702208 (86%)]	Loss: 0.051915Train Epoch: 4 [606080/702208 (86%)]	Loss: 0.019214Train Epoch: 4 [607104/702208 (86%)]	Loss: 0.037782Train Epoch: 4 [608000/702208 (87%)]	Loss: 0.064827Train Epoch: 4 [608128/702208 (87%)]	Loss: 0.027700Train Epoch: 4 [609024/702208 (87%)]	Loss: 0.094315Train Epoch: 4 [610048/702208 (87%)]	Loss: 0.065802Train Epoch: 4 [611072/702208 (87%)]	Loss: 0.044297Train Epoch: 4 [612096/702208 (87%)]	Loss: 0.082921Train Epoch: 4 [613120/702208 (87%)]	Loss: 0.050546Train Epoch: 4 [614016/702208 (87%)]	Loss: 0.083359Train Epoch: 4 [615040/702208 (88%)]	Loss: 0.094377Train Epoch: 4 [616064/702208 (88%)]	Loss: 0.075682Train Epoch: 4 [617088/702208 (88%)]	Loss: 0.099253Train Epoch: 4 [618112/702208 (88%)]	Loss: 0.094406Train Epoch: 4 [619008/702208 (88%)]	Loss: 0.041298Train Epoch: 4 [620032/702208 (88%)]	Loss: 0.084154Train Epoch: 4 [621056/702208 (88%)]	Loss: 0.105429Train Epoch: 4 [622080/702208 (89%)]	Loss: 0.081281Train Epoch: 4 [623104/702208 (89%)]	Loss: 0.089884Train Epoch: 4 [624000/702208 (89%)]	Loss: 0.088329Train Epoch: 4 [624128/702208 (89%)]	Loss: 0.049325Train Epoch: 4 [625024/702208 (89%)]	Loss: 0.088030
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8016 / 8283] 96 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-2731648-total-97.82-class0-96.78-class1-99.72999999999999
Train Epoch: 4 [626048/702208 (89%)]	Loss: 0.077298Train Epoch: 4 [627072/702208 (89%)]	Loss: 0.043834Train Epoch: 4 [628096/702208 (89%)]	Loss: 0.125509Train Epoch: 4 [629120/702208 (90%)]	Loss: 0.034686Train Epoch: 4 [630016/702208 (90%)]	Loss: 0.062720Train Epoch: 4 [631040/702208 (90%)]	Loss: 0.040664Train Epoch: 4 [632064/702208 (90%)]	Loss: 0.045031Train Epoch: 4 [633088/702208 (90%)]	Loss: 0.085985Train Epoch: 4 [634112/702208 (90%)]	Loss: 0.053489Train Epoch: 4 [635008/702208 (90%)]	Loss: 0.030181Train Epoch: 4 [636032/702208 (91%)]	Loss: 0.054063Train Epoch: 4 [637056/702208 (91%)]	Loss: 0.105391Train Epoch: 4 [638080/702208 (91%)]	Loss: 0.135437Train Epoch: 4 [639104/702208 (91%)]	Loss: 0.066063Train Epoch: 4 [640000/702208 (91%)]	Loss: 0.034274Train Epoch: 4 [640128/702208 (91%)]	Loss: 0.098757Train Epoch: 4 [641024/702208 (91%)]	Loss: 0.111731Train Epoch: 4 [642048/702208 (91%)]	Loss: 0.096895Train Epoch: 4 [643072/702208 (92%)]	Loss: 0.055734Train Epoch: 4 [644096/702208 (92%)]	Loss: 0.073578Train Epoch: 4 [645120/702208 (92%)]	Loss: 0.051379Train Epoch: 4 [646016/702208 (92%)]	Loss: 0.061001Train Epoch: 4 [647040/702208 (92%)]	Loss: 0.030888Train Epoch: 4 [648064/702208 (92%)]	Loss: 0.051768Train Epoch: 4 [649088/702208 (92%)]	Loss: 0.020114Train Epoch: 4 [650112/702208 (93%)]	Loss: 0.109427
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8149 / 8283] 98 %
Accuracy of the network on test loader class  1: [4482 / 4517] 99 %

Writing model: iterations-2756736-total-98.68-class0-98.38-class1-99.22999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12300 / 12833] 95 %
Accuracy of the network on train loader class  1: [7065 / 7135] 99 %
Train Epoch: 4 [651008/702208 (93%)]	Loss: 0.019709Train Epoch: 4 [652032/702208 (93%)]	Loss: 0.023313Train Epoch: 4 [653056/702208 (93%)]	Loss: 0.052162Train Epoch: 4 [654080/702208 (93%)]	Loss: 0.043558Train Epoch: 4 [655104/702208 (93%)]	Loss: 0.085700Train Epoch: 4 [656000/702208 (93%)]	Loss: 0.133445Train Epoch: 4 [656128/702208 (93%)]	Loss: 0.056116Train Epoch: 4 [657024/702208 (94%)]	Loss: 0.033109Train Epoch: 4 [658048/702208 (94%)]	Loss: 0.052117Train Epoch: 4 [659072/702208 (94%)]	Loss: 0.062465Train Epoch: 4 [660096/702208 (94%)]	Loss: 0.078150Train Epoch: 4 [661120/702208 (94%)]	Loss: 0.092817Train Epoch: 4 [662016/702208 (94%)]	Loss: 0.081522Train Epoch: 4 [663040/702208 (94%)]	Loss: 0.042592Train Epoch: 4 [664064/702208 (95%)]	Loss: 0.060877Train Epoch: 4 [665088/702208 (95%)]	Loss: 0.052336Train Epoch: 4 [666112/702208 (95%)]	Loss: 0.062505Train Epoch: 4 [667008/702208 (95%)]	Loss: 0.142452Train Epoch: 4 [668032/702208 (95%)]	Loss: 0.048075Train Epoch: 4 [669056/702208 (95%)]	Loss: 0.066972Train Epoch: 4 [670080/702208 (95%)]	Loss: 0.087924Train Epoch: 4 [671104/702208 (96%)]	Loss: 0.070056Train Epoch: 4 [672000/702208 (96%)]	Loss: 0.053170Train Epoch: 4 [672128/702208 (96%)]	Loss: 0.072627Train Epoch: 4 [673024/702208 (96%)]	Loss: 0.029925Train Epoch: 4 [674048/702208 (96%)]	Loss: 0.052050Train Epoch: 4 [675072/702208 (96%)]	Loss: 0.085091
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8046 / 8283] 97 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-2781696-total-97.98-class0-97.14-class1-99.51
Train Epoch: 4 [676096/702208 (96%)]	Loss: 0.144664Train Epoch: 4 [677120/702208 (96%)]	Loss: 0.036132Train Epoch: 4 [678016/702208 (97%)]	Loss: 0.041312Train Epoch: 4 [679040/702208 (97%)]	Loss: 0.060205Train Epoch: 4 [680064/702208 (97%)]	Loss: 0.091071Train Epoch: 4 [681088/702208 (97%)]	Loss: 0.038799Train Epoch: 4 [682112/702208 (97%)]	Loss: 0.054544Train Epoch: 4 [683008/702208 (97%)]	Loss: 0.048236Train Epoch: 4 [684032/702208 (97%)]	Loss: 0.074483Train Epoch: 4 [685056/702208 (98%)]	Loss: 0.063745Train Epoch: 4 [686080/702208 (98%)]	Loss: 0.038868Train Epoch: 4 [687104/702208 (98%)]	Loss: 0.011895Train Epoch: 4 [688000/702208 (98%)]	Loss: 0.041348Train Epoch: 4 [688128/702208 (98%)]	Loss: 0.066705Train Epoch: 4 [689024/702208 (98%)]	Loss: 0.050813Train Epoch: 4 [690048/702208 (98%)]	Loss: 0.086236Train Epoch: 4 [691072/702208 (98%)]	Loss: 0.054859Train Epoch: 4 [692096/702208 (99%)]	Loss: 0.067269Train Epoch: 4 [693120/702208 (99%)]	Loss: 0.017924Train Epoch: 4 [694016/702208 (99%)]	Loss: 0.102666Train Epoch: 4 [695040/702208 (99%)]	Loss: 0.124627Train Epoch: 4 [696064/702208 (99%)]	Loss: 0.115413Train Epoch: 4 [697088/702208 (99%)]	Loss: 0.133963Train Epoch: 4 [698112/702208 (99%)]	Loss: 0.042886Train Epoch: 4 [699008/702208 (100%)]	Loss: 0.092927Train Epoch: 4 [700032/702208 (100%)]	Loss: 0.087193
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8122 / 8283] 98 %
Accuracy of the network on test loader class  1: [4483 / 4517] 99 %

Writing model: iterations-2806656-total-98.48-class0-98.06-class1-99.25

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [12059 / 12833] 93 %
Accuracy of the network on train loader class  1: [6750 / 7135] 94 %
Train Epoch: 4 [701056/702208 (100%)]	Loss: 0.055294Train Epoch: 4 [702080/702208 (100%)]	Loss: 0.059048
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7936 / 8283] 95 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %
Train Epoch: 5 [1024/702208 (0%)]	Loss: 0.059541Train Epoch: 5 [2048/702208 (0%)]	Loss: 0.046978Train Epoch: 5 [3072/702208 (0%)]	Loss: 0.107404Train Epoch: 5 [4096/702208 (1%)]	Loss: 0.036147Train Epoch: 5 [5120/702208 (1%)]	Loss: 0.080925Train Epoch: 5 [6016/702208 (1%)]	Loss: 0.106606Train Epoch: 5 [7040/702208 (1%)]	Loss: 0.056968Train Epoch: 5 [8064/702208 (1%)]	Loss: 0.089073Train Epoch: 5 [9088/702208 (1%)]	Loss: 0.094077Train Epoch: 5 [10112/702208 (1%)]	Loss: 0.056674Train Epoch: 5 [11008/702208 (2%)]	Loss: 0.084195Train Epoch: 5 [12032/702208 (2%)]	Loss: 0.109737Train Epoch: 5 [13056/702208 (2%)]	Loss: 0.058039Train Epoch: 5 [14080/702208 (2%)]	Loss: 0.033598Train Epoch: 5 [15104/702208 (2%)]	Loss: 0.039171Train Epoch: 5 [16000/702208 (2%)]	Loss: 0.070711Train Epoch: 5 [16128/702208 (2%)]	Loss: 0.063872Train Epoch: 5 [17024/702208 (2%)]	Loss: 0.076993Train Epoch: 5 [18048/702208 (3%)]	Loss: 0.118131Train Epoch: 5 [19072/702208 (3%)]	Loss: 0.046421Train Epoch: 5 [20096/702208 (3%)]	Loss: 0.107977Train Epoch: 5 [21120/702208 (3%)]	Loss: 0.025483Train Epoch: 5 [22016/702208 (3%)]	Loss: 0.092747Train Epoch: 5 [23040/702208 (3%)]	Loss: 0.023858Train Epoch: 5 [24064/702208 (3%)]	Loss: 0.087385Train Epoch: 5 [25088/702208 (4%)]	Loss: 0.032040
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8029 / 8283] 96 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-2833920-total-97.91-class0-96.93-class1-99.69
Train Epoch: 5 [26112/702208 (4%)]	Loss: 0.089647Train Epoch: 5 [27008/702208 (4%)]	Loss: 0.073655Train Epoch: 5 [28032/702208 (4%)]	Loss: 0.108975Train Epoch: 5 [29056/702208 (4%)]	Loss: 0.129020Train Epoch: 5 [30080/702208 (4%)]	Loss: 0.045674Train Epoch: 5 [31104/702208 (4%)]	Loss: 0.057875Train Epoch: 5 [32000/702208 (5%)]	Loss: 0.080746Train Epoch: 5 [32128/702208 (5%)]	Loss: 0.038670Train Epoch: 5 [33024/702208 (5%)]	Loss: 0.263272Train Epoch: 5 [34048/702208 (5%)]	Loss: 0.023452Train Epoch: 5 [35072/702208 (5%)]	Loss: 0.060203Train Epoch: 5 [36096/702208 (5%)]	Loss: 0.116011Train Epoch: 5 [37120/702208 (5%)]	Loss: 0.014959Train Epoch: 5 [38016/702208 (5%)]	Loss: 0.101499Train Epoch: 5 [39040/702208 (6%)]	Loss: 0.151529Train Epoch: 5 [40064/702208 (6%)]	Loss: 0.074446Train Epoch: 5 [41088/702208 (6%)]	Loss: 0.046621Train Epoch: 5 [42112/702208 (6%)]	Loss: 0.076920Train Epoch: 5 [43008/702208 (6%)]	Loss: 0.044644Train Epoch: 5 [44032/702208 (6%)]	Loss: 0.048317Train Epoch: 5 [45056/702208 (6%)]	Loss: 0.040837Train Epoch: 5 [46080/702208 (7%)]	Loss: 0.033032Train Epoch: 5 [47104/702208 (7%)]	Loss: 0.049607Train Epoch: 5 [48000/702208 (7%)]	Loss: 0.092116Train Epoch: 5 [48128/702208 (7%)]	Loss: 0.060075Train Epoch: 5 [49024/702208 (7%)]	Loss: 0.088353Train Epoch: 5 [50048/702208 (7%)]	Loss: 0.082280
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8026 / 8283] 96 %
Accuracy of the network on test loader class  1: [4498 / 4517] 99 %

Writing model: iterations-2858880-total-97.84-class0-96.89999999999999-class1-99.58

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12203 / 12833] 95 %
Accuracy of the network on train loader class  1: [7065 / 7135] 99 %
Train Epoch: 5 [51072/702208 (7%)]	Loss: 0.018893Train Epoch: 5 [52096/702208 (7%)]	Loss: 0.083368Train Epoch: 5 [53120/702208 (8%)]	Loss: 0.010988Train Epoch: 5 [54016/702208 (8%)]	Loss: 0.061813Train Epoch: 5 [55040/702208 (8%)]	Loss: 0.031932Train Epoch: 5 [56064/702208 (8%)]	Loss: 0.052694Train Epoch: 5 [57088/702208 (8%)]	Loss: 0.035412Train Epoch: 5 [58112/702208 (8%)]	Loss: 0.052393Train Epoch: 5 [59008/702208 (8%)]	Loss: 0.060479Train Epoch: 5 [60032/702208 (9%)]	Loss: 0.106811Train Epoch: 5 [61056/702208 (9%)]	Loss: 0.080362Train Epoch: 5 [62080/702208 (9%)]	Loss: 0.117919Train Epoch: 5 [63104/702208 (9%)]	Loss: 0.138757Train Epoch: 5 [64000/702208 (9%)]	Loss: 0.054902Train Epoch: 5 [64128/702208 (9%)]	Loss: 0.045236Train Epoch: 5 [65024/702208 (9%)]	Loss: 0.074044Train Epoch: 5 [66048/702208 (9%)]	Loss: 0.022289Train Epoch: 5 [67072/702208 (10%)]	Loss: 0.080189Train Epoch: 5 [68096/702208 (10%)]	Loss: 0.056379Train Epoch: 5 [69120/702208 (10%)]	Loss: 0.033975Train Epoch: 5 [70016/702208 (10%)]	Loss: 0.061386Train Epoch: 5 [71040/702208 (10%)]	Loss: 0.046455Train Epoch: 5 [72064/702208 (10%)]	Loss: 0.064726Train Epoch: 5 [73088/702208 (10%)]	Loss: 0.131317Train Epoch: 5 [74112/702208 (11%)]	Loss: 0.047052Train Epoch: 5 [75008/702208 (11%)]	Loss: 0.060700
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8087 / 8283] 97 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-2883840-total-98.36-class0-97.63-class1-99.69
Train Epoch: 5 [76032/702208 (11%)]	Loss: 0.062553Train Epoch: 5 [77056/702208 (11%)]	Loss: 0.034683Train Epoch: 5 [78080/702208 (11%)]	Loss: 0.034545Train Epoch: 5 [79104/702208 (11%)]	Loss: 0.080862Train Epoch: 5 [80000/702208 (11%)]	Loss: 0.055915Train Epoch: 5 [80128/702208 (11%)]	Loss: 0.042738Train Epoch: 5 [81024/702208 (12%)]	Loss: 0.006633Train Epoch: 5 [82048/702208 (12%)]	Loss: 0.037912Train Epoch: 5 [83072/702208 (12%)]	Loss: 0.088568Train Epoch: 5 [84096/702208 (12%)]	Loss: 0.111332Train Epoch: 5 [85120/702208 (12%)]	Loss: 0.051132Train Epoch: 5 [86016/702208 (12%)]	Loss: 0.036287Train Epoch: 5 [87040/702208 (12%)]	Loss: 0.055971Train Epoch: 5 [88064/702208 (13%)]	Loss: 0.035986Train Epoch: 5 [89088/702208 (13%)]	Loss: 0.067879Train Epoch: 5 [90112/702208 (13%)]	Loss: 0.081015Train Epoch: 5 [91008/702208 (13%)]	Loss: 0.040692Train Epoch: 5 [92032/702208 (13%)]	Loss: 0.047779Train Epoch: 5 [93056/702208 (13%)]	Loss: 0.061180Train Epoch: 5 [94080/702208 (13%)]	Loss: 0.028727Train Epoch: 5 [95104/702208 (14%)]	Loss: 0.086576Train Epoch: 5 [96000/702208 (14%)]	Loss: 0.129230Train Epoch: 5 [96128/702208 (14%)]	Loss: 0.087898Train Epoch: 5 [97024/702208 (14%)]	Loss: 0.065161Train Epoch: 5 [98048/702208 (14%)]	Loss: 0.067077Train Epoch: 5 [99072/702208 (14%)]	Loss: 0.058104Train Epoch: 5 [100096/702208 (14%)]	Loss: 0.032779
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7895 / 8283] 95 %
Accuracy of the network on test loader class  1: [4501 / 4517] 99 %

Writing model: iterations-2908928-total-96.84-class0-95.32000000000001-class1-99.65

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11833 / 12833] 92 %
Accuracy of the network on train loader class  1: [6973 / 7135] 97 %
Train Epoch: 5 [101120/702208 (14%)]	Loss: 0.060377Train Epoch: 5 [102016/702208 (15%)]	Loss: 0.033348Train Epoch: 5 [103040/702208 (15%)]	Loss: 0.070378Train Epoch: 5 [104064/702208 (15%)]	Loss: 0.039153Train Epoch: 5 [105088/702208 (15%)]	Loss: 0.019490Train Epoch: 5 [106112/702208 (15%)]	Loss: 0.053072Train Epoch: 5 [107008/702208 (15%)]	Loss: 0.035616Train Epoch: 5 [108032/702208 (15%)]	Loss: 0.063426Train Epoch: 5 [109056/702208 (16%)]	Loss: 0.062645Train Epoch: 5 [110080/702208 (16%)]	Loss: 0.046532Train Epoch: 5 [111104/702208 (16%)]	Loss: 0.046339Train Epoch: 5 [112000/702208 (16%)]	Loss: 0.032597Train Epoch: 5 [112128/702208 (16%)]	Loss: 0.021430Train Epoch: 5 [113024/702208 (16%)]	Loss: 0.030612Train Epoch: 5 [114048/702208 (16%)]	Loss: 0.043879Train Epoch: 5 [115072/702208 (16%)]	Loss: 0.057932Train Epoch: 5 [116096/702208 (17%)]	Loss: 0.084027Train Epoch: 5 [117120/702208 (17%)]	Loss: 0.071766Train Epoch: 5 [118016/702208 (17%)]	Loss: 0.069706Train Epoch: 5 [119040/702208 (17%)]	Loss: 0.138664Train Epoch: 5 [120064/702208 (17%)]	Loss: 0.045464Train Epoch: 5 [121088/702208 (17%)]	Loss: 0.128288Train Epoch: 5 [122112/702208 (17%)]	Loss: 0.058339Train Epoch: 5 [123008/702208 (18%)]	Loss: 0.121800Train Epoch: 5 [124032/702208 (18%)]	Loss: 0.036229Train Epoch: 5 [125056/702208 (18%)]	Loss: 0.037370
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8017 / 8283] 96 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-2933888-total-97.78999999999999-class0-96.78999999999999-class1-99.62
Train Epoch: 5 [126080/702208 (18%)]	Loss: 0.046520Train Epoch: 5 [127104/702208 (18%)]	Loss: 0.088033Train Epoch: 5 [128000/702208 (18%)]	Loss: 0.030959Train Epoch: 5 [128128/702208 (18%)]	Loss: 0.116645Train Epoch: 5 [129024/702208 (18%)]	Loss: 0.025353Train Epoch: 5 [130048/702208 (19%)]	Loss: 0.079186Train Epoch: 5 [131072/702208 (19%)]	Loss: 0.126856Train Epoch: 5 [132096/702208 (19%)]	Loss: 0.089903Train Epoch: 5 [133120/702208 (19%)]	Loss: 0.067376Train Epoch: 5 [134016/702208 (19%)]	Loss: 0.065502Train Epoch: 5 [135040/702208 (19%)]	Loss: 0.043869Train Epoch: 5 [136064/702208 (19%)]	Loss: 0.066574Train Epoch: 5 [137088/702208 (20%)]	Loss: 0.057641Train Epoch: 5 [138112/702208 (20%)]	Loss: 0.143043Train Epoch: 5 [139008/702208 (20%)]	Loss: 0.070433Train Epoch: 5 [140032/702208 (20%)]	Loss: 0.058785Train Epoch: 5 [141056/702208 (20%)]	Loss: 0.041395Train Epoch: 5 [142080/702208 (20%)]	Loss: 0.081801Train Epoch: 5 [143104/702208 (20%)]	Loss: 0.044949Train Epoch: 5 [144000/702208 (21%)]	Loss: 0.048242Train Epoch: 5 [144128/702208 (21%)]	Loss: 0.087305Train Epoch: 5 [145024/702208 (21%)]	Loss: 0.119796Train Epoch: 5 [146048/702208 (21%)]	Loss: 0.039229Train Epoch: 5 [147072/702208 (21%)]	Loss: 0.039642Train Epoch: 5 [148096/702208 (21%)]	Loss: 0.063285Train Epoch: 5 [149120/702208 (21%)]	Loss: 0.040092Train Epoch: 5 [150016/702208 (21%)]	Loss: 0.049191
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8086 / 8283] 97 %
Accuracy of the network on test loader class  1: [4484 / 4517] 99 %

Writing model: iterations-2958848-total-98.2-class0-97.61999999999999-class1-99.27

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12154 / 12833] 94 %
Accuracy of the network on train loader class  1: [6845 / 7135] 95 %
Train Epoch: 5 [151040/702208 (22%)]	Loss: 0.064354Train Epoch: 5 [152064/702208 (22%)]	Loss: 0.032056Train Epoch: 5 [153088/702208 (22%)]	Loss: 0.101596Train Epoch: 5 [154112/702208 (22%)]	Loss: 0.050586Train Epoch: 5 [155008/702208 (22%)]	Loss: 0.075993Train Epoch: 5 [156032/702208 (22%)]	Loss: 0.034397Train Epoch: 5 [157056/702208 (22%)]	Loss: 0.107744Train Epoch: 5 [158080/702208 (23%)]	Loss: 0.031790Train Epoch: 5 [159104/702208 (23%)]	Loss: 0.057067Train Epoch: 5 [160000/702208 (23%)]	Loss: 0.037315Train Epoch: 5 [160128/702208 (23%)]	Loss: 0.056520Train Epoch: 5 [161024/702208 (23%)]	Loss: 0.065538Train Epoch: 5 [162048/702208 (23%)]	Loss: 0.107594Train Epoch: 5 [163072/702208 (23%)]	Loss: 0.071970Train Epoch: 5 [164096/702208 (23%)]	Loss: 0.031551Train Epoch: 5 [165120/702208 (24%)]	Loss: 0.057637Train Epoch: 5 [166016/702208 (24%)]	Loss: 0.059072Train Epoch: 5 [167040/702208 (24%)]	Loss: 0.032805Train Epoch: 5 [168064/702208 (24%)]	Loss: 0.052319Train Epoch: 5 [169088/702208 (24%)]	Loss: 0.054640Train Epoch: 5 [170112/702208 (24%)]	Loss: 0.068948Train Epoch: 5 [171008/702208 (24%)]	Loss: 0.036482Train Epoch: 5 [172032/702208 (24%)]	Loss: 0.092030Train Epoch: 5 [173056/702208 (25%)]	Loss: 0.092112Train Epoch: 5 [174080/702208 (25%)]	Loss: 0.083190Train Epoch: 5 [175104/702208 (25%)]	Loss: 0.132273
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8032 / 8283] 96 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-2983936-total-97.87-class0-96.97-class1-99.51
Train Epoch: 5 [176000/702208 (25%)]	Loss: 0.106857Train Epoch: 5 [176128/702208 (25%)]	Loss: 0.065285Train Epoch: 5 [177024/702208 (25%)]	Loss: 0.154646Train Epoch: 5 [178048/702208 (25%)]	Loss: 0.114715Train Epoch: 5 [179072/702208 (26%)]	Loss: 0.058003Train Epoch: 5 [180096/702208 (26%)]	Loss: 0.057730Train Epoch: 5 [181120/702208 (26%)]	Loss: 0.051486Train Epoch: 5 [182016/702208 (26%)]	Loss: 0.025384Train Epoch: 5 [183040/702208 (26%)]	Loss: 0.093368Train Epoch: 5 [184064/702208 (26%)]	Loss: 0.067566Train Epoch: 5 [185088/702208 (26%)]	Loss: 0.100913Train Epoch: 5 [186112/702208 (27%)]	Loss: 0.058860Train Epoch: 5 [187008/702208 (27%)]	Loss: 0.066385Train Epoch: 5 [188032/702208 (27%)]	Loss: 0.146713Train Epoch: 5 [189056/702208 (27%)]	Loss: 0.072631Train Epoch: 5 [190080/702208 (27%)]	Loss: 0.149627Train Epoch: 5 [191104/702208 (27%)]	Loss: 0.074870Train Epoch: 5 [192000/702208 (27%)]	Loss: 0.020934Train Epoch: 5 [192128/702208 (27%)]	Loss: 0.041822Train Epoch: 5 [193024/702208 (27%)]	Loss: 0.038269Train Epoch: 5 [194048/702208 (28%)]	Loss: 0.067910Train Epoch: 5 [195072/702208 (28%)]	Loss: 0.051465Train Epoch: 5 [196096/702208 (28%)]	Loss: 0.065626Train Epoch: 5 [197120/702208 (28%)]	Loss: 0.061183Train Epoch: 5 [198016/702208 (28%)]	Loss: 0.159885Train Epoch: 5 [199040/702208 (28%)]	Loss: 0.023598Train Epoch: 5 [200064/702208 (28%)]	Loss: 0.036984
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8106 / 8283] 97 %
Accuracy of the network on test loader class  1: [4490 / 4517] 99 %

Writing model: iterations-3008896-total-98.41-class0-97.86-class1-99.4

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12189 / 12833] 94 %
Accuracy of the network on train loader class  1: [6952 / 7135] 97 %
Train Epoch: 5 [201088/702208 (29%)]	Loss: 0.137570Train Epoch: 5 [202112/702208 (29%)]	Loss: 0.124265Train Epoch: 5 [203008/702208 (29%)]	Loss: 0.078285Train Epoch: 5 [204032/702208 (29%)]	Loss: 0.168638Train Epoch: 5 [205056/702208 (29%)]	Loss: 0.191242Train Epoch: 5 [206080/702208 (29%)]	Loss: 0.047614Train Epoch: 5 [207104/702208 (29%)]	Loss: 0.082498Train Epoch: 5 [208000/702208 (30%)]	Loss: 0.027993Train Epoch: 5 [208128/702208 (30%)]	Loss: 0.056034Train Epoch: 5 [209024/702208 (30%)]	Loss: 0.068590Train Epoch: 5 [210048/702208 (30%)]	Loss: 0.058123Train Epoch: 5 [211072/702208 (30%)]	Loss: 0.060485Train Epoch: 5 [212096/702208 (30%)]	Loss: 0.037817Train Epoch: 5 [213120/702208 (30%)]	Loss: 0.041900Train Epoch: 5 [214016/702208 (30%)]	Loss: 0.080995Train Epoch: 5 [215040/702208 (31%)]	Loss: 0.026264Train Epoch: 5 [216064/702208 (31%)]	Loss: 0.094928Train Epoch: 5 [217088/702208 (31%)]	Loss: 0.036197Train Epoch: 5 [218112/702208 (31%)]	Loss: 0.106353Train Epoch: 5 [219008/702208 (31%)]	Loss: 0.112215Train Epoch: 5 [220032/702208 (31%)]	Loss: 0.041391Train Epoch: 5 [221056/702208 (31%)]	Loss: 0.090782Train Epoch: 5 [222080/702208 (32%)]	Loss: 0.023052Train Epoch: 5 [223104/702208 (32%)]	Loss: 0.070998Train Epoch: 5 [224000/702208 (32%)]	Loss: 0.066737Train Epoch: 5 [224128/702208 (32%)]	Loss: 0.198897Train Epoch: 5 [225024/702208 (32%)]	Loss: 0.032619
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8088 / 8283] 97 %
Accuracy of the network on test loader class  1: [4492 / 4517] 99 %

Writing model: iterations-3033856-total-98.28-class0-97.65-class1-99.45
Train Epoch: 5 [226048/702208 (32%)]	Loss: 0.089036Train Epoch: 5 [227072/702208 (32%)]	Loss: 0.063767Train Epoch: 5 [228096/702208 (32%)]	Loss: 0.045873Train Epoch: 5 [229120/702208 (33%)]	Loss: 0.117992Train Epoch: 5 [230016/702208 (33%)]	Loss: 0.050479Train Epoch: 5 [231040/702208 (33%)]	Loss: 0.052758Train Epoch: 5 [232064/702208 (33%)]	Loss: 0.060649Train Epoch: 5 [233088/702208 (33%)]	Loss: 0.060340Train Epoch: 5 [234112/702208 (33%)]	Loss: 0.028998Train Epoch: 5 [235008/702208 (33%)]	Loss: 0.062147Train Epoch: 5 [236032/702208 (34%)]	Loss: 0.111221Train Epoch: 5 [237056/702208 (34%)]	Loss: 0.048055Train Epoch: 5 [238080/702208 (34%)]	Loss: 0.078219Train Epoch: 5 [239104/702208 (34%)]	Loss: 0.109614Train Epoch: 5 [240000/702208 (34%)]	Loss: 0.051283Train Epoch: 5 [240128/702208 (34%)]	Loss: 0.027252Train Epoch: 5 [241024/702208 (34%)]	Loss: 0.064813Train Epoch: 5 [242048/702208 (34%)]	Loss: 0.027850Train Epoch: 5 [243072/702208 (35%)]	Loss: 0.085375Train Epoch: 5 [244096/702208 (35%)]	Loss: 0.063681Train Epoch: 5 [245120/702208 (35%)]	Loss: 0.040461Train Epoch: 5 [246016/702208 (35%)]	Loss: 0.054583Train Epoch: 5 [247040/702208 (35%)]	Loss: 0.093722Train Epoch: 5 [248064/702208 (35%)]	Loss: 0.123612Train Epoch: 5 [249088/702208 (35%)]	Loss: 0.080090Train Epoch: 5 [250112/702208 (36%)]	Loss: 0.059978
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8057 / 8283] 97 %
Accuracy of the network on test loader class  1: [4497 / 4517] 99 %

Writing model: iterations-3058944-total-98.08-class0-97.27-class1-99.56

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12320 / 12833] 96 %
Accuracy of the network on train loader class  1: [7036 / 7135] 98 %
Train Epoch: 5 [251008/702208 (36%)]	Loss: 0.126393Train Epoch: 5 [252032/702208 (36%)]	Loss: 0.069720Train Epoch: 5 [253056/702208 (36%)]	Loss: 0.070174Train Epoch: 5 [254080/702208 (36%)]	Loss: 0.058990Train Epoch: 5 [255104/702208 (36%)]	Loss: 0.039413Train Epoch: 5 [256000/702208 (36%)]	Loss: 0.085013Train Epoch: 5 [256128/702208 (36%)]	Loss: 0.069469Train Epoch: 5 [257024/702208 (37%)]	Loss: 0.063066Train Epoch: 5 [258048/702208 (37%)]	Loss: 0.214518Train Epoch: 5 [259072/702208 (37%)]	Loss: 0.038504Train Epoch: 5 [260096/702208 (37%)]	Loss: 0.052217Train Epoch: 5 [261120/702208 (37%)]	Loss: 0.124935Train Epoch: 5 [262016/702208 (37%)]	Loss: 0.035533Train Epoch: 5 [263040/702208 (37%)]	Loss: 0.130607Train Epoch: 5 [264064/702208 (38%)]	Loss: 0.063425Train Epoch: 5 [265088/702208 (38%)]	Loss: 0.054796Train Epoch: 5 [266112/702208 (38%)]	Loss: 0.061721Train Epoch: 5 [267008/702208 (38%)]	Loss: 0.040534Train Epoch: 5 [268032/702208 (38%)]	Loss: 0.122035Train Epoch: 5 [269056/702208 (38%)]	Loss: 0.084404Train Epoch: 5 [270080/702208 (38%)]	Loss: 0.041745Train Epoch: 5 [271104/702208 (39%)]	Loss: 0.109788Train Epoch: 5 [272000/702208 (39%)]	Loss: 0.035114Train Epoch: 5 [272128/702208 (39%)]	Loss: 0.156877Train Epoch: 5 [273024/702208 (39%)]	Loss: 0.036972Train Epoch: 5 [274048/702208 (39%)]	Loss: 0.044608Train Epoch: 5 [275072/702208 (39%)]	Loss: 0.057613
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7954 / 8283] 96 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-3083904-total-97.35000000000001-class0-96.03-class1-99.78
Train Epoch: 5 [276096/702208 (39%)]	Loss: 0.105892Train Epoch: 5 [277120/702208 (39%)]	Loss: 0.097428Train Epoch: 5 [278016/702208 (40%)]	Loss: 0.047948Train Epoch: 5 [279040/702208 (40%)]	Loss: 0.037231Train Epoch: 5 [280064/702208 (40%)]	Loss: 0.060573Train Epoch: 5 [281088/702208 (40%)]	Loss: 0.078000Train Epoch: 5 [282112/702208 (40%)]	Loss: 0.109579Train Epoch: 5 [283008/702208 (40%)]	Loss: 0.022392Train Epoch: 5 [284032/702208 (40%)]	Loss: 0.098831Train Epoch: 5 [285056/702208 (41%)]	Loss: 0.080621Train Epoch: 5 [286080/702208 (41%)]	Loss: 0.080661Train Epoch: 5 [287104/702208 (41%)]	Loss: 0.030274Train Epoch: 5 [288000/702208 (41%)]	Loss: 0.040070Train Epoch: 5 [288128/702208 (41%)]	Loss: 0.033683Train Epoch: 5 [289024/702208 (41%)]	Loss: 0.045470Train Epoch: 5 [290048/702208 (41%)]	Loss: 0.071635Train Epoch: 5 [291072/702208 (41%)]	Loss: 0.063535Train Epoch: 5 [292096/702208 (42%)]	Loss: 0.075598Train Epoch: 5 [293120/702208 (42%)]	Loss: 0.040035Train Epoch: 5 [294016/702208 (42%)]	Loss: 0.052970Train Epoch: 5 [295040/702208 (42%)]	Loss: 0.062524Train Epoch: 5 [296064/702208 (42%)]	Loss: 0.044927Train Epoch: 5 [297088/702208 (42%)]	Loss: 0.024730Train Epoch: 5 [298112/702208 (42%)]	Loss: 0.041354Train Epoch: 5 [299008/702208 (43%)]	Loss: 0.069570Train Epoch: 5 [300032/702208 (43%)]	Loss: 0.053820
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8089 / 8283] 97 %
Accuracy of the network on test loader class  1: [4488 / 4517] 99 %

Writing model: iterations-3108864-total-98.26-class0-97.66-class1-99.36

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12057 / 12833] 93 %
Accuracy of the network on train loader class  1: [7031 / 7135] 98 %
Train Epoch: 5 [301056/702208 (43%)]	Loss: 0.035626Train Epoch: 5 [302080/702208 (43%)]	Loss: 0.116632Train Epoch: 5 [303104/702208 (43%)]	Loss: 0.101614Train Epoch: 5 [304000/702208 (43%)]	Loss: 0.049708Train Epoch: 5 [304128/702208 (43%)]	Loss: 0.120694Train Epoch: 5 [305024/702208 (43%)]	Loss: 0.092220Train Epoch: 5 [306048/702208 (44%)]	Loss: 0.040737Train Epoch: 5 [307072/702208 (44%)]	Loss: 0.112039Train Epoch: 5 [308096/702208 (44%)]	Loss: 0.039754Train Epoch: 5 [309120/702208 (44%)]	Loss: 0.082541Train Epoch: 5 [310016/702208 (44%)]	Loss: 0.047626Train Epoch: 5 [311040/702208 (44%)]	Loss: 0.063577Train Epoch: 5 [312064/702208 (44%)]	Loss: 0.025103Train Epoch: 5 [313088/702208 (45%)]	Loss: 0.137631Train Epoch: 5 [314112/702208 (45%)]	Loss: 0.040127Train Epoch: 5 [315008/702208 (45%)]	Loss: 0.059687Train Epoch: 5 [316032/702208 (45%)]	Loss: 0.076972Train Epoch: 5 [317056/702208 (45%)]	Loss: 0.079366Train Epoch: 5 [318080/702208 (45%)]	Loss: 0.047484Train Epoch: 5 [319104/702208 (45%)]	Loss: 0.064456Train Epoch: 5 [320000/702208 (46%)]	Loss: 0.043277Train Epoch: 5 [320128/702208 (46%)]	Loss: 0.049322Train Epoch: 5 [321024/702208 (46%)]	Loss: 0.117124Train Epoch: 5 [322048/702208 (46%)]	Loss: 0.036291Train Epoch: 5 [323072/702208 (46%)]	Loss: 0.189744Train Epoch: 5 [324096/702208 (46%)]	Loss: 0.044466Train Epoch: 5 [325120/702208 (46%)]	Loss: 0.054442
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7973 / 8283] 96 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-3133952-total-97.52-class0-96.26-class1-99.82
Train Epoch: 5 [326016/702208 (46%)]	Loss: 0.030084Train Epoch: 5 [327040/702208 (47%)]	Loss: 0.109248Train Epoch: 5 [328064/702208 (47%)]	Loss: 0.049705Train Epoch: 5 [329088/702208 (47%)]	Loss: 0.065167Train Epoch: 5 [330112/702208 (47%)]	Loss: 0.127234Train Epoch: 5 [331008/702208 (47%)]	Loss: 0.029681Train Epoch: 5 [332032/702208 (47%)]	Loss: 0.056759Train Epoch: 5 [333056/702208 (47%)]	Loss: 0.030891Train Epoch: 5 [334080/702208 (48%)]	Loss: 0.058586Train Epoch: 5 [335104/702208 (48%)]	Loss: 0.090540Train Epoch: 5 [336000/702208 (48%)]	Loss: 0.054316Train Epoch: 5 [336128/702208 (48%)]	Loss: 0.039175Train Epoch: 5 [337024/702208 (48%)]	Loss: 0.032741Train Epoch: 5 [338048/702208 (48%)]	Loss: 0.080831Train Epoch: 5 [339072/702208 (48%)]	Loss: 0.074239Train Epoch: 5 [340096/702208 (48%)]	Loss: 0.030212Train Epoch: 5 [341120/702208 (49%)]	Loss: 0.109998Train Epoch: 5 [342016/702208 (49%)]	Loss: 0.027746Train Epoch: 5 [343040/702208 (49%)]	Loss: 0.045265Train Epoch: 5 [344064/702208 (49%)]	Loss: 0.023991Train Epoch: 5 [345088/702208 (49%)]	Loss: 0.092564Train Epoch: 5 [346112/702208 (49%)]	Loss: 0.093315Train Epoch: 5 [347008/702208 (49%)]	Loss: 0.041187Train Epoch: 5 [348032/702208 (50%)]	Loss: 0.050197Train Epoch: 5 [349056/702208 (50%)]	Loss: 0.152154Train Epoch: 5 [350080/702208 (50%)]	Loss: 0.115846
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8115 / 8283] 97 %
Accuracy of the network on test loader class  1: [4493 / 4517] 99 %

Writing model: iterations-3158912-total-98.5-class0-97.97-class1-99.47

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12178 / 12833] 94 %
Accuracy of the network on train loader class  1: [7101 / 7135] 99 %
Train Epoch: 5 [351104/702208 (50%)]	Loss: 0.176135Train Epoch: 5 [352000/702208 (50%)]	Loss: 0.094370Train Epoch: 5 [352128/702208 (50%)]	Loss: 0.049894Train Epoch: 5 [353024/702208 (50%)]	Loss: 0.097274Train Epoch: 5 [354048/702208 (50%)]	Loss: 0.091666Train Epoch: 5 [355072/702208 (51%)]	Loss: 0.075717Train Epoch: 5 [356096/702208 (51%)]	Loss: 0.063651Train Epoch: 5 [357120/702208 (51%)]	Loss: 0.034212Train Epoch: 5 [358016/702208 (51%)]	Loss: 0.061157Train Epoch: 5 [359040/702208 (51%)]	Loss: 0.045841Train Epoch: 5 [360064/702208 (51%)]	Loss: 0.129136Train Epoch: 5 [361088/702208 (51%)]	Loss: 0.081220Train Epoch: 5 [362112/702208 (52%)]	Loss: 0.095940Train Epoch: 5 [363008/702208 (52%)]	Loss: 0.043229Train Epoch: 5 [364032/702208 (52%)]	Loss: 0.065936Train Epoch: 5 [365056/702208 (52%)]	Loss: 0.046617Train Epoch: 5 [366080/702208 (52%)]	Loss: 0.086627Train Epoch: 5 [367104/702208 (52%)]	Loss: 0.058587Train Epoch: 5 [368000/702208 (52%)]	Loss: 0.071878Train Epoch: 5 [368128/702208 (52%)]	Loss: 0.033510Train Epoch: 5 [369024/702208 (53%)]	Loss: 0.084392Train Epoch: 5 [370048/702208 (53%)]	Loss: 0.120367Train Epoch: 5 [371072/702208 (53%)]	Loss: 0.042382Train Epoch: 5 [372096/702208 (53%)]	Loss: 0.023929Train Epoch: 5 [373120/702208 (53%)]	Loss: 0.049117Train Epoch: 5 [374016/702208 (53%)]	Loss: 0.102890Train Epoch: 5 [375040/702208 (53%)]	Loss: 0.054419
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8015 / 8283] 96 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-3183872-total-97.84-class0-96.76-class1-99.8
Train Epoch: 5 [376064/702208 (54%)]	Loss: 0.074584Train Epoch: 5 [377088/702208 (54%)]	Loss: 0.062130Train Epoch: 5 [378112/702208 (54%)]	Loss: 0.084355Train Epoch: 5 [379008/702208 (54%)]	Loss: 0.084507Train Epoch: 5 [380032/702208 (54%)]	Loss: 0.097294Train Epoch: 5 [381056/702208 (54%)]	Loss: 0.013689Train Epoch: 5 [382080/702208 (54%)]	Loss: 0.090425Train Epoch: 5 [383104/702208 (55%)]	Loss: 0.038881Train Epoch: 5 [384000/702208 (55%)]	Loss: 0.063482Train Epoch: 5 [384128/702208 (55%)]	Loss: 0.027816Train Epoch: 5 [385024/702208 (55%)]	Loss: 0.063488Train Epoch: 5 [386048/702208 (55%)]	Loss: 0.079177Train Epoch: 5 [387072/702208 (55%)]	Loss: 0.151787Train Epoch: 5 [388096/702208 (55%)]	Loss: 0.036314Train Epoch: 5 [389120/702208 (55%)]	Loss: 0.032211Train Epoch: 5 [390016/702208 (56%)]	Loss: 0.079139Train Epoch: 5 [391040/702208 (56%)]	Loss: 0.036832Train Epoch: 5 [392064/702208 (56%)]	Loss: 0.103374Train Epoch: 5 [393088/702208 (56%)]	Loss: 0.129690Train Epoch: 5 [394112/702208 (56%)]	Loss: 0.043194Train Epoch: 5 [395008/702208 (56%)]	Loss: 0.050372Train Epoch: 5 [396032/702208 (56%)]	Loss: 0.060744Train Epoch: 5 [397056/702208 (57%)]	Loss: 0.038847Train Epoch: 5 [398080/702208 (57%)]	Loss: 0.035054Train Epoch: 5 [399104/702208 (57%)]	Loss: 0.073741Train Epoch: 5 [400000/702208 (57%)]	Loss: 0.093561
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7912 / 8283] 95 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-3208832-total-97.05-class0-95.52000000000001-class1-99.87

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12169 / 12833] 94 %
Accuracy of the network on train loader class  1: [7101 / 7135] 99 %
Train Epoch: 5 [400128/702208 (57%)]	Loss: 0.034174
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 96 %
Accuracy of the network on test loader class  0: [7887 / 8283] 95 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-3208960-total-96.86-class0-95.22-class1-99.87

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12191 / 12833] 94 %
Accuracy of the network on train loader class  1: [7093 / 7135] 99 %
Train Epoch: 5 [401024/702208 (57%)]	Loss: 0.049205Train Epoch: 5 [402048/702208 (57%)]	Loss: 0.044600Train Epoch: 5 [403072/702208 (57%)]	Loss: 0.045119Train Epoch: 5 [404096/702208 (58%)]	Loss: 0.039636Train Epoch: 5 [405120/702208 (58%)]	Loss: 0.034087Train Epoch: 5 [406016/702208 (58%)]	Loss: 0.022270Train Epoch: 5 [407040/702208 (58%)]	Loss: 0.062254Train Epoch: 5 [408064/702208 (58%)]	Loss: 0.067413Train Epoch: 5 [409088/702208 (58%)]	Loss: 0.055090Train Epoch: 5 [410112/702208 (58%)]	Loss: 0.077642Train Epoch: 5 [411008/702208 (59%)]	Loss: 0.068756Train Epoch: 5 [412032/702208 (59%)]	Loss: 0.065147Train Epoch: 5 [413056/702208 (59%)]	Loss: 0.088103Train Epoch: 5 [414080/702208 (59%)]	Loss: 0.098307Train Epoch: 5 [415104/702208 (59%)]	Loss: 0.035497Train Epoch: 5 [416000/702208 (59%)]	Loss: 0.040682Train Epoch: 5 [416128/702208 (59%)]	Loss: 0.066055Train Epoch: 5 [417024/702208 (59%)]	Loss: 0.028065Train Epoch: 5 [418048/702208 (60%)]	Loss: 0.092349Train Epoch: 5 [419072/702208 (60%)]	Loss: 0.052621Train Epoch: 5 [420096/702208 (60%)]	Loss: 0.039815Train Epoch: 5 [421120/702208 (60%)]	Loss: 0.053898Train Epoch: 5 [422016/702208 (60%)]	Loss: 0.094368Train Epoch: 5 [423040/702208 (60%)]	Loss: 0.051338Train Epoch: 5 [424064/702208 (60%)]	Loss: 0.026092Train Epoch: 5 [425088/702208 (61%)]	Loss: 0.133101
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8117 / 8283] 97 %
Accuracy of the network on test loader class  1: [4484 / 4517] 99 %

Writing model: iterations-3233920-total-98.45-class0-98.0-class1-99.27
Train Epoch: 5 [426112/702208 (61%)]	Loss: 0.060708Train Epoch: 5 [427008/702208 (61%)]	Loss: 0.078642Train Epoch: 5 [428032/702208 (61%)]	Loss: 0.047829Train Epoch: 5 [429056/702208 (61%)]	Loss: 0.126807Train Epoch: 5 [430080/702208 (61%)]	Loss: 0.014143Train Epoch: 5 [431104/702208 (61%)]	Loss: 0.048086Train Epoch: 5 [432000/702208 (62%)]	Loss: 0.111425Train Epoch: 5 [432128/702208 (62%)]	Loss: 0.039899Train Epoch: 5 [433024/702208 (62%)]	Loss: 0.063506Train Epoch: 5 [434048/702208 (62%)]	Loss: 0.050185Train Epoch: 5 [435072/702208 (62%)]	Loss: 0.064543Train Epoch: 5 [436096/702208 (62%)]	Loss: 0.023955Train Epoch: 5 [437120/702208 (62%)]	Loss: 0.047683Train Epoch: 5 [438016/702208 (62%)]	Loss: 0.173760Train Epoch: 5 [439040/702208 (63%)]	Loss: 0.026276Train Epoch: 5 [440064/702208 (63%)]	Loss: 0.126720Train Epoch: 5 [441088/702208 (63%)]	Loss: 0.029777Train Epoch: 5 [442112/702208 (63%)]	Loss: 0.025770Train Epoch: 5 [443008/702208 (63%)]	Loss: 0.134442Train Epoch: 5 [444032/702208 (63%)]	Loss: 0.092788Train Epoch: 5 [445056/702208 (63%)]	Loss: 0.044119Train Epoch: 5 [446080/702208 (64%)]	Loss: 0.022785Train Epoch: 5 [447104/702208 (64%)]	Loss: 0.111082Train Epoch: 5 [448000/702208 (64%)]	Loss: 0.039382Train Epoch: 5 [448128/702208 (64%)]	Loss: 0.093126Train Epoch: 5 [449024/702208 (64%)]	Loss: 0.061482Train Epoch: 5 [450048/702208 (64%)]	Loss: 0.038121
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8055 / 8283] 97 %
Accuracy of the network on test loader class  1: [4499 / 4517] 99 %

Writing model: iterations-3258880-total-98.08-class0-97.25-class1-99.6

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12222 / 12833] 95 %
Accuracy of the network on train loader class  1: [7097 / 7135] 99 %
Train Epoch: 5 [451072/702208 (64%)]	Loss: 0.167017Train Epoch: 5 [452096/702208 (64%)]	Loss: 0.129145Train Epoch: 5 [453120/702208 (65%)]	Loss: 0.077135Train Epoch: 5 [454016/702208 (65%)]	Loss: 0.051546Train Epoch: 5 [455040/702208 (65%)]	Loss: 0.033532Train Epoch: 5 [456064/702208 (65%)]	Loss: 0.070151Train Epoch: 5 [457088/702208 (65%)]	Loss: 0.061276Train Epoch: 5 [458112/702208 (65%)]	Loss: 0.090731Train Epoch: 5 [459008/702208 (65%)]	Loss: 0.034876Train Epoch: 5 [460032/702208 (66%)]	Loss: 0.106015Train Epoch: 5 [461056/702208 (66%)]	Loss: 0.031551Train Epoch: 5 [462080/702208 (66%)]	Loss: 0.069964Train Epoch: 5 [463104/702208 (66%)]	Loss: 0.053104Train Epoch: 5 [464000/702208 (66%)]	Loss: 0.105106Train Epoch: 5 [464128/702208 (66%)]	Loss: 0.062422Train Epoch: 5 [465024/702208 (66%)]	Loss: 0.064106Train Epoch: 5 [466048/702208 (66%)]	Loss: 0.053476Train Epoch: 5 [467072/702208 (67%)]	Loss: 0.043899Train Epoch: 5 [468096/702208 (67%)]	Loss: 0.065644Train Epoch: 5 [469120/702208 (67%)]	Loss: 0.047715Train Epoch: 5 [470016/702208 (67%)]	Loss: 0.018738Train Epoch: 5 [471040/702208 (67%)]	Loss: 0.045130Train Epoch: 5 [472064/702208 (67%)]	Loss: 0.024988Train Epoch: 5 [473088/702208 (67%)]	Loss: 0.069491Train Epoch: 5 [474112/702208 (68%)]	Loss: 0.095218Train Epoch: 5 [475008/702208 (68%)]	Loss: 0.037416
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8035 / 8283] 97 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-3283840-total-97.92999999999999-class0-97.00999999999999-class1-99.62
Train Epoch: 5 [476032/702208 (68%)]	Loss: 0.049031Train Epoch: 5 [477056/702208 (68%)]	Loss: 0.115982Train Epoch: 5 [478080/702208 (68%)]	Loss: 0.054505Train Epoch: 5 [479104/702208 (68%)]	Loss: 0.054706Train Epoch: 5 [480000/702208 (68%)]	Loss: 0.061260Train Epoch: 5 [480128/702208 (68%)]	Loss: 0.135253Train Epoch: 5 [481024/702208 (69%)]	Loss: 0.103364Train Epoch: 5 [482048/702208 (69%)]	Loss: 0.053104Train Epoch: 5 [483072/702208 (69%)]	Loss: 0.102528Train Epoch: 5 [484096/702208 (69%)]	Loss: 0.066041Train Epoch: 5 [485120/702208 (69%)]	Loss: 0.145693Train Epoch: 5 [486016/702208 (69%)]	Loss: 0.035459Train Epoch: 5 [487040/702208 (69%)]	Loss: 0.054619Train Epoch: 5 [488064/702208 (70%)]	Loss: 0.061609Train Epoch: 5 [489088/702208 (70%)]	Loss: 0.053056Train Epoch: 5 [490112/702208 (70%)]	Loss: 0.047648Train Epoch: 5 [491008/702208 (70%)]	Loss: 0.026584Train Epoch: 5 [492032/702208 (70%)]	Loss: 0.042126Train Epoch: 5 [493056/702208 (70%)]	Loss: 0.088906Train Epoch: 5 [494080/702208 (70%)]	Loss: 0.054419Train Epoch: 5 [495104/702208 (71%)]	Loss: 0.073742Train Epoch: 5 [496000/702208 (71%)]	Loss: 0.042341Train Epoch: 5 [496128/702208 (71%)]	Loss: 0.045793Train Epoch: 5 [497024/702208 (71%)]	Loss: 0.023558Train Epoch: 5 [498048/702208 (71%)]	Loss: 0.043136Train Epoch: 5 [499072/702208 (71%)]	Loss: 0.041752Train Epoch: 5 [500096/702208 (71%)]	Loss: 0.033462
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8017 / 8283] 96 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-3308928-total-97.81-class0-96.78999999999999-class1-99.69

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12277 / 12833] 95 %
Accuracy of the network on train loader class  1: [7077 / 7135] 99 %
Train Epoch: 5 [501120/702208 (71%)]	Loss: 0.041086Train Epoch: 5 [502016/702208 (71%)]	Loss: 0.090426Train Epoch: 5 [503040/702208 (72%)]	Loss: 0.060076Train Epoch: 5 [504064/702208 (72%)]	Loss: 0.021947Train Epoch: 5 [505088/702208 (72%)]	Loss: 0.054219Train Epoch: 5 [506112/702208 (72%)]	Loss: 0.088757Train Epoch: 5 [507008/702208 (72%)]	Loss: 0.077075Train Epoch: 5 [508032/702208 (72%)]	Loss: 0.073329Train Epoch: 5 [509056/702208 (72%)]	Loss: 0.018112Train Epoch: 5 [510080/702208 (73%)]	Loss: 0.063943Train Epoch: 5 [511104/702208 (73%)]	Loss: 0.031853Train Epoch: 5 [512000/702208 (73%)]	Loss: 0.054829Train Epoch: 5 [512128/702208 (73%)]	Loss: 0.050610Train Epoch: 5 [513024/702208 (73%)]	Loss: 0.067717Train Epoch: 5 [514048/702208 (73%)]	Loss: 0.102044Train Epoch: 5 [515072/702208 (73%)]	Loss: 0.052227Train Epoch: 5 [516096/702208 (73%)]	Loss: 0.097543Train Epoch: 5 [517120/702208 (74%)]	Loss: 0.053012Train Epoch: 5 [518016/702208 (74%)]	Loss: 0.073129Train Epoch: 5 [519040/702208 (74%)]	Loss: 0.082738Train Epoch: 5 [520064/702208 (74%)]	Loss: 0.026991Train Epoch: 5 [521088/702208 (74%)]	Loss: 0.080446Train Epoch: 5 [522112/702208 (74%)]	Loss: 0.060210Train Epoch: 5 [523008/702208 (74%)]	Loss: 0.076643Train Epoch: 5 [524032/702208 (75%)]	Loss: 0.053588Train Epoch: 5 [525056/702208 (75%)]	Loss: 0.042520
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8007 / 8283] 96 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-3333888-total-97.76-class0-96.67-class1-99.76
Train Epoch: 5 [526080/702208 (75%)]	Loss: 0.053514Train Epoch: 5 [527104/702208 (75%)]	Loss: 0.083871Train Epoch: 5 [528000/702208 (75%)]	Loss: 0.070598Train Epoch: 5 [528128/702208 (75%)]	Loss: 0.041793Train Epoch: 5 [529024/702208 (75%)]	Loss: 0.048276Train Epoch: 5 [530048/702208 (75%)]	Loss: 0.040508Train Epoch: 5 [531072/702208 (76%)]	Loss: 0.053808Train Epoch: 5 [532096/702208 (76%)]	Loss: 0.063589Train Epoch: 5 [533120/702208 (76%)]	Loss: 0.060748Train Epoch: 5 [534016/702208 (76%)]	Loss: 0.093107Train Epoch: 5 [535040/702208 (76%)]	Loss: 0.060911Train Epoch: 5 [536064/702208 (76%)]	Loss: 0.066685Train Epoch: 5 [537088/702208 (76%)]	Loss: 0.071037Train Epoch: 5 [538112/702208 (77%)]	Loss: 0.050606Train Epoch: 5 [539008/702208 (77%)]	Loss: 0.053244Train Epoch: 5 [540032/702208 (77%)]	Loss: 0.020023Train Epoch: 5 [541056/702208 (77%)]	Loss: 0.064718Train Epoch: 5 [542080/702208 (77%)]	Loss: 0.212163Train Epoch: 5 [543104/702208 (77%)]	Loss: 0.039605Train Epoch: 5 [544000/702208 (77%)]	Loss: 0.087600Train Epoch: 5 [544128/702208 (77%)]	Loss: 0.047055Train Epoch: 5 [545024/702208 (78%)]	Loss: 0.074397Train Epoch: 5 [546048/702208 (78%)]	Loss: 0.051099Train Epoch: 5 [547072/702208 (78%)]	Loss: 0.072520Train Epoch: 5 [548096/702208 (78%)]	Loss: 0.073312Train Epoch: 5 [549120/702208 (78%)]	Loss: 0.075678Train Epoch: 5 [550016/702208 (78%)]	Loss: 0.076518
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8025 / 8283] 96 %
Accuracy of the network on test loader class  1: [4499 / 4517] 99 %

Writing model: iterations-3358848-total-97.84-class0-96.89-class1-99.6

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12230 / 12833] 95 %
Accuracy of the network on train loader class  1: [7094 / 7135] 99 %
Train Epoch: 5 [551040/702208 (78%)]	Loss: 0.084601Train Epoch: 5 [552064/702208 (79%)]	Loss: 0.054900Train Epoch: 5 [553088/702208 (79%)]	Loss: 0.066541Train Epoch: 5 [554112/702208 (79%)]	Loss: 0.036055Train Epoch: 5 [555008/702208 (79%)]	Loss: 0.038179Train Epoch: 5 [556032/702208 (79%)]	Loss: 0.047382Train Epoch: 5 [557056/702208 (79%)]	Loss: 0.072365Train Epoch: 5 [558080/702208 (79%)]	Loss: 0.015116Train Epoch: 5 [559104/702208 (80%)]	Loss: 0.071177Train Epoch: 5 [560000/702208 (80%)]	Loss: 0.035908Train Epoch: 5 [560128/702208 (80%)]	Loss: 0.033834Train Epoch: 5 [561024/702208 (80%)]	Loss: 0.059386Train Epoch: 5 [562048/702208 (80%)]	Loss: 0.071829Train Epoch: 5 [563072/702208 (80%)]	Loss: 0.119167Train Epoch: 5 [564096/702208 (80%)]	Loss: 0.031365Train Epoch: 5 [565120/702208 (80%)]	Loss: 0.042832Train Epoch: 5 [566016/702208 (81%)]	Loss: 0.060985Train Epoch: 5 [567040/702208 (81%)]	Loss: 0.032557Train Epoch: 5 [568064/702208 (81%)]	Loss: 0.094608Train Epoch: 5 [569088/702208 (81%)]	Loss: 0.040395Train Epoch: 5 [570112/702208 (81%)]	Loss: 0.165828Train Epoch: 5 [571008/702208 (81%)]	Loss: 0.056263Train Epoch: 5 [572032/702208 (81%)]	Loss: 0.068181Train Epoch: 5 [573056/702208 (82%)]	Loss: 0.053552Train Epoch: 5 [574080/702208 (82%)]	Loss: 0.011179Train Epoch: 5 [575104/702208 (82%)]	Loss: 0.061691
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8003 / 8283] 96 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-3383936-total-97.72999999999999-class0-96.61999999999999-class1-99.76
Train Epoch: 5 [576000/702208 (82%)]	Loss: 0.101390Train Epoch: 5 [576128/702208 (82%)]	Loss: 0.073601Train Epoch: 5 [577024/702208 (82%)]	Loss: 0.055098Train Epoch: 5 [578048/702208 (82%)]	Loss: 0.072953Train Epoch: 5 [579072/702208 (82%)]	Loss: 0.023620Train Epoch: 5 [580096/702208 (83%)]	Loss: 0.110333Train Epoch: 5 [581120/702208 (83%)]	Loss: 0.016661Train Epoch: 5 [582016/702208 (83%)]	Loss: 0.058703Train Epoch: 5 [583040/702208 (83%)]	Loss: 0.061153Train Epoch: 5 [584064/702208 (83%)]	Loss: 0.144768Train Epoch: 5 [585088/702208 (83%)]	Loss: 0.044115Train Epoch: 5 [586112/702208 (83%)]	Loss: 0.041198Train Epoch: 5 [587008/702208 (84%)]	Loss: 0.077507Train Epoch: 5 [588032/702208 (84%)]	Loss: 0.057341Train Epoch: 5 [589056/702208 (84%)]	Loss: 0.067645Train Epoch: 5 [590080/702208 (84%)]	Loss: 0.034512Train Epoch: 5 [591104/702208 (84%)]	Loss: 0.094115Train Epoch: 5 [592000/702208 (84%)]	Loss: 0.116005Train Epoch: 5 [592128/702208 (84%)]	Loss: 0.080915Train Epoch: 5 [593024/702208 (84%)]	Loss: 0.031619Train Epoch: 5 [594048/702208 (85%)]	Loss: 0.042296Train Epoch: 5 [595072/702208 (85%)]	Loss: 0.045939Train Epoch: 5 [596096/702208 (85%)]	Loss: 0.099292Train Epoch: 5 [597120/702208 (85%)]	Loss: 0.049908Train Epoch: 5 [598016/702208 (85%)]	Loss: 0.107611Train Epoch: 5 [599040/702208 (85%)]	Loss: 0.044059Train Epoch: 5 [600064/702208 (85%)]	Loss: 0.045128
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8097 / 8283] 97 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-3408896-total-98.37-class0-97.75-class1-99.49

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12366 / 12833] 96 %
Accuracy of the network on train loader class  1: [7082 / 7135] 99 %
Train Epoch: 5 [601088/702208 (86%)]	Loss: 0.058199Train Epoch: 5 [602112/702208 (86%)]	Loss: 0.078376Train Epoch: 5 [603008/702208 (86%)]	Loss: 0.073722Train Epoch: 5 [604032/702208 (86%)]	Loss: 0.062219Train Epoch: 5 [605056/702208 (86%)]	Loss: 0.102749Train Epoch: 5 [606080/702208 (86%)]	Loss: 0.042815Train Epoch: 5 [607104/702208 (86%)]	Loss: 0.107968Train Epoch: 5 [608000/702208 (87%)]	Loss: 0.069148Train Epoch: 5 [608128/702208 (87%)]	Loss: 0.072034Train Epoch: 5 [609024/702208 (87%)]	Loss: 0.080830Train Epoch: 5 [610048/702208 (87%)]	Loss: 0.058318Train Epoch: 5 [611072/702208 (87%)]	Loss: 0.022451Train Epoch: 5 [612096/702208 (87%)]	Loss: 0.052687Train Epoch: 5 [613120/702208 (87%)]	Loss: 0.037989Train Epoch: 5 [614016/702208 (87%)]	Loss: 0.022465Train Epoch: 5 [615040/702208 (88%)]	Loss: 0.084191Train Epoch: 5 [616064/702208 (88%)]	Loss: 0.083218Train Epoch: 5 [617088/702208 (88%)]	Loss: 0.033820Train Epoch: 5 [618112/702208 (88%)]	Loss: 0.072551Train Epoch: 5 [619008/702208 (88%)]	Loss: 0.033758Train Epoch: 5 [620032/702208 (88%)]	Loss: 0.035396Train Epoch: 5 [621056/702208 (88%)]	Loss: 0.017256Train Epoch: 5 [622080/702208 (89%)]	Loss: 0.079689Train Epoch: 5 [623104/702208 (89%)]	Loss: 0.136410Train Epoch: 5 [624000/702208 (89%)]	Loss: 0.047452Train Epoch: 5 [624128/702208 (89%)]	Loss: 0.094820Train Epoch: 5 [625024/702208 (89%)]	Loss: 0.045648
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8079 / 8283] 97 %
Accuracy of the network on test loader class  1: [4496 / 4517] 99 %

Writing model: iterations-3433856-total-98.24000000000001-class0-97.54-class1-99.53999999999999
Train Epoch: 5 [626048/702208 (89%)]	Loss: 0.116130Train Epoch: 5 [627072/702208 (89%)]	Loss: 0.122214Train Epoch: 5 [628096/702208 (89%)]	Loss: 0.084691Train Epoch: 5 [629120/702208 (90%)]	Loss: 0.075648Train Epoch: 5 [630016/702208 (90%)]	Loss: 0.048587Train Epoch: 5 [631040/702208 (90%)]	Loss: 0.118941Train Epoch: 5 [632064/702208 (90%)]	Loss: 0.048238Train Epoch: 5 [633088/702208 (90%)]	Loss: 0.036813Train Epoch: 5 [634112/702208 (90%)]	Loss: 0.083509Train Epoch: 5 [635008/702208 (90%)]	Loss: 0.030793Train Epoch: 5 [636032/702208 (91%)]	Loss: 0.080272Train Epoch: 5 [637056/702208 (91%)]	Loss: 0.234152Train Epoch: 5 [638080/702208 (91%)]	Loss: 0.043132Train Epoch: 5 [639104/702208 (91%)]	Loss: 0.039853Train Epoch: 5 [640000/702208 (91%)]	Loss: 0.036745Train Epoch: 5 [640128/702208 (91%)]	Loss: 0.063150Train Epoch: 5 [641024/702208 (91%)]	Loss: 0.040999Train Epoch: 5 [642048/702208 (91%)]	Loss: 0.042235Train Epoch: 5 [643072/702208 (92%)]	Loss: 0.072891Train Epoch: 5 [644096/702208 (92%)]	Loss: 0.101891Train Epoch: 5 [645120/702208 (92%)]	Loss: 0.027224Train Epoch: 5 [646016/702208 (92%)]	Loss: 0.076812Train Epoch: 5 [647040/702208 (92%)]	Loss: 0.040342Train Epoch: 5 [648064/702208 (92%)]	Loss: 0.086874Train Epoch: 5 [649088/702208 (92%)]	Loss: 0.154699Train Epoch: 5 [650112/702208 (93%)]	Loss: 0.040253
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8008 / 8283] 96 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-3458944-total-97.77-class0-96.67999999999999-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12119 / 12833] 94 %
Accuracy of the network on train loader class  1: [7039 / 7135] 98 %
Train Epoch: 5 [651008/702208 (93%)]	Loss: 0.109350Train Epoch: 5 [652032/702208 (93%)]	Loss: 0.049188Train Epoch: 5 [653056/702208 (93%)]	Loss: 0.072265Train Epoch: 5 [654080/702208 (93%)]	Loss: 0.036868Train Epoch: 5 [655104/702208 (93%)]	Loss: 0.017086Train Epoch: 5 [656000/702208 (93%)]	Loss: 0.073098Train Epoch: 5 [656128/702208 (93%)]	Loss: 0.039238Train Epoch: 5 [657024/702208 (94%)]	Loss: 0.073505Train Epoch: 5 [658048/702208 (94%)]	Loss: 0.032314Train Epoch: 5 [659072/702208 (94%)]	Loss: 0.093311Train Epoch: 5 [660096/702208 (94%)]	Loss: 0.088266Train Epoch: 5 [661120/702208 (94%)]	Loss: 0.030311Train Epoch: 5 [662016/702208 (94%)]	Loss: 0.041433Train Epoch: 5 [663040/702208 (94%)]	Loss: 0.068473Train Epoch: 5 [664064/702208 (95%)]	Loss: 0.051478Train Epoch: 5 [665088/702208 (95%)]	Loss: 0.048890Train Epoch: 5 [666112/702208 (95%)]	Loss: 0.102356Train Epoch: 5 [667008/702208 (95%)]	Loss: 0.079427Train Epoch: 5 [668032/702208 (95%)]	Loss: 0.030785Train Epoch: 5 [669056/702208 (95%)]	Loss: 0.038231Train Epoch: 5 [670080/702208 (95%)]	Loss: 0.071263Train Epoch: 5 [671104/702208 (96%)]	Loss: 0.068753Train Epoch: 5 [672000/702208 (96%)]	Loss: 0.044820Train Epoch: 5 [672128/702208 (96%)]	Loss: 0.061228Train Epoch: 5 [673024/702208 (96%)]	Loss: 0.080411Train Epoch: 5 [674048/702208 (96%)]	Loss: 0.085959Train Epoch: 5 [675072/702208 (96%)]	Loss: 0.023805
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8046 / 8283] 97 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %

Writing model: iterations-3483904-total-98.03-class0-97.14-class1-99.67
Train Epoch: 5 [676096/702208 (96%)]	Loss: 0.032289Train Epoch: 5 [677120/702208 (96%)]	Loss: 0.081273Train Epoch: 5 [678016/702208 (97%)]	Loss: 0.071371Train Epoch: 5 [679040/702208 (97%)]	Loss: 0.048544Train Epoch: 5 [680064/702208 (97%)]	Loss: 0.023445Train Epoch: 5 [681088/702208 (97%)]	Loss: 0.056247Train Epoch: 5 [682112/702208 (97%)]	Loss: 0.060604Train Epoch: 5 [683008/702208 (97%)]	Loss: 0.075701Train Epoch: 5 [684032/702208 (97%)]	Loss: 0.028193Train Epoch: 5 [685056/702208 (98%)]	Loss: 0.093946Train Epoch: 5 [686080/702208 (98%)]	Loss: 0.039466Train Epoch: 5 [687104/702208 (98%)]	Loss: 0.055209Train Epoch: 5 [688000/702208 (98%)]	Loss: 0.057081Train Epoch: 5 [688128/702208 (98%)]	Loss: 0.050508Train Epoch: 5 [689024/702208 (98%)]	Loss: 0.068216Train Epoch: 5 [690048/702208 (98%)]	Loss: 0.052563Train Epoch: 5 [691072/702208 (98%)]	Loss: 0.098243Train Epoch: 5 [692096/702208 (99%)]	Loss: 0.024868Train Epoch: 5 [693120/702208 (99%)]	Loss: 0.049315Train Epoch: 5 [694016/702208 (99%)]	Loss: 0.088503Train Epoch: 5 [695040/702208 (99%)]	Loss: 0.031514Train Epoch: 5 [696064/702208 (99%)]	Loss: 0.048141Train Epoch: 5 [697088/702208 (99%)]	Loss: 0.118838Train Epoch: 5 [698112/702208 (99%)]	Loss: 0.046138Train Epoch: 5 [699008/702208 (100%)]	Loss: 0.049621Train Epoch: 5 [700032/702208 (100%)]	Loss: 0.079799
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8018 / 8283] 96 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %

Writing model: iterations-3508864-total-97.81-class0-96.8-class1-99.67

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 93 %
Accuracy of the network on train loader class  0: [11633 / 12833] 90 %
Accuracy of the network on train loader class  1: [7035 / 7135] 98 %
Train Epoch: 5 [701056/702208 (100%)]	Loss: 0.033103Train Epoch: 5 [702080/702208 (100%)]	Loss: 0.044729
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7990 / 8283] 96 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %
Train Epoch: 6 [1024/702208 (0%)]	Loss: 0.050060Train Epoch: 6 [2048/702208 (0%)]	Loss: 0.038671Train Epoch: 6 [3072/702208 (0%)]	Loss: 0.097997Train Epoch: 6 [4096/702208 (1%)]	Loss: 0.046405Train Epoch: 6 [5120/702208 (1%)]	Loss: 0.043571Train Epoch: 6 [6016/702208 (1%)]	Loss: 0.151796Train Epoch: 6 [7040/702208 (1%)]	Loss: 0.035864Train Epoch: 6 [8064/702208 (1%)]	Loss: 0.075365Train Epoch: 6 [9088/702208 (1%)]	Loss: 0.061395Train Epoch: 6 [10112/702208 (1%)]	Loss: 0.039193Train Epoch: 6 [11008/702208 (2%)]	Loss: 0.050053Train Epoch: 6 [12032/702208 (2%)]	Loss: 0.081140Train Epoch: 6 [13056/702208 (2%)]	Loss: 0.089500Train Epoch: 6 [14080/702208 (2%)]	Loss: 0.071676Train Epoch: 6 [15104/702208 (2%)]	Loss: 0.030669Train Epoch: 6 [16000/702208 (2%)]	Loss: 0.026834Train Epoch: 6 [16128/702208 (2%)]	Loss: 0.060269Train Epoch: 6 [17024/702208 (2%)]	Loss: 0.025418Train Epoch: 6 [18048/702208 (3%)]	Loss: 0.098398Train Epoch: 6 [19072/702208 (3%)]	Loss: 0.041704Train Epoch: 6 [20096/702208 (3%)]	Loss: 0.047977Train Epoch: 6 [21120/702208 (3%)]	Loss: 0.083131Train Epoch: 6 [22016/702208 (3%)]	Loss: 0.039358Train Epoch: 6 [23040/702208 (3%)]	Loss: 0.073500Train Epoch: 6 [24064/702208 (3%)]	Loss: 0.046015Train Epoch: 6 [25088/702208 (4%)]	Loss: 0.077056
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8089 / 8283] 97 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-3536128-total-98.3-class0-97.66-class1-99.49
Train Epoch: 6 [26112/702208 (4%)]	Loss: 0.044191Train Epoch: 6 [27008/702208 (4%)]	Loss: 0.056625Train Epoch: 6 [28032/702208 (4%)]	Loss: 0.037452Train Epoch: 6 [29056/702208 (4%)]	Loss: 0.037529Train Epoch: 6 [30080/702208 (4%)]	Loss: 0.031290Train Epoch: 6 [31104/702208 (4%)]	Loss: 0.114336Train Epoch: 6 [32000/702208 (5%)]	Loss: 0.032343Train Epoch: 6 [32128/702208 (5%)]	Loss: 0.019768Train Epoch: 6 [33024/702208 (5%)]	Loss: 0.067962Train Epoch: 6 [34048/702208 (5%)]	Loss: 0.091970Train Epoch: 6 [35072/702208 (5%)]	Loss: 0.160179Train Epoch: 6 [36096/702208 (5%)]	Loss: 0.078175Train Epoch: 6 [37120/702208 (5%)]	Loss: 0.056625Train Epoch: 6 [38016/702208 (5%)]	Loss: 0.087013Train Epoch: 6 [39040/702208 (6%)]	Loss: 0.042005Train Epoch: 6 [40064/702208 (6%)]	Loss: 0.105225Train Epoch: 6 [41088/702208 (6%)]	Loss: 0.060527Train Epoch: 6 [42112/702208 (6%)]	Loss: 0.058892Train Epoch: 6 [43008/702208 (6%)]	Loss: 0.028226Train Epoch: 6 [44032/702208 (6%)]	Loss: 0.039401Train Epoch: 6 [45056/702208 (6%)]	Loss: 0.030849Train Epoch: 6 [46080/702208 (7%)]	Loss: 0.097031Train Epoch: 6 [47104/702208 (7%)]	Loss: 0.043082Train Epoch: 6 [48000/702208 (7%)]	Loss: 0.054916Train Epoch: 6 [48128/702208 (7%)]	Loss: 0.044540Train Epoch: 6 [49024/702208 (7%)]	Loss: 0.020910Train Epoch: 6 [50048/702208 (7%)]	Loss: 0.031564
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8086 / 8283] 97 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-3561088-total-98.33-class0-97.61999999999999-class1-99.62

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12333 / 12833] 96 %
Accuracy of the network on train loader class  1: [7072 / 7135] 99 %
Train Epoch: 6 [51072/702208 (7%)]	Loss: 0.095979Train Epoch: 6 [52096/702208 (7%)]	Loss: 0.058368Train Epoch: 6 [53120/702208 (8%)]	Loss: 0.054761Train Epoch: 6 [54016/702208 (8%)]	Loss: 0.043748Train Epoch: 6 [55040/702208 (8%)]	Loss: 0.048398Train Epoch: 6 [56064/702208 (8%)]	Loss: 0.107323Train Epoch: 6 [57088/702208 (8%)]	Loss: 0.042020Train Epoch: 6 [58112/702208 (8%)]	Loss: 0.080364Train Epoch: 6 [59008/702208 (8%)]	Loss: 0.083128Train Epoch: 6 [60032/702208 (9%)]	Loss: 0.081748Train Epoch: 6 [61056/702208 (9%)]	Loss: 0.022367Train Epoch: 6 [62080/702208 (9%)]	Loss: 0.014733Train Epoch: 6 [63104/702208 (9%)]	Loss: 0.047207Train Epoch: 6 [64000/702208 (9%)]	Loss: 0.107307Train Epoch: 6 [64128/702208 (9%)]	Loss: 0.020623Train Epoch: 6 [65024/702208 (9%)]	Loss: 0.107973Train Epoch: 6 [66048/702208 (9%)]	Loss: 0.054249Train Epoch: 6 [67072/702208 (10%)]	Loss: 0.024097Train Epoch: 6 [68096/702208 (10%)]	Loss: 0.043605Train Epoch: 6 [69120/702208 (10%)]	Loss: 0.041889Train Epoch: 6 [70016/702208 (10%)]	Loss: 0.096056Train Epoch: 6 [71040/702208 (10%)]	Loss: 0.119379Train Epoch: 6 [72064/702208 (10%)]	Loss: 0.045474Train Epoch: 6 [73088/702208 (10%)]	Loss: 0.067768Train Epoch: 6 [74112/702208 (11%)]	Loss: 0.046974Train Epoch: 6 [75008/702208 (11%)]	Loss: 0.098005
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8045 / 8283] 97 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-3586048-total-98.05-class0-97.13000000000001-class1-99.76
Train Epoch: 6 [76032/702208 (11%)]	Loss: 0.068758Train Epoch: 6 [77056/702208 (11%)]	Loss: 0.092444Train Epoch: 6 [78080/702208 (11%)]	Loss: 0.049496Train Epoch: 6 [79104/702208 (11%)]	Loss: 0.040009Train Epoch: 6 [80000/702208 (11%)]	Loss: 0.051710Train Epoch: 6 [80128/702208 (11%)]	Loss: 0.085414Train Epoch: 6 [81024/702208 (12%)]	Loss: 0.016829Train Epoch: 6 [82048/702208 (12%)]	Loss: 0.078729Train Epoch: 6 [83072/702208 (12%)]	Loss: 0.041751Train Epoch: 6 [84096/702208 (12%)]	Loss: 0.042838Train Epoch: 6 [85120/702208 (12%)]	Loss: 0.108013Train Epoch: 6 [86016/702208 (12%)]	Loss: 0.018789Train Epoch: 6 [87040/702208 (12%)]	Loss: 0.055803Train Epoch: 6 [88064/702208 (13%)]	Loss: 0.047732Train Epoch: 6 [89088/702208 (13%)]	Loss: 0.032870Train Epoch: 6 [90112/702208 (13%)]	Loss: 0.075040Train Epoch: 6 [91008/702208 (13%)]	Loss: 0.113898Train Epoch: 6 [92032/702208 (13%)]	Loss: 0.033998Train Epoch: 6 [93056/702208 (13%)]	Loss: 0.040476Train Epoch: 6 [94080/702208 (13%)]	Loss: 0.038383Train Epoch: 6 [95104/702208 (14%)]	Loss: 0.048769Train Epoch: 6 [96000/702208 (14%)]	Loss: 0.058230Train Epoch: 6 [96128/702208 (14%)]	Loss: 0.076951Train Epoch: 6 [97024/702208 (14%)]	Loss: 0.049574Train Epoch: 6 [98048/702208 (14%)]	Loss: 0.038467Train Epoch: 6 [99072/702208 (14%)]	Loss: 0.039070Train Epoch: 6 [100096/702208 (14%)]	Loss: 0.070381
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8093 / 8283] 97 %
Accuracy of the network on test loader class  1: [4499 / 4517] 99 %

Writing model: iterations-3611136-total-98.38-class0-97.71-class1-99.6

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12353 / 12833] 96 %
Accuracy of the network on train loader class  1: [7088 / 7135] 99 %
Train Epoch: 6 [101120/702208 (14%)]	Loss: 0.057491Train Epoch: 6 [102016/702208 (15%)]	Loss: 0.048287Train Epoch: 6 [103040/702208 (15%)]	Loss: 0.044288Train Epoch: 6 [104064/702208 (15%)]	Loss: 0.020898Train Epoch: 6 [105088/702208 (15%)]	Loss: 0.111911Train Epoch: 6 [106112/702208 (15%)]	Loss: 0.063930Train Epoch: 6 [107008/702208 (15%)]	Loss: 0.056307Train Epoch: 6 [108032/702208 (15%)]	Loss: 0.096867Train Epoch: 6 [109056/702208 (16%)]	Loss: 0.075083Train Epoch: 6 [110080/702208 (16%)]	Loss: 0.026079Train Epoch: 6 [111104/702208 (16%)]	Loss: 0.076251Train Epoch: 6 [112000/702208 (16%)]	Loss: 0.038303Train Epoch: 6 [112128/702208 (16%)]	Loss: 0.054170Train Epoch: 6 [113024/702208 (16%)]	Loss: 0.131029Train Epoch: 6 [114048/702208 (16%)]	Loss: 0.037186Train Epoch: 6 [115072/702208 (16%)]	Loss: 0.014082Train Epoch: 6 [116096/702208 (17%)]	Loss: 0.042293Train Epoch: 6 [117120/702208 (17%)]	Loss: 0.137760Train Epoch: 6 [118016/702208 (17%)]	Loss: 0.069868Train Epoch: 6 [119040/702208 (17%)]	Loss: 0.094660Train Epoch: 6 [120064/702208 (17%)]	Loss: 0.107929Train Epoch: 6 [121088/702208 (17%)]	Loss: 0.044798Train Epoch: 6 [122112/702208 (17%)]	Loss: 0.036078Train Epoch: 6 [123008/702208 (18%)]	Loss: 0.053532Train Epoch: 6 [124032/702208 (18%)]	Loss: 0.076586Train Epoch: 6 [125056/702208 (18%)]	Loss: 0.059979
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7989 / 8283] 96 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-3636096-total-97.6-class0-96.45-class1-99.71
Train Epoch: 6 [126080/702208 (18%)]	Loss: 0.124129Train Epoch: 6 [127104/702208 (18%)]	Loss: 0.070717Train Epoch: 6 [128000/702208 (18%)]	Loss: 0.076542Train Epoch: 6 [128128/702208 (18%)]	Loss: 0.033424Train Epoch: 6 [129024/702208 (18%)]	Loss: 0.071403Train Epoch: 6 [130048/702208 (19%)]	Loss: 0.059937Train Epoch: 6 [131072/702208 (19%)]	Loss: 0.053095Train Epoch: 6 [132096/702208 (19%)]	Loss: 0.138209Train Epoch: 6 [133120/702208 (19%)]	Loss: 0.077132Train Epoch: 6 [134016/702208 (19%)]	Loss: 0.074508Train Epoch: 6 [135040/702208 (19%)]	Loss: 0.082471Train Epoch: 6 [136064/702208 (19%)]	Loss: 0.056636Train Epoch: 6 [137088/702208 (20%)]	Loss: 0.020120Train Epoch: 6 [138112/702208 (20%)]	Loss: 0.060689Train Epoch: 6 [139008/702208 (20%)]	Loss: 0.116352Train Epoch: 6 [140032/702208 (20%)]	Loss: 0.072955Train Epoch: 6 [141056/702208 (20%)]	Loss: 0.035290Train Epoch: 6 [142080/702208 (20%)]	Loss: 0.025230Train Epoch: 6 [143104/702208 (20%)]	Loss: 0.044598Train Epoch: 6 [144000/702208 (21%)]	Loss: 0.037177Train Epoch: 6 [144128/702208 (21%)]	Loss: 0.025692Train Epoch: 6 [145024/702208 (21%)]	Loss: 0.044202Train Epoch: 6 [146048/702208 (21%)]	Loss: 0.062111Train Epoch: 6 [147072/702208 (21%)]	Loss: 0.128197Train Epoch: 6 [148096/702208 (21%)]	Loss: 0.132189Train Epoch: 6 [149120/702208 (21%)]	Loss: 0.077638Train Epoch: 6 [150016/702208 (21%)]	Loss: 0.022128
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8022 / 8283] 96 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-3661056-total-97.85000000000001-class0-96.85000000000001-class1-99.69

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12213 / 12833] 95 %
Accuracy of the network on train loader class  1: [6825 / 7135] 95 %
Train Epoch: 6 [151040/702208 (22%)]	Loss: 0.029650Train Epoch: 6 [152064/702208 (22%)]	Loss: 0.025404Train Epoch: 6 [153088/702208 (22%)]	Loss: 0.040345Train Epoch: 6 [154112/702208 (22%)]	Loss: 0.029678Train Epoch: 6 [155008/702208 (22%)]	Loss: 0.032016Train Epoch: 6 [156032/702208 (22%)]	Loss: 0.093497Train Epoch: 6 [157056/702208 (22%)]	Loss: 0.055347Train Epoch: 6 [158080/702208 (23%)]	Loss: 0.019653Train Epoch: 6 [159104/702208 (23%)]	Loss: 0.059498Train Epoch: 6 [160000/702208 (23%)]	Loss: 0.024374Train Epoch: 6 [160128/702208 (23%)]	Loss: 0.020043Train Epoch: 6 [161024/702208 (23%)]	Loss: 0.033330Train Epoch: 6 [162048/702208 (23%)]	Loss: 0.015979Train Epoch: 6 [163072/702208 (23%)]	Loss: 0.060148Train Epoch: 6 [164096/702208 (23%)]	Loss: 0.053314Train Epoch: 6 [165120/702208 (24%)]	Loss: 0.067663Train Epoch: 6 [166016/702208 (24%)]	Loss: 0.041188Train Epoch: 6 [167040/702208 (24%)]	Loss: 0.036323Train Epoch: 6 [168064/702208 (24%)]	Loss: 0.037217Train Epoch: 6 [169088/702208 (24%)]	Loss: 0.040146Train Epoch: 6 [170112/702208 (24%)]	Loss: 0.041677Train Epoch: 6 [171008/702208 (24%)]	Loss: 0.044081Train Epoch: 6 [172032/702208 (24%)]	Loss: 0.175209Train Epoch: 6 [173056/702208 (25%)]	Loss: 0.062035Train Epoch: 6 [174080/702208 (25%)]	Loss: 0.042537Train Epoch: 6 [175104/702208 (25%)]	Loss: 0.109875
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8099 / 8283] 97 %
Accuracy of the network on test loader class  1: [4495 / 4517] 99 %

Writing model: iterations-3686144-total-98.39-class0-97.78-class1-99.51
Train Epoch: 6 [176000/702208 (25%)]	Loss: 0.032531Train Epoch: 6 [176128/702208 (25%)]	Loss: 0.040182Train Epoch: 6 [177024/702208 (25%)]	Loss: 0.027694Train Epoch: 6 [178048/702208 (25%)]	Loss: 0.089332Train Epoch: 6 [179072/702208 (26%)]	Loss: 0.086113Train Epoch: 6 [180096/702208 (26%)]	Loss: 0.044058Train Epoch: 6 [181120/702208 (26%)]	Loss: 0.075538Train Epoch: 6 [182016/702208 (26%)]	Loss: 0.053684Train Epoch: 6 [183040/702208 (26%)]	Loss: 0.099775Train Epoch: 6 [184064/702208 (26%)]	Loss: 0.106037Train Epoch: 6 [185088/702208 (26%)]	Loss: 0.040524Train Epoch: 6 [186112/702208 (27%)]	Loss: 0.018440Train Epoch: 6 [187008/702208 (27%)]	Loss: 0.025631Train Epoch: 6 [188032/702208 (27%)]	Loss: 0.046816Train Epoch: 6 [189056/702208 (27%)]	Loss: 0.049062Train Epoch: 6 [190080/702208 (27%)]	Loss: 0.081595Train Epoch: 6 [191104/702208 (27%)]	Loss: 0.063814Train Epoch: 6 [192000/702208 (27%)]	Loss: 0.055292Train Epoch: 6 [192128/702208 (27%)]	Loss: 0.093875Train Epoch: 6 [193024/702208 (27%)]	Loss: 0.026997Train Epoch: 6 [194048/702208 (28%)]	Loss: 0.026815Train Epoch: 6 [195072/702208 (28%)]	Loss: 0.075968Train Epoch: 6 [196096/702208 (28%)]	Loss: 0.184436Train Epoch: 6 [197120/702208 (28%)]	Loss: 0.028585Train Epoch: 6 [198016/702208 (28%)]	Loss: 0.076792Train Epoch: 6 [199040/702208 (28%)]	Loss: 0.169056Train Epoch: 6 [200064/702208 (28%)]	Loss: 0.076585
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7931 / 8283] 95 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-3711104-total-97.18-class0-95.75-class1-99.8

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 91 %
Accuracy of the network on train loader class  0: [11326 / 12833] 88 %
Accuracy of the network on train loader class  1: [7000 / 7135] 98 %
Train Epoch: 6 [201088/702208 (29%)]	Loss: 0.083633Train Epoch: 6 [202112/702208 (29%)]	Loss: 0.057085Train Epoch: 6 [203008/702208 (29%)]	Loss: 0.030974Train Epoch: 6 [204032/702208 (29%)]	Loss: 0.073795Train Epoch: 6 [205056/702208 (29%)]	Loss: 0.029000Train Epoch: 6 [206080/702208 (29%)]	Loss: 0.052843Train Epoch: 6 [207104/702208 (29%)]	Loss: 0.088580Train Epoch: 6 [208000/702208 (30%)]	Loss: 0.057844Train Epoch: 6 [208128/702208 (30%)]	Loss: 0.056196Train Epoch: 6 [209024/702208 (30%)]	Loss: 0.036925Train Epoch: 6 [210048/702208 (30%)]	Loss: 0.054068Train Epoch: 6 [211072/702208 (30%)]	Loss: 0.086595Train Epoch: 6 [212096/702208 (30%)]	Loss: 0.027378Train Epoch: 6 [213120/702208 (30%)]	Loss: 0.041873Train Epoch: 6 [214016/702208 (30%)]	Loss: 0.041524Train Epoch: 6 [215040/702208 (31%)]	Loss: 0.069530Train Epoch: 6 [216064/702208 (31%)]	Loss: 0.051351Train Epoch: 6 [217088/702208 (31%)]	Loss: 0.097321Train Epoch: 6 [218112/702208 (31%)]	Loss: 0.060326Train Epoch: 6 [219008/702208 (31%)]	Loss: 0.081919Train Epoch: 6 [220032/702208 (31%)]	Loss: 0.086804Train Epoch: 6 [221056/702208 (31%)]	Loss: 0.046178Train Epoch: 6 [222080/702208 (32%)]	Loss: 0.087514Train Epoch: 6 [223104/702208 (32%)]	Loss: 0.044770Train Epoch: 6 [224000/702208 (32%)]	Loss: 0.151631Train Epoch: 6 [224128/702208 (32%)]	Loss: 0.029190Train Epoch: 6 [225024/702208 (32%)]	Loss: 0.058363
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7700 / 8283] 92 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-3736064-total-95.39999999999999-class0-92.96-class1-99.87
Train Epoch: 6 [226048/702208 (32%)]	Loss: 0.042961Train Epoch: 6 [227072/702208 (32%)]	Loss: 0.134079Train Epoch: 6 [228096/702208 (32%)]	Loss: 0.053734Train Epoch: 6 [229120/702208 (33%)]	Loss: 0.030546Train Epoch: 6 [230016/702208 (33%)]	Loss: 0.090967Train Epoch: 6 [231040/702208 (33%)]	Loss: 0.101753Train Epoch: 6 [232064/702208 (33%)]	Loss: 0.043297Train Epoch: 6 [233088/702208 (33%)]	Loss: 0.030601Train Epoch: 6 [234112/702208 (33%)]	Loss: 0.097987Train Epoch: 6 [235008/702208 (33%)]	Loss: 0.050233Train Epoch: 6 [236032/702208 (34%)]	Loss: 0.060630Train Epoch: 6 [237056/702208 (34%)]	Loss: 0.104155Train Epoch: 6 [238080/702208 (34%)]	Loss: 0.035991Train Epoch: 6 [239104/702208 (34%)]	Loss: 0.053007Train Epoch: 6 [240000/702208 (34%)]	Loss: 0.058216Train Epoch: 6 [240128/702208 (34%)]	Loss: 0.050838Train Epoch: 6 [241024/702208 (34%)]	Loss: 0.024966Train Epoch: 6 [242048/702208 (34%)]	Loss: 0.047523Train Epoch: 6 [243072/702208 (35%)]	Loss: 0.025592Train Epoch: 6 [244096/702208 (35%)]	Loss: 0.115671Train Epoch: 6 [245120/702208 (35%)]	Loss: 0.029504Train Epoch: 6 [246016/702208 (35%)]	Loss: 0.046227Train Epoch: 6 [247040/702208 (35%)]	Loss: 0.072519Train Epoch: 6 [248064/702208 (35%)]	Loss: 0.069160Train Epoch: 6 [249088/702208 (35%)]	Loss: 0.070727Train Epoch: 6 [250112/702208 (36%)]	Loss: 0.047284
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7995 / 8283] 96 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-3761152-total-97.61999999999999-class0-96.52-class1-99.62

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12170 / 12833] 94 %
Accuracy of the network on train loader class  1: [7069 / 7135] 99 %
Train Epoch: 6 [251008/702208 (36%)]	Loss: 0.095550Train Epoch: 6 [252032/702208 (36%)]	Loss: 0.144196Train Epoch: 6 [253056/702208 (36%)]	Loss: 0.032359Train Epoch: 6 [254080/702208 (36%)]	Loss: 0.050608Train Epoch: 6 [255104/702208 (36%)]	Loss: 0.054707Train Epoch: 6 [256000/702208 (36%)]	Loss: 0.059969Train Epoch: 6 [256128/702208 (36%)]	Loss: 0.093813Train Epoch: 6 [257024/702208 (37%)]	Loss: 0.038499Train Epoch: 6 [258048/702208 (37%)]	Loss: 0.114525Train Epoch: 6 [259072/702208 (37%)]	Loss: 0.047942Train Epoch: 6 [260096/702208 (37%)]	Loss: 0.032101Train Epoch: 6 [261120/702208 (37%)]	Loss: 0.062072Train Epoch: 6 [262016/702208 (37%)]	Loss: 0.069437Train Epoch: 6 [263040/702208 (37%)]	Loss: 0.035880Train Epoch: 6 [264064/702208 (38%)]	Loss: 0.046572Train Epoch: 6 [265088/702208 (38%)]	Loss: 0.107424Train Epoch: 6 [266112/702208 (38%)]	Loss: 0.038121Train Epoch: 6 [267008/702208 (38%)]	Loss: 0.051971Train Epoch: 6 [268032/702208 (38%)]	Loss: 0.033199Train Epoch: 6 [269056/702208 (38%)]	Loss: 0.150523Train Epoch: 6 [270080/702208 (38%)]	Loss: 0.074269Train Epoch: 6 [271104/702208 (39%)]	Loss: 0.065887Train Epoch: 6 [272000/702208 (39%)]	Loss: 0.129841Train Epoch: 6 [272128/702208 (39%)]	Loss: 0.027590Train Epoch: 6 [273024/702208 (39%)]	Loss: 0.072290Train Epoch: 6 [274048/702208 (39%)]	Loss: 0.060815Train Epoch: 6 [275072/702208 (39%)]	Loss: 0.040535
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8075 / 8283] 97 %
Accuracy of the network on test loader class  1: [4497 / 4517] 99 %

Writing model: iterations-3786112-total-98.22-class0-97.49-class1-99.56
Train Epoch: 6 [276096/702208 (39%)]	Loss: 0.152775Train Epoch: 6 [277120/702208 (39%)]	Loss: 0.038342Train Epoch: 6 [278016/702208 (40%)]	Loss: 0.028807Train Epoch: 6 [279040/702208 (40%)]	Loss: 0.069115Train Epoch: 6 [280064/702208 (40%)]	Loss: 0.025063Train Epoch: 6 [281088/702208 (40%)]	Loss: 0.027124Train Epoch: 6 [282112/702208 (40%)]	Loss: 0.065687Train Epoch: 6 [283008/702208 (40%)]	Loss: 0.054518Train Epoch: 6 [284032/702208 (40%)]	Loss: 0.040339Train Epoch: 6 [285056/702208 (41%)]	Loss: 0.103483Train Epoch: 6 [286080/702208 (41%)]	Loss: 0.074824Train Epoch: 6 [287104/702208 (41%)]	Loss: 0.081199Train Epoch: 6 [288000/702208 (41%)]	Loss: 0.038830Train Epoch: 6 [288128/702208 (41%)]	Loss: 0.041845Train Epoch: 6 [289024/702208 (41%)]	Loss: 0.068090Train Epoch: 6 [290048/702208 (41%)]	Loss: 0.070367Train Epoch: 6 [291072/702208 (41%)]	Loss: 0.041157Train Epoch: 6 [292096/702208 (42%)]	Loss: 0.066582Train Epoch: 6 [293120/702208 (42%)]	Loss: 0.074811Train Epoch: 6 [294016/702208 (42%)]	Loss: 0.066323Train Epoch: 6 [295040/702208 (42%)]	Loss: 0.056710Train Epoch: 6 [296064/702208 (42%)]	Loss: 0.056708Train Epoch: 6 [297088/702208 (42%)]	Loss: 0.051710Train Epoch: 6 [298112/702208 (42%)]	Loss: 0.066869Train Epoch: 6 [299008/702208 (43%)]	Loss: 0.047173Train Epoch: 6 [300032/702208 (43%)]	Loss: 0.033772
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8028 / 8283] 96 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-3811072-total-97.92-class0-96.92-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12266 / 12833] 95 %
Accuracy of the network on train loader class  1: [7085 / 7135] 99 %
Train Epoch: 6 [301056/702208 (43%)]	Loss: 0.104638Train Epoch: 6 [302080/702208 (43%)]	Loss: 0.035542Train Epoch: 6 [303104/702208 (43%)]	Loss: 0.050313Train Epoch: 6 [304000/702208 (43%)]	Loss: 0.057578Train Epoch: 6 [304128/702208 (43%)]	Loss: 0.081770Train Epoch: 6 [305024/702208 (43%)]	Loss: 0.052080Train Epoch: 6 [306048/702208 (44%)]	Loss: 0.034221Train Epoch: 6 [307072/702208 (44%)]	Loss: 0.057587Train Epoch: 6 [308096/702208 (44%)]	Loss: 0.061042Train Epoch: 6 [309120/702208 (44%)]	Loss: 0.111049Train Epoch: 6 [310016/702208 (44%)]	Loss: 0.075095Train Epoch: 6 [311040/702208 (44%)]	Loss: 0.034797Train Epoch: 6 [312064/702208 (44%)]	Loss: 0.059400Train Epoch: 6 [313088/702208 (45%)]	Loss: 0.039822Train Epoch: 6 [314112/702208 (45%)]	Loss: 0.034716Train Epoch: 6 [315008/702208 (45%)]	Loss: 0.024534Train Epoch: 6 [316032/702208 (45%)]	Loss: 0.032177Train Epoch: 6 [317056/702208 (45%)]	Loss: 0.050578Train Epoch: 6 [318080/702208 (45%)]	Loss: 0.048875Train Epoch: 6 [319104/702208 (45%)]	Loss: 0.043177Train Epoch: 6 [320000/702208 (46%)]	Loss: 0.048237Train Epoch: 6 [320128/702208 (46%)]	Loss: 0.043528Train Epoch: 6 [321024/702208 (46%)]	Loss: 0.066604Train Epoch: 6 [322048/702208 (46%)]	Loss: 0.051106Train Epoch: 6 [323072/702208 (46%)]	Loss: 0.046518Train Epoch: 6 [324096/702208 (46%)]	Loss: 0.038660Train Epoch: 6 [325120/702208 (46%)]	Loss: 0.031633
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7969 / 8283] 96 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-3836160-total-97.5-class0-96.21-class1-99.87
Train Epoch: 6 [326016/702208 (46%)]	Loss: 0.094837Train Epoch: 6 [327040/702208 (47%)]	Loss: 0.043485Train Epoch: 6 [328064/702208 (47%)]	Loss: 0.054752Train Epoch: 6 [329088/702208 (47%)]	Loss: 0.018692Train Epoch: 6 [330112/702208 (47%)]	Loss: 0.059549Train Epoch: 6 [331008/702208 (47%)]	Loss: 0.031000Train Epoch: 6 [332032/702208 (47%)]	Loss: 0.057764Train Epoch: 6 [333056/702208 (47%)]	Loss: 0.021976Train Epoch: 6 [334080/702208 (48%)]	Loss: 0.034409Train Epoch: 6 [335104/702208 (48%)]	Loss: 0.042495Train Epoch: 6 [336000/702208 (48%)]	Loss: 0.052160Train Epoch: 6 [336128/702208 (48%)]	Loss: 0.026965Train Epoch: 6 [337024/702208 (48%)]	Loss: 0.065656Train Epoch: 6 [338048/702208 (48%)]	Loss: 0.054594Train Epoch: 6 [339072/702208 (48%)]	Loss: 0.084264Train Epoch: 6 [340096/702208 (48%)]	Loss: 0.024909Train Epoch: 6 [341120/702208 (49%)]	Loss: 0.063428Train Epoch: 6 [342016/702208 (49%)]	Loss: 0.074340Train Epoch: 6 [343040/702208 (49%)]	Loss: 0.074598Train Epoch: 6 [344064/702208 (49%)]	Loss: 0.035138Train Epoch: 6 [345088/702208 (49%)]	Loss: 0.014134Train Epoch: 6 [346112/702208 (49%)]	Loss: 0.061636Train Epoch: 6 [347008/702208 (49%)]	Loss: 0.073088Train Epoch: 6 [348032/702208 (50%)]	Loss: 0.048730Train Epoch: 6 [349056/702208 (50%)]	Loss: 0.029400Train Epoch: 6 [350080/702208 (50%)]	Loss: 0.045924
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8036 / 8283] 97 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-3861120-total-97.97-class0-97.02-class1-99.71

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12338 / 12833] 96 %
Accuracy of the network on train loader class  1: [7077 / 7135] 99 %
Train Epoch: 6 [351104/702208 (50%)]	Loss: 0.028252Train Epoch: 6 [352000/702208 (50%)]	Loss: 0.047414Train Epoch: 6 [352128/702208 (50%)]	Loss: 0.105068Train Epoch: 6 [353024/702208 (50%)]	Loss: 0.035237Train Epoch: 6 [354048/702208 (50%)]	Loss: 0.045025Train Epoch: 6 [355072/702208 (51%)]	Loss: 0.062969Train Epoch: 6 [356096/702208 (51%)]	Loss: 0.036199Train Epoch: 6 [357120/702208 (51%)]	Loss: 0.113601Train Epoch: 6 [358016/702208 (51%)]	Loss: 0.080235Train Epoch: 6 [359040/702208 (51%)]	Loss: 0.062376Train Epoch: 6 [360064/702208 (51%)]	Loss: 0.083030Train Epoch: 6 [361088/702208 (51%)]	Loss: 0.077805Train Epoch: 6 [362112/702208 (52%)]	Loss: 0.069476Train Epoch: 6 [363008/702208 (52%)]	Loss: 0.080642Train Epoch: 6 [364032/702208 (52%)]	Loss: 0.027556Train Epoch: 6 [365056/702208 (52%)]	Loss: 0.084354Train Epoch: 6 [366080/702208 (52%)]	Loss: 0.039500Train Epoch: 6 [367104/702208 (52%)]	Loss: 0.036700Train Epoch: 6 [368000/702208 (52%)]	Loss: 0.083120Train Epoch: 6 [368128/702208 (52%)]	Loss: 0.078600Train Epoch: 6 [369024/702208 (53%)]	Loss: 0.053892Train Epoch: 6 [370048/702208 (53%)]	Loss: 0.063540Train Epoch: 6 [371072/702208 (53%)]	Loss: 0.059024Train Epoch: 6 [372096/702208 (53%)]	Loss: 0.075529Train Epoch: 6 [373120/702208 (53%)]	Loss: 0.032702Train Epoch: 6 [374016/702208 (53%)]	Loss: 0.048591Train Epoch: 6 [375040/702208 (53%)]	Loss: 0.038551
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8080 / 8283] 97 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-3886080-total-98.3-class0-97.55-class1-99.69
Train Epoch: 6 [376064/702208 (54%)]	Loss: 0.025145Train Epoch: 6 [377088/702208 (54%)]	Loss: 0.059342Train Epoch: 6 [378112/702208 (54%)]	Loss: 0.115650Train Epoch: 6 [379008/702208 (54%)]	Loss: 0.036281Train Epoch: 6 [380032/702208 (54%)]	Loss: 0.023801Train Epoch: 6 [381056/702208 (54%)]	Loss: 0.069584Train Epoch: 6 [382080/702208 (54%)]	Loss: 0.096876Train Epoch: 6 [383104/702208 (55%)]	Loss: 0.034361Train Epoch: 6 [384000/702208 (55%)]	Loss: 0.076598Train Epoch: 6 [384128/702208 (55%)]	Loss: 0.034423Train Epoch: 6 [385024/702208 (55%)]	Loss: 0.021823Train Epoch: 6 [386048/702208 (55%)]	Loss: 0.033004Train Epoch: 6 [387072/702208 (55%)]	Loss: 0.058924Train Epoch: 6 [388096/702208 (55%)]	Loss: 0.057639Train Epoch: 6 [389120/702208 (55%)]	Loss: 0.059011Train Epoch: 6 [390016/702208 (56%)]	Loss: 0.028954Train Epoch: 6 [391040/702208 (56%)]	Loss: 0.031645Train Epoch: 6 [392064/702208 (56%)]	Loss: 0.019965Train Epoch: 6 [393088/702208 (56%)]	Loss: 0.064452Train Epoch: 6 [394112/702208 (56%)]	Loss: 0.030943Train Epoch: 6 [395008/702208 (56%)]	Loss: 0.026093Train Epoch: 6 [396032/702208 (56%)]	Loss: 0.052445Train Epoch: 6 [397056/702208 (57%)]	Loss: 0.096549Train Epoch: 6 [398080/702208 (57%)]	Loss: 0.100518Train Epoch: 6 [399104/702208 (57%)]	Loss: 0.032806Train Epoch: 6 [400000/702208 (57%)]	Loss: 0.031269
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8110 / 8283] 97 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-3911040-total-98.52-class0-97.91-class1-99.62

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12410 / 12833] 96 %
Accuracy of the network on train loader class  1: [7073 / 7135] 99 %
Train Epoch: 6 [400128/702208 (57%)]	Loss: 0.056417
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8107 / 8283] 97 %
Accuracy of the network on test loader class  1: [4501 / 4517] 99 %

Writing model: iterations-3911168-total-98.5-class0-97.88-class1-99.65

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12420 / 12833] 96 %
Accuracy of the network on train loader class  1: [7071 / 7135] 99 %
Train Epoch: 6 [401024/702208 (57%)]	Loss: 0.071316Train Epoch: 6 [402048/702208 (57%)]	Loss: 0.049370Train Epoch: 6 [403072/702208 (57%)]	Loss: 0.045892Train Epoch: 6 [404096/702208 (58%)]	Loss: 0.048603Train Epoch: 6 [405120/702208 (58%)]	Loss: 0.034885Train Epoch: 6 [406016/702208 (58%)]	Loss: 0.058564Train Epoch: 6 [407040/702208 (58%)]	Loss: 0.055092Train Epoch: 6 [408064/702208 (58%)]	Loss: 0.038480Train Epoch: 6 [409088/702208 (58%)]	Loss: 0.085160Train Epoch: 6 [410112/702208 (58%)]	Loss: 0.074886Train Epoch: 6 [411008/702208 (59%)]	Loss: 0.084212Train Epoch: 6 [412032/702208 (59%)]	Loss: 0.034268Train Epoch: 6 [413056/702208 (59%)]	Loss: 0.036837Train Epoch: 6 [414080/702208 (59%)]	Loss: 0.108763Train Epoch: 6 [415104/702208 (59%)]	Loss: 0.023034Train Epoch: 6 [416000/702208 (59%)]	Loss: 0.065862Train Epoch: 6 [416128/702208 (59%)]	Loss: 0.024070Train Epoch: 6 [417024/702208 (59%)]	Loss: 0.068769Train Epoch: 6 [418048/702208 (60%)]	Loss: 0.042262Train Epoch: 6 [419072/702208 (60%)]	Loss: 0.074960Train Epoch: 6 [420096/702208 (60%)]	Loss: 0.057786Train Epoch: 6 [421120/702208 (60%)]	Loss: 0.048022Train Epoch: 6 [422016/702208 (60%)]	Loss: 0.019719Train Epoch: 6 [423040/702208 (60%)]	Loss: 0.031267Train Epoch: 6 [424064/702208 (60%)]	Loss: 0.029361Train Epoch: 6 [425088/702208 (61%)]	Loss: 0.029878
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8044 / 8283] 97 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-3936128-total-98.09-class0-97.11-class1-99.89
Train Epoch: 6 [426112/702208 (61%)]	Loss: 0.102767Train Epoch: 6 [427008/702208 (61%)]	Loss: 0.066071Train Epoch: 6 [428032/702208 (61%)]	Loss: 0.085786Train Epoch: 6 [429056/702208 (61%)]	Loss: 0.092463Train Epoch: 6 [430080/702208 (61%)]	Loss: 0.088700Train Epoch: 6 [431104/702208 (61%)]	Loss: 0.053794Train Epoch: 6 [432000/702208 (62%)]	Loss: 0.051500Train Epoch: 6 [432128/702208 (62%)]	Loss: 0.024898Train Epoch: 6 [433024/702208 (62%)]	Loss: 0.029271Train Epoch: 6 [434048/702208 (62%)]	Loss: 0.014444Train Epoch: 6 [435072/702208 (62%)]	Loss: 0.102819Train Epoch: 6 [436096/702208 (62%)]	Loss: 0.033314Train Epoch: 6 [437120/702208 (62%)]	Loss: 0.063385Train Epoch: 6 [438016/702208 (62%)]	Loss: 0.177328Train Epoch: 6 [439040/702208 (63%)]	Loss: 0.092278Train Epoch: 6 [440064/702208 (63%)]	Loss: 0.163843Train Epoch: 6 [441088/702208 (63%)]	Loss: 0.034388Train Epoch: 6 [442112/702208 (63%)]	Loss: 0.070583Train Epoch: 6 [443008/702208 (63%)]	Loss: 0.089769Train Epoch: 6 [444032/702208 (63%)]	Loss: 0.051452Train Epoch: 6 [445056/702208 (63%)]	Loss: 0.049010Train Epoch: 6 [446080/702208 (64%)]	Loss: 0.093127Train Epoch: 6 [447104/702208 (64%)]	Loss: 0.024951Train Epoch: 6 [448000/702208 (64%)]	Loss: 0.054490Train Epoch: 6 [448128/702208 (64%)]	Loss: 0.149880Train Epoch: 6 [449024/702208 (64%)]	Loss: 0.067899Train Epoch: 6 [450048/702208 (64%)]	Loss: 0.034239
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7953 / 8283] 96 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-3961088-total-97.39-class0-96.02000000000001-class1-99.91

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12249 / 12833] 95 %
Accuracy of the network on train loader class  1: [7095 / 7135] 99 %
Train Epoch: 6 [451072/702208 (64%)]	Loss: 0.146831Train Epoch: 6 [452096/702208 (64%)]	Loss: 0.065462Train Epoch: 6 [453120/702208 (65%)]	Loss: 0.023246Train Epoch: 6 [454016/702208 (65%)]	Loss: 0.056866Train Epoch: 6 [455040/702208 (65%)]	Loss: 0.059409Train Epoch: 6 [456064/702208 (65%)]	Loss: 0.041440Train Epoch: 6 [457088/702208 (65%)]	Loss: 0.055402Train Epoch: 6 [458112/702208 (65%)]	Loss: 0.038248Train Epoch: 6 [459008/702208 (65%)]	Loss: 0.047996Train Epoch: 6 [460032/702208 (66%)]	Loss: 0.057366Train Epoch: 6 [461056/702208 (66%)]	Loss: 0.109043Train Epoch: 6 [462080/702208 (66%)]	Loss: 0.051100Train Epoch: 6 [463104/702208 (66%)]	Loss: 0.056696Train Epoch: 6 [464000/702208 (66%)]	Loss: 0.071891Train Epoch: 6 [464128/702208 (66%)]	Loss: 0.091631Train Epoch: 6 [465024/702208 (66%)]	Loss: 0.063043Train Epoch: 6 [466048/702208 (66%)]	Loss: 0.077904Train Epoch: 6 [467072/702208 (67%)]	Loss: 0.041082Train Epoch: 6 [468096/702208 (67%)]	Loss: 0.057198Train Epoch: 6 [469120/702208 (67%)]	Loss: 0.031786Train Epoch: 6 [470016/702208 (67%)]	Loss: 0.020193Train Epoch: 6 [471040/702208 (67%)]	Loss: 0.056950Train Epoch: 6 [472064/702208 (67%)]	Loss: 0.078477Train Epoch: 6 [473088/702208 (67%)]	Loss: 0.056891Train Epoch: 6 [474112/702208 (68%)]	Loss: 0.043718Train Epoch: 6 [475008/702208 (68%)]	Loss: 0.049249
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8082 / 8283] 97 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-3986048-total-98.32-class0-97.57000000000001-class1-99.69
Train Epoch: 6 [476032/702208 (68%)]	Loss: 0.030684Train Epoch: 6 [477056/702208 (68%)]	Loss: 0.095206Train Epoch: 6 [478080/702208 (68%)]	Loss: 0.036190Train Epoch: 6 [479104/702208 (68%)]	Loss: 0.044961Train Epoch: 6 [480000/702208 (68%)]	Loss: 0.113631Train Epoch: 6 [480128/702208 (68%)]	Loss: 0.034368Train Epoch: 6 [481024/702208 (69%)]	Loss: 0.050995Train Epoch: 6 [482048/702208 (69%)]	Loss: 0.101240Train Epoch: 6 [483072/702208 (69%)]	Loss: 0.073043Train Epoch: 6 [484096/702208 (69%)]	Loss: 0.075181Train Epoch: 6 [485120/702208 (69%)]	Loss: 0.045338Train Epoch: 6 [486016/702208 (69%)]	Loss: 0.022584Train Epoch: 6 [487040/702208 (69%)]	Loss: 0.059278Train Epoch: 6 [488064/702208 (70%)]	Loss: 0.054220Train Epoch: 6 [489088/702208 (70%)]	Loss: 0.046071Train Epoch: 6 [490112/702208 (70%)]	Loss: 0.060471Train Epoch: 6 [491008/702208 (70%)]	Loss: 0.037502Train Epoch: 6 [492032/702208 (70%)]	Loss: 0.077569Train Epoch: 6 [493056/702208 (70%)]	Loss: 0.047823Train Epoch: 6 [494080/702208 (70%)]	Loss: 0.040503Train Epoch: 6 [495104/702208 (71%)]	Loss: 0.070134Train Epoch: 6 [496000/702208 (71%)]	Loss: 0.086064Train Epoch: 6 [496128/702208 (71%)]	Loss: 0.057353Train Epoch: 6 [497024/702208 (71%)]	Loss: 0.030763Train Epoch: 6 [498048/702208 (71%)]	Loss: 0.048107Train Epoch: 6 [499072/702208 (71%)]	Loss: 0.054882Train Epoch: 6 [500096/702208 (71%)]	Loss: 0.030930
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8092 / 8283] 97 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-4011136-total-98.41-class0-97.69-class1-99.72999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12373 / 12833] 96 %
Accuracy of the network on train loader class  1: [7082 / 7135] 99 %
Train Epoch: 6 [501120/702208 (71%)]	Loss: 0.122561Train Epoch: 6 [502016/702208 (71%)]	Loss: 0.068573Train Epoch: 6 [503040/702208 (72%)]	Loss: 0.034653Train Epoch: 6 [504064/702208 (72%)]	Loss: 0.056663Train Epoch: 6 [505088/702208 (72%)]	Loss: 0.059673Train Epoch: 6 [506112/702208 (72%)]	Loss: 0.121739Train Epoch: 6 [507008/702208 (72%)]	Loss: 0.036047Train Epoch: 6 [508032/702208 (72%)]	Loss: 0.114055Train Epoch: 6 [509056/702208 (72%)]	Loss: 0.066245Train Epoch: 6 [510080/702208 (73%)]	Loss: 0.055080Train Epoch: 6 [511104/702208 (73%)]	Loss: 0.084120Train Epoch: 6 [512000/702208 (73%)]	Loss: 0.025951Train Epoch: 6 [512128/702208 (73%)]	Loss: 0.052672Train Epoch: 6 [513024/702208 (73%)]	Loss: 0.021548Train Epoch: 6 [514048/702208 (73%)]	Loss: 0.065689Train Epoch: 6 [515072/702208 (73%)]	Loss: 0.075477Train Epoch: 6 [516096/702208 (73%)]	Loss: 0.150563Train Epoch: 6 [517120/702208 (74%)]	Loss: 0.044327Train Epoch: 6 [518016/702208 (74%)]	Loss: 0.069640Train Epoch: 6 [519040/702208 (74%)]	Loss: 0.075672Train Epoch: 6 [520064/702208 (74%)]	Loss: 0.079305Train Epoch: 6 [521088/702208 (74%)]	Loss: 0.037449Train Epoch: 6 [522112/702208 (74%)]	Loss: 0.041883Train Epoch: 6 [523008/702208 (74%)]	Loss: 0.077227Train Epoch: 6 [524032/702208 (75%)]	Loss: 0.029680Train Epoch: 6 [525056/702208 (75%)]	Loss: 0.025279
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7965 / 8283] 96 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-4036096-total-97.48-class0-96.16-class1-99.89
Train Epoch: 6 [526080/702208 (75%)]	Loss: 0.024015Train Epoch: 6 [527104/702208 (75%)]	Loss: 0.088483Train Epoch: 6 [528000/702208 (75%)]	Loss: 0.060585Train Epoch: 6 [528128/702208 (75%)]	Loss: 0.067410Train Epoch: 6 [529024/702208 (75%)]	Loss: 0.048134Train Epoch: 6 [530048/702208 (75%)]	Loss: 0.044267Train Epoch: 6 [531072/702208 (76%)]	Loss: 0.033360Train Epoch: 6 [532096/702208 (76%)]	Loss: 0.064069Train Epoch: 6 [533120/702208 (76%)]	Loss: 0.035727Train Epoch: 6 [534016/702208 (76%)]	Loss: 0.054061Train Epoch: 6 [535040/702208 (76%)]	Loss: 0.040313Train Epoch: 6 [536064/702208 (76%)]	Loss: 0.035581Train Epoch: 6 [537088/702208 (76%)]	Loss: 0.014870Train Epoch: 6 [538112/702208 (77%)]	Loss: 0.033490Train Epoch: 6 [539008/702208 (77%)]	Loss: 0.043313Train Epoch: 6 [540032/702208 (77%)]	Loss: 0.099514Train Epoch: 6 [541056/702208 (77%)]	Loss: 0.040409Train Epoch: 6 [542080/702208 (77%)]	Loss: 0.026438Train Epoch: 6 [543104/702208 (77%)]	Loss: 0.073589Train Epoch: 6 [544000/702208 (77%)]	Loss: 0.040068Train Epoch: 6 [544128/702208 (77%)]	Loss: 0.089007Train Epoch: 6 [545024/702208 (78%)]	Loss: 0.078911Train Epoch: 6 [546048/702208 (78%)]	Loss: 0.015918Train Epoch: 6 [547072/702208 (78%)]	Loss: 0.042079Train Epoch: 6 [548096/702208 (78%)]	Loss: 0.029813Train Epoch: 6 [549120/702208 (78%)]	Loss: 0.043799Train Epoch: 6 [550016/702208 (78%)]	Loss: 0.228540
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8074 / 8283] 97 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-4061056-total-98.26-class0-97.48-class1-99.69

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12204 / 12833] 95 %
Accuracy of the network on train loader class  1: [7060 / 7135] 98 %
Train Epoch: 6 [551040/702208 (78%)]	Loss: 0.044837Train Epoch: 6 [552064/702208 (79%)]	Loss: 0.051885Train Epoch: 6 [553088/702208 (79%)]	Loss: 0.034523Train Epoch: 6 [554112/702208 (79%)]	Loss: 0.028975Train Epoch: 6 [555008/702208 (79%)]	Loss: 0.082199Train Epoch: 6 [556032/702208 (79%)]	Loss: 0.031695Train Epoch: 6 [557056/702208 (79%)]	Loss: 0.127744Train Epoch: 6 [558080/702208 (79%)]	Loss: 0.068696Train Epoch: 6 [559104/702208 (80%)]	Loss: 0.109692Train Epoch: 6 [560000/702208 (80%)]	Loss: 0.143690Train Epoch: 6 [560128/702208 (80%)]	Loss: 0.046214Train Epoch: 6 [561024/702208 (80%)]	Loss: 0.064678Train Epoch: 6 [562048/702208 (80%)]	Loss: 0.048707Train Epoch: 6 [563072/702208 (80%)]	Loss: 0.071358Train Epoch: 6 [564096/702208 (80%)]	Loss: 0.073749Train Epoch: 6 [565120/702208 (80%)]	Loss: 0.043430Train Epoch: 6 [566016/702208 (81%)]	Loss: 0.054585Train Epoch: 6 [567040/702208 (81%)]	Loss: 0.043205Train Epoch: 6 [568064/702208 (81%)]	Loss: 0.091228Train Epoch: 6 [569088/702208 (81%)]	Loss: 0.038183Train Epoch: 6 [570112/702208 (81%)]	Loss: 0.038339Train Epoch: 6 [571008/702208 (81%)]	Loss: 0.032351Train Epoch: 6 [572032/702208 (81%)]	Loss: 0.060315Train Epoch: 6 [573056/702208 (82%)]	Loss: 0.036747Train Epoch: 6 [574080/702208 (82%)]	Loss: 0.029479Train Epoch: 6 [575104/702208 (82%)]	Loss: 0.017455
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8021 / 8283] 96 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-4086144-total-97.91-class0-96.84-class1-99.87
Train Epoch: 6 [576000/702208 (82%)]	Loss: 0.018830Train Epoch: 6 [576128/702208 (82%)]	Loss: 0.039488Train Epoch: 6 [577024/702208 (82%)]	Loss: 0.076740Train Epoch: 6 [578048/702208 (82%)]	Loss: 0.115778Train Epoch: 6 [579072/702208 (82%)]	Loss: 0.056896Train Epoch: 6 [580096/702208 (83%)]	Loss: 0.055509Train Epoch: 6 [581120/702208 (83%)]	Loss: 0.062584Train Epoch: 6 [582016/702208 (83%)]	Loss: 0.034850Train Epoch: 6 [583040/702208 (83%)]	Loss: 0.033916Train Epoch: 6 [584064/702208 (83%)]	Loss: 0.038081Train Epoch: 6 [585088/702208 (83%)]	Loss: 0.020567Train Epoch: 6 [586112/702208 (83%)]	Loss: 0.035989Train Epoch: 6 [587008/702208 (84%)]	Loss: 0.019297Train Epoch: 6 [588032/702208 (84%)]	Loss: 0.036583Train Epoch: 6 [589056/702208 (84%)]	Loss: 0.075234Train Epoch: 6 [590080/702208 (84%)]	Loss: 0.079721Train Epoch: 6 [591104/702208 (84%)]	Loss: 0.039038Train Epoch: 6 [592000/702208 (84%)]	Loss: 0.104070Train Epoch: 6 [592128/702208 (84%)]	Loss: 0.107112Train Epoch: 6 [593024/702208 (84%)]	Loss: 0.057253Train Epoch: 6 [594048/702208 (85%)]	Loss: 0.044811Train Epoch: 6 [595072/702208 (85%)]	Loss: 0.040723Train Epoch: 6 [596096/702208 (85%)]	Loss: 0.043919Train Epoch: 6 [597120/702208 (85%)]	Loss: 0.048189Train Epoch: 6 [598016/702208 (85%)]	Loss: 0.027781Train Epoch: 6 [599040/702208 (85%)]	Loss: 0.081983Train Epoch: 6 [600064/702208 (85%)]	Loss: 0.045043
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8047 / 8283] 97 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-4111104-total-98.06-class0-97.15-class1-99.72999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12328 / 12833] 96 %
Accuracy of the network on train loader class  1: [7090 / 7135] 99 %
Train Epoch: 6 [601088/702208 (86%)]	Loss: 0.113419Train Epoch: 6 [602112/702208 (86%)]	Loss: 0.042120Train Epoch: 6 [603008/702208 (86%)]	Loss: 0.057690Train Epoch: 6 [604032/702208 (86%)]	Loss: 0.092910Train Epoch: 6 [605056/702208 (86%)]	Loss: 0.063095Train Epoch: 6 [606080/702208 (86%)]	Loss: 0.064689Train Epoch: 6 [607104/702208 (86%)]	Loss: 0.144640Train Epoch: 6 [608000/702208 (87%)]	Loss: 0.025609Train Epoch: 6 [608128/702208 (87%)]	Loss: 0.028334Train Epoch: 6 [609024/702208 (87%)]	Loss: 0.053632Train Epoch: 6 [610048/702208 (87%)]	Loss: 0.058540Train Epoch: 6 [611072/702208 (87%)]	Loss: 0.024550Train Epoch: 6 [612096/702208 (87%)]	Loss: 0.076014Train Epoch: 6 [613120/702208 (87%)]	Loss: 0.048819Train Epoch: 6 [614016/702208 (87%)]	Loss: 0.013464Train Epoch: 6 [615040/702208 (88%)]	Loss: 0.038269Train Epoch: 6 [616064/702208 (88%)]	Loss: 0.023361Train Epoch: 6 [617088/702208 (88%)]	Loss: 0.054847Train Epoch: 6 [618112/702208 (88%)]	Loss: 0.042718Train Epoch: 6 [619008/702208 (88%)]	Loss: 0.016062Train Epoch: 6 [620032/702208 (88%)]	Loss: 0.069571Train Epoch: 6 [621056/702208 (88%)]	Loss: 0.037487Train Epoch: 6 [622080/702208 (89%)]	Loss: 0.039059Train Epoch: 6 [623104/702208 (89%)]	Loss: 0.034579Train Epoch: 6 [624000/702208 (89%)]	Loss: 0.091278Train Epoch: 6 [624128/702208 (89%)]	Loss: 0.060880Train Epoch: 6 [625024/702208 (89%)]	Loss: 0.051636
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8052 / 8283] 97 %
Accuracy of the network on test loader class  1: [4500 / 4517] 99 %

Writing model: iterations-4136064-total-98.06-class0-97.21-class1-99.62
Train Epoch: 6 [626048/702208 (89%)]	Loss: 0.041510Train Epoch: 6 [627072/702208 (89%)]	Loss: 0.204309Train Epoch: 6 [628096/702208 (89%)]	Loss: 0.031772Train Epoch: 6 [629120/702208 (90%)]	Loss: 0.049771Train Epoch: 6 [630016/702208 (90%)]	Loss: 0.078936Train Epoch: 6 [631040/702208 (90%)]	Loss: 0.028395Train Epoch: 6 [632064/702208 (90%)]	Loss: 0.027213Train Epoch: 6 [633088/702208 (90%)]	Loss: 0.034664Train Epoch: 6 [634112/702208 (90%)]	Loss: 0.091803Train Epoch: 6 [635008/702208 (90%)]	Loss: 0.090267Train Epoch: 6 [636032/702208 (91%)]	Loss: 0.043557Train Epoch: 6 [637056/702208 (91%)]	Loss: 0.027794Train Epoch: 6 [638080/702208 (91%)]	Loss: 0.018757Train Epoch: 6 [639104/702208 (91%)]	Loss: 0.084098Train Epoch: 6 [640000/702208 (91%)]	Loss: 0.021420Train Epoch: 6 [640128/702208 (91%)]	Loss: 0.041683Train Epoch: 6 [641024/702208 (91%)]	Loss: 0.030624Train Epoch: 6 [642048/702208 (91%)]	Loss: 0.114256Train Epoch: 6 [643072/702208 (92%)]	Loss: 0.058746Train Epoch: 6 [644096/702208 (92%)]	Loss: 0.058614Train Epoch: 6 [645120/702208 (92%)]	Loss: 0.054650Train Epoch: 6 [646016/702208 (92%)]	Loss: 0.052681Train Epoch: 6 [647040/702208 (92%)]	Loss: 0.075323Train Epoch: 6 [648064/702208 (92%)]	Loss: 0.071204Train Epoch: 6 [649088/702208 (92%)]	Loss: 0.052515Train Epoch: 6 [650112/702208 (93%)]	Loss: 0.046753
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8079 / 8283] 97 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-4161152-total-98.3-class0-97.54-class1-99.71

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12345 / 12833] 96 %
Accuracy of the network on train loader class  1: [7084 / 7135] 99 %
Train Epoch: 6 [651008/702208 (93%)]	Loss: 0.088416Train Epoch: 6 [652032/702208 (93%)]	Loss: 0.025986Train Epoch: 6 [653056/702208 (93%)]	Loss: 0.081879Train Epoch: 6 [654080/702208 (93%)]	Loss: 0.021436Train Epoch: 6 [655104/702208 (93%)]	Loss: 0.122941Train Epoch: 6 [656000/702208 (93%)]	Loss: 0.050651Train Epoch: 6 [656128/702208 (93%)]	Loss: 0.080405Train Epoch: 6 [657024/702208 (94%)]	Loss: 0.023344Train Epoch: 6 [658048/702208 (94%)]	Loss: 0.084442Train Epoch: 6 [659072/702208 (94%)]	Loss: 0.035075Train Epoch: 6 [660096/702208 (94%)]	Loss: 0.026126Train Epoch: 6 [661120/702208 (94%)]	Loss: 0.037005Train Epoch: 6 [662016/702208 (94%)]	Loss: 0.038019Train Epoch: 6 [663040/702208 (94%)]	Loss: 0.063753Train Epoch: 6 [664064/702208 (95%)]	Loss: 0.038490Train Epoch: 6 [665088/702208 (95%)]	Loss: 0.145544Train Epoch: 6 [666112/702208 (95%)]	Loss: 0.129457Train Epoch: 6 [667008/702208 (95%)]	Loss: 0.050372Train Epoch: 6 [668032/702208 (95%)]	Loss: 0.063705Train Epoch: 6 [669056/702208 (95%)]	Loss: 0.045391Train Epoch: 6 [670080/702208 (95%)]	Loss: 0.026074Train Epoch: 6 [671104/702208 (96%)]	Loss: 0.034185Train Epoch: 6 [672000/702208 (96%)]	Loss: 0.041829Train Epoch: 6 [672128/702208 (96%)]	Loss: 0.039397Train Epoch: 6 [673024/702208 (96%)]	Loss: 0.040143Train Epoch: 6 [674048/702208 (96%)]	Loss: 0.062776Train Epoch: 6 [675072/702208 (96%)]	Loss: 0.036107
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8100 / 8283] 97 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-4186112-total-98.50999999999999-class0-97.78999999999999-class1-99.82
Train Epoch: 6 [676096/702208 (96%)]	Loss: 0.036066Train Epoch: 6 [677120/702208 (96%)]	Loss: 0.033429Train Epoch: 6 [678016/702208 (97%)]	Loss: 0.027824Train Epoch: 6 [679040/702208 (97%)]	Loss: 0.025022Train Epoch: 6 [680064/702208 (97%)]	Loss: 0.026681Train Epoch: 6 [681088/702208 (97%)]	Loss: 0.098295Train Epoch: 6 [682112/702208 (97%)]	Loss: 0.107820Train Epoch: 6 [683008/702208 (97%)]	Loss: 0.043043Train Epoch: 6 [684032/702208 (97%)]	Loss: 0.036835Train Epoch: 6 [685056/702208 (98%)]	Loss: 0.035682Train Epoch: 6 [686080/702208 (98%)]	Loss: 0.098026Train Epoch: 6 [687104/702208 (98%)]	Loss: 0.044816Train Epoch: 6 [688000/702208 (98%)]	Loss: 0.064586Train Epoch: 6 [688128/702208 (98%)]	Loss: 0.055757Train Epoch: 6 [689024/702208 (98%)]	Loss: 0.021053Train Epoch: 6 [690048/702208 (98%)]	Loss: 0.088083Train Epoch: 6 [691072/702208 (98%)]	Loss: 0.051689Train Epoch: 6 [692096/702208 (99%)]	Loss: 0.030349Train Epoch: 6 [693120/702208 (99%)]	Loss: 0.135108Train Epoch: 6 [694016/702208 (99%)]	Loss: 0.061787Train Epoch: 6 [695040/702208 (99%)]	Loss: 0.086193Train Epoch: 6 [696064/702208 (99%)]	Loss: 0.091066Train Epoch: 6 [697088/702208 (99%)]	Loss: 0.069415Train Epoch: 6 [698112/702208 (99%)]	Loss: 0.043971Train Epoch: 6 [699008/702208 (100%)]	Loss: 0.055618Train Epoch: 6 [700032/702208 (100%)]	Loss: 0.097470
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8102 / 8283] 97 %
Accuracy of the network on test loader class  1: [4498 / 4517] 99 %

Writing model: iterations-4211072-total-98.44000000000001-class0-97.81-class1-99.58

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12400 / 12833] 96 %
Accuracy of the network on train loader class  1: [7091 / 7135] 99 %
Train Epoch: 6 [701056/702208 (100%)]	Loss: 0.070534Train Epoch: 6 [702080/702208 (100%)]	Loss: 0.126526
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8118 / 8283] 98 %
Accuracy of the network on test loader class  1: [4497 / 4517] 99 %
Train Epoch: 7 [1024/702208 (0%)]	Loss: 0.028644Train Epoch: 7 [2048/702208 (0%)]	Loss: 0.026676Train Epoch: 7 [3072/702208 (0%)]	Loss: 0.113151Train Epoch: 7 [4096/702208 (1%)]	Loss: 0.055608Train Epoch: 7 [5120/702208 (1%)]	Loss: 0.044874Train Epoch: 7 [6016/702208 (1%)]	Loss: 0.035965Train Epoch: 7 [7040/702208 (1%)]	Loss: 0.041554Train Epoch: 7 [8064/702208 (1%)]	Loss: 0.105142Train Epoch: 7 [9088/702208 (1%)]	Loss: 0.053985Train Epoch: 7 [10112/702208 (1%)]	Loss: 0.034521Train Epoch: 7 [11008/702208 (2%)]	Loss: 0.029136Train Epoch: 7 [12032/702208 (2%)]	Loss: 0.022844Train Epoch: 7 [13056/702208 (2%)]	Loss: 0.150754Train Epoch: 7 [14080/702208 (2%)]	Loss: 0.023093Train Epoch: 7 [15104/702208 (2%)]	Loss: 0.047119Train Epoch: 7 [16000/702208 (2%)]	Loss: 0.063454Train Epoch: 7 [16128/702208 (2%)]	Loss: 0.074951Train Epoch: 7 [17024/702208 (2%)]	Loss: 0.074531Train Epoch: 7 [18048/702208 (3%)]	Loss: 0.035274Train Epoch: 7 [19072/702208 (3%)]	Loss: 0.036195Train Epoch: 7 [20096/702208 (3%)]	Loss: 0.041583Train Epoch: 7 [21120/702208 (3%)]	Loss: 0.039939Train Epoch: 7 [22016/702208 (3%)]	Loss: 0.056826Train Epoch: 7 [23040/702208 (3%)]	Loss: 0.013030Train Epoch: 7 [24064/702208 (3%)]	Loss: 0.016148Train Epoch: 7 [25088/702208 (4%)]	Loss: 0.062404
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8086 / 8283] 97 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-4238336-total-98.35000000000001-class0-97.61999999999999-class1-99.69
Train Epoch: 7 [26112/702208 (4%)]	Loss: 0.109541Train Epoch: 7 [27008/702208 (4%)]	Loss: 0.057032Train Epoch: 7 [28032/702208 (4%)]	Loss: 0.009300Train Epoch: 7 [29056/702208 (4%)]	Loss: 0.068148Train Epoch: 7 [30080/702208 (4%)]	Loss: 0.016018Train Epoch: 7 [31104/702208 (4%)]	Loss: 0.067626Train Epoch: 7 [32000/702208 (5%)]	Loss: 0.041745Train Epoch: 7 [32128/702208 (5%)]	Loss: 0.041119Train Epoch: 7 [33024/702208 (5%)]	Loss: 0.049374Train Epoch: 7 [34048/702208 (5%)]	Loss: 0.156463Train Epoch: 7 [35072/702208 (5%)]	Loss: 0.079063Train Epoch: 7 [36096/702208 (5%)]	Loss: 0.086660Train Epoch: 7 [37120/702208 (5%)]	Loss: 0.126644Train Epoch: 7 [38016/702208 (5%)]	Loss: 0.054232Train Epoch: 7 [39040/702208 (6%)]	Loss: 0.104503Train Epoch: 7 [40064/702208 (6%)]	Loss: 0.056741Train Epoch: 7 [41088/702208 (6%)]	Loss: 0.068961Train Epoch: 7 [42112/702208 (6%)]	Loss: 0.022303Train Epoch: 7 [43008/702208 (6%)]	Loss: 0.050938Train Epoch: 7 [44032/702208 (6%)]	Loss: 0.180130Train Epoch: 7 [45056/702208 (6%)]	Loss: 0.095662Train Epoch: 7 [46080/702208 (7%)]	Loss: 0.037234Train Epoch: 7 [47104/702208 (7%)]	Loss: 0.039113Train Epoch: 7 [48000/702208 (7%)]	Loss: 0.124677Train Epoch: 7 [48128/702208 (7%)]	Loss: 0.049321Train Epoch: 7 [49024/702208 (7%)]	Loss: 0.033674Train Epoch: 7 [50048/702208 (7%)]	Loss: 0.025100
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8036 / 8283] 97 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-4263296-total-98.02-class0-97.02-class1-99.87

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12387 / 12833] 96 %
Accuracy of the network on train loader class  1: [7070 / 7135] 99 %
Train Epoch: 7 [51072/702208 (7%)]	Loss: 0.026944Train Epoch: 7 [52096/702208 (7%)]	Loss: 0.044368Train Epoch: 7 [53120/702208 (8%)]	Loss: 0.123851Train Epoch: 7 [54016/702208 (8%)]	Loss: 0.045993Train Epoch: 7 [55040/702208 (8%)]	Loss: 0.035125Train Epoch: 7 [56064/702208 (8%)]	Loss: 0.155389Train Epoch: 7 [57088/702208 (8%)]	Loss: 0.049425Train Epoch: 7 [58112/702208 (8%)]	Loss: 0.039821Train Epoch: 7 [59008/702208 (8%)]	Loss: 0.054162Train Epoch: 7 [60032/702208 (9%)]	Loss: 0.051399Train Epoch: 7 [61056/702208 (9%)]	Loss: 0.019690Train Epoch: 7 [62080/702208 (9%)]	Loss: 0.024367Train Epoch: 7 [63104/702208 (9%)]	Loss: 0.045217Train Epoch: 7 [64000/702208 (9%)]	Loss: 0.048480Train Epoch: 7 [64128/702208 (9%)]	Loss: 0.123811Train Epoch: 7 [65024/702208 (9%)]	Loss: 0.062831Train Epoch: 7 [66048/702208 (9%)]	Loss: 0.047049Train Epoch: 7 [67072/702208 (10%)]	Loss: 0.057919Train Epoch: 7 [68096/702208 (10%)]	Loss: 0.063174Train Epoch: 7 [69120/702208 (10%)]	Loss: 0.047959Train Epoch: 7 [70016/702208 (10%)]	Loss: 0.041715Train Epoch: 7 [71040/702208 (10%)]	Loss: 0.025533Train Epoch: 7 [72064/702208 (10%)]	Loss: 0.036973Train Epoch: 7 [73088/702208 (10%)]	Loss: 0.063837Train Epoch: 7 [74112/702208 (11%)]	Loss: 0.038610Train Epoch: 7 [75008/702208 (11%)]	Loss: 0.023875
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8087 / 8283] 97 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-4288256-total-98.4-class0-97.63-class1-99.8
Train Epoch: 7 [76032/702208 (11%)]	Loss: 0.114649Train Epoch: 7 [77056/702208 (11%)]	Loss: 0.078540Train Epoch: 7 [78080/702208 (11%)]	Loss: 0.067603Train Epoch: 7 [79104/702208 (11%)]	Loss: 0.066798Train Epoch: 7 [80000/702208 (11%)]	Loss: 0.032805Train Epoch: 7 [80128/702208 (11%)]	Loss: 0.020233Train Epoch: 7 [81024/702208 (12%)]	Loss: 0.068074Train Epoch: 7 [82048/702208 (12%)]	Loss: 0.124624Train Epoch: 7 [83072/702208 (12%)]	Loss: 0.037562Train Epoch: 7 [84096/702208 (12%)]	Loss: 0.143449Train Epoch: 7 [85120/702208 (12%)]	Loss: 0.035115Train Epoch: 7 [86016/702208 (12%)]	Loss: 0.095288Train Epoch: 7 [87040/702208 (12%)]	Loss: 0.035945Train Epoch: 7 [88064/702208 (13%)]	Loss: 0.027301Train Epoch: 7 [89088/702208 (13%)]	Loss: 0.063857Train Epoch: 7 [90112/702208 (13%)]	Loss: 0.049137Train Epoch: 7 [91008/702208 (13%)]	Loss: 0.082750Train Epoch: 7 [92032/702208 (13%)]	Loss: 0.027311Train Epoch: 7 [93056/702208 (13%)]	Loss: 0.056384Train Epoch: 7 [94080/702208 (13%)]	Loss: 0.128608Train Epoch: 7 [95104/702208 (14%)]	Loss: 0.034232Train Epoch: 7 [96000/702208 (14%)]	Loss: 0.051103Train Epoch: 7 [96128/702208 (14%)]	Loss: 0.040101Train Epoch: 7 [97024/702208 (14%)]	Loss: 0.098809Train Epoch: 7 [98048/702208 (14%)]	Loss: 0.058036Train Epoch: 7 [99072/702208 (14%)]	Loss: 0.020910Train Epoch: 7 [100096/702208 (14%)]	Loss: 0.041999
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8039 / 8283] 97 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-4313344-total-98.00999999999999-class0-97.05-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12361 / 12833] 96 %
Accuracy of the network on train loader class  1: [7084 / 7135] 99 %
Train Epoch: 7 [101120/702208 (14%)]	Loss: 0.058171Train Epoch: 7 [102016/702208 (15%)]	Loss: 0.136822Train Epoch: 7 [103040/702208 (15%)]	Loss: 0.032670Train Epoch: 7 [104064/702208 (15%)]	Loss: 0.047479Train Epoch: 7 [105088/702208 (15%)]	Loss: 0.092299Train Epoch: 7 [106112/702208 (15%)]	Loss: 0.094217Train Epoch: 7 [107008/702208 (15%)]	Loss: 0.050331Train Epoch: 7 [108032/702208 (15%)]	Loss: 0.034306Train Epoch: 7 [109056/702208 (16%)]	Loss: 0.034574Train Epoch: 7 [110080/702208 (16%)]	Loss: 0.146125Train Epoch: 7 [111104/702208 (16%)]	Loss: 0.067020Train Epoch: 7 [112000/702208 (16%)]	Loss: 0.033701Train Epoch: 7 [112128/702208 (16%)]	Loss: 0.058175Train Epoch: 7 [113024/702208 (16%)]	Loss: 0.024219Train Epoch: 7 [114048/702208 (16%)]	Loss: 0.042945Train Epoch: 7 [115072/702208 (16%)]	Loss: 0.046881Train Epoch: 7 [116096/702208 (17%)]	Loss: 0.051809Train Epoch: 7 [117120/702208 (17%)]	Loss: 0.039260Train Epoch: 7 [118016/702208 (17%)]	Loss: 0.082574Train Epoch: 7 [119040/702208 (17%)]	Loss: 0.033504Train Epoch: 7 [120064/702208 (17%)]	Loss: 0.070611Train Epoch: 7 [121088/702208 (17%)]	Loss: 0.048110Train Epoch: 7 [122112/702208 (17%)]	Loss: 0.031836Train Epoch: 7 [123008/702208 (18%)]	Loss: 0.018028Train Epoch: 7 [124032/702208 (18%)]	Loss: 0.036362Train Epoch: 7 [125056/702208 (18%)]	Loss: 0.094704
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8064 / 8283] 97 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-4338304-total-98.24000000000001-class0-97.36-class1-99.87
Train Epoch: 7 [126080/702208 (18%)]	Loss: 0.017946Train Epoch: 7 [127104/702208 (18%)]	Loss: 0.050535Train Epoch: 7 [128000/702208 (18%)]	Loss: 0.058388Train Epoch: 7 [128128/702208 (18%)]	Loss: 0.140137Train Epoch: 7 [129024/702208 (18%)]	Loss: 0.067266Train Epoch: 7 [130048/702208 (19%)]	Loss: 0.019090Train Epoch: 7 [131072/702208 (19%)]	Loss: 0.116452Train Epoch: 7 [132096/702208 (19%)]	Loss: 0.045293Train Epoch: 7 [133120/702208 (19%)]	Loss: 0.033161Train Epoch: 7 [134016/702208 (19%)]	Loss: 0.017460Train Epoch: 7 [135040/702208 (19%)]	Loss: 0.046919Train Epoch: 7 [136064/702208 (19%)]	Loss: 0.037193Train Epoch: 7 [137088/702208 (20%)]	Loss: 0.020714Train Epoch: 7 [138112/702208 (20%)]	Loss: 0.115510Train Epoch: 7 [139008/702208 (20%)]	Loss: 0.095042Train Epoch: 7 [140032/702208 (20%)]	Loss: 0.055282Train Epoch: 7 [141056/702208 (20%)]	Loss: 0.062665Train Epoch: 7 [142080/702208 (20%)]	Loss: 0.025066Train Epoch: 7 [143104/702208 (20%)]	Loss: 0.044867Train Epoch: 7 [144000/702208 (21%)]	Loss: 0.097863Train Epoch: 7 [144128/702208 (21%)]	Loss: 0.051150Train Epoch: 7 [145024/702208 (21%)]	Loss: 0.055827Train Epoch: 7 [146048/702208 (21%)]	Loss: 0.034836Train Epoch: 7 [147072/702208 (21%)]	Loss: 0.018089Train Epoch: 7 [148096/702208 (21%)]	Loss: 0.170966Train Epoch: 7 [149120/702208 (21%)]	Loss: 0.078288Train Epoch: 7 [150016/702208 (21%)]	Loss: 0.039280
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8104 / 8283] 97 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %

Writing model: iterations-4363264-total-98.48-class0-97.84-class1-99.67

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12290 / 12833] 95 %
Accuracy of the network on train loader class  1: [7057 / 7135] 98 %
Train Epoch: 7 [151040/702208 (22%)]	Loss: 0.035844Train Epoch: 7 [152064/702208 (22%)]	Loss: 0.131170Train Epoch: 7 [153088/702208 (22%)]	Loss: 0.048770Train Epoch: 7 [154112/702208 (22%)]	Loss: 0.104945Train Epoch: 7 [155008/702208 (22%)]	Loss: 0.174175Train Epoch: 7 [156032/702208 (22%)]	Loss: 0.067980Train Epoch: 7 [157056/702208 (22%)]	Loss: 0.080945Train Epoch: 7 [158080/702208 (23%)]	Loss: 0.048897Train Epoch: 7 [159104/702208 (23%)]	Loss: 0.165358Train Epoch: 7 [160000/702208 (23%)]	Loss: 0.046682Train Epoch: 7 [160128/702208 (23%)]	Loss: 0.019886Train Epoch: 7 [161024/702208 (23%)]	Loss: 0.103003Train Epoch: 7 [162048/702208 (23%)]	Loss: 0.030817Train Epoch: 7 [163072/702208 (23%)]	Loss: 0.070714Train Epoch: 7 [164096/702208 (23%)]	Loss: 0.042015Train Epoch: 7 [165120/702208 (24%)]	Loss: 0.113784Train Epoch: 7 [166016/702208 (24%)]	Loss: 0.025369Train Epoch: 7 [167040/702208 (24%)]	Loss: 0.104721Train Epoch: 7 [168064/702208 (24%)]	Loss: 0.010114Train Epoch: 7 [169088/702208 (24%)]	Loss: 0.095985Train Epoch: 7 [170112/702208 (24%)]	Loss: 0.026235Train Epoch: 7 [171008/702208 (24%)]	Loss: 0.026762Train Epoch: 7 [172032/702208 (24%)]	Loss: 0.046350Train Epoch: 7 [173056/702208 (25%)]	Loss: 0.043286Train Epoch: 7 [174080/702208 (25%)]	Loss: 0.050009Train Epoch: 7 [175104/702208 (25%)]	Loss: 0.038791
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8066 / 8283] 97 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-4388352-total-98.22999999999999-class0-97.38-class1-99.78
Train Epoch: 7 [176000/702208 (25%)]	Loss: 0.094320Train Epoch: 7 [176128/702208 (25%)]	Loss: 0.039534Train Epoch: 7 [177024/702208 (25%)]	Loss: 0.030564Train Epoch: 7 [178048/702208 (25%)]	Loss: 0.049771Train Epoch: 7 [179072/702208 (26%)]	Loss: 0.054485Train Epoch: 7 [180096/702208 (26%)]	Loss: 0.021608Train Epoch: 7 [181120/702208 (26%)]	Loss: 0.078273Train Epoch: 7 [182016/702208 (26%)]	Loss: 0.047933Train Epoch: 7 [183040/702208 (26%)]	Loss: 0.023599Train Epoch: 7 [184064/702208 (26%)]	Loss: 0.068206Train Epoch: 7 [185088/702208 (26%)]	Loss: 0.022952Train Epoch: 7 [186112/702208 (27%)]	Loss: 0.045548Train Epoch: 7 [187008/702208 (27%)]	Loss: 0.057089Train Epoch: 7 [188032/702208 (27%)]	Loss: 0.019745Train Epoch: 7 [189056/702208 (27%)]	Loss: 0.073163Train Epoch: 7 [190080/702208 (27%)]	Loss: 0.028493Train Epoch: 7 [191104/702208 (27%)]	Loss: 0.048995Train Epoch: 7 [192000/702208 (27%)]	Loss: 0.064581Train Epoch: 7 [192128/702208 (27%)]	Loss: 0.022678Train Epoch: 7 [193024/702208 (27%)]	Loss: 0.072011Train Epoch: 7 [194048/702208 (28%)]	Loss: 0.081377Train Epoch: 7 [195072/702208 (28%)]	Loss: 0.057241Train Epoch: 7 [196096/702208 (28%)]	Loss: 0.051324Train Epoch: 7 [197120/702208 (28%)]	Loss: 0.037695Train Epoch: 7 [198016/702208 (28%)]	Loss: 0.038842Train Epoch: 7 [199040/702208 (28%)]	Loss: 0.151269Train Epoch: 7 [200064/702208 (28%)]	Loss: 0.078043
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 76 %
Accuracy of the network on test loader class  0: [5228 / 8283] 63 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-4413312-total-76.08-class0-63.12-class1-99.85000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 78 %
Accuracy of the network on train loader class  0: [8660 / 12833] 67 %
Accuracy of the network on train loader class  1: [6937 / 7135] 97 %
Train Epoch: 7 [201088/702208 (29%)]	Loss: 0.066016Train Epoch: 7 [202112/702208 (29%)]	Loss: 0.027062Train Epoch: 7 [203008/702208 (29%)]	Loss: 0.055660Train Epoch: 7 [204032/702208 (29%)]	Loss: 0.032135Train Epoch: 7 [205056/702208 (29%)]	Loss: 0.099217Train Epoch: 7 [206080/702208 (29%)]	Loss: 0.041994Train Epoch: 7 [207104/702208 (29%)]	Loss: 0.067558Train Epoch: 7 [208000/702208 (30%)]	Loss: 0.102156Train Epoch: 7 [208128/702208 (30%)]	Loss: 0.024952Train Epoch: 7 [209024/702208 (30%)]	Loss: 0.064420Train Epoch: 7 [210048/702208 (30%)]	Loss: 0.070389Train Epoch: 7 [211072/702208 (30%)]	Loss: 0.149133Train Epoch: 7 [212096/702208 (30%)]	Loss: 0.035169Train Epoch: 7 [213120/702208 (30%)]	Loss: 0.026108Train Epoch: 7 [214016/702208 (30%)]	Loss: 0.073258Train Epoch: 7 [215040/702208 (31%)]	Loss: 0.051786Train Epoch: 7 [216064/702208 (31%)]	Loss: 0.054296Train Epoch: 7 [217088/702208 (31%)]	Loss: 0.087606Train Epoch: 7 [218112/702208 (31%)]	Loss: 0.077062Train Epoch: 7 [219008/702208 (31%)]	Loss: 0.042741Train Epoch: 7 [220032/702208 (31%)]	Loss: 0.060217Train Epoch: 7 [221056/702208 (31%)]	Loss: 0.071474Train Epoch: 7 [222080/702208 (32%)]	Loss: 0.045992Train Epoch: 7 [223104/702208 (32%)]	Loss: 0.058517Train Epoch: 7 [224000/702208 (32%)]	Loss: 0.111480Train Epoch: 7 [224128/702208 (32%)]	Loss: 0.046988Train Epoch: 7 [225024/702208 (32%)]	Loss: 0.121340
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8091 / 8283] 97 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-4438272-total-98.45-class0-97.68-class1-99.85000000000001
Train Epoch: 7 [226048/702208 (32%)]	Loss: 0.087418Train Epoch: 7 [227072/702208 (32%)]	Loss: 0.043270Train Epoch: 7 [228096/702208 (32%)]	Loss: 0.052794Train Epoch: 7 [229120/702208 (33%)]	Loss: 0.044947Train Epoch: 7 [230016/702208 (33%)]	Loss: 0.023420Train Epoch: 7 [231040/702208 (33%)]	Loss: 0.034769Train Epoch: 7 [232064/702208 (33%)]	Loss: 0.063612Train Epoch: 7 [233088/702208 (33%)]	Loss: 0.028668Train Epoch: 7 [234112/702208 (33%)]	Loss: 0.098751Train Epoch: 7 [235008/702208 (33%)]	Loss: 0.059412Train Epoch: 7 [236032/702208 (34%)]	Loss: 0.041785Train Epoch: 7 [237056/702208 (34%)]	Loss: 0.029136Train Epoch: 7 [238080/702208 (34%)]	Loss: 0.059784Train Epoch: 7 [239104/702208 (34%)]	Loss: 0.018376Train Epoch: 7 [240000/702208 (34%)]	Loss: 0.010596Train Epoch: 7 [240128/702208 (34%)]	Loss: 0.066376Train Epoch: 7 [241024/702208 (34%)]	Loss: 0.053350Train Epoch: 7 [242048/702208 (34%)]	Loss: 0.067261Train Epoch: 7 [243072/702208 (35%)]	Loss: 0.023195Train Epoch: 7 [244096/702208 (35%)]	Loss: 0.036811Train Epoch: 7 [245120/702208 (35%)]	Loss: 0.135302Train Epoch: 7 [246016/702208 (35%)]	Loss: 0.073262Train Epoch: 7 [247040/702208 (35%)]	Loss: 0.057130Train Epoch: 7 [248064/702208 (35%)]	Loss: 0.051509Train Epoch: 7 [249088/702208 (35%)]	Loss: 0.035562Train Epoch: 7 [250112/702208 (36%)]	Loss: 0.037300
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8126 / 8283] 98 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-4463360-total-98.67-class0-98.1-class1-99.71

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12353 / 12833] 96 %
Accuracy of the network on train loader class  1: [7096 / 7135] 99 %
Train Epoch: 7 [251008/702208 (36%)]	Loss: 0.085217Train Epoch: 7 [252032/702208 (36%)]	Loss: 0.115392Train Epoch: 7 [253056/702208 (36%)]	Loss: 0.026511Train Epoch: 7 [254080/702208 (36%)]	Loss: 0.065094Train Epoch: 7 [255104/702208 (36%)]	Loss: 0.088083Train Epoch: 7 [256000/702208 (36%)]	Loss: 0.024033Train Epoch: 7 [256128/702208 (36%)]	Loss: 0.060719Train Epoch: 7 [257024/702208 (37%)]	Loss: 0.054862Train Epoch: 7 [258048/702208 (37%)]	Loss: 0.029006Train Epoch: 7 [259072/702208 (37%)]	Loss: 0.072516Train Epoch: 7 [260096/702208 (37%)]	Loss: 0.036677Train Epoch: 7 [261120/702208 (37%)]	Loss: 0.016515Train Epoch: 7 [262016/702208 (37%)]	Loss: 0.049349Train Epoch: 7 [263040/702208 (37%)]	Loss: 0.093483Train Epoch: 7 [264064/702208 (38%)]	Loss: 0.095959Train Epoch: 7 [265088/702208 (38%)]	Loss: 0.039616Train Epoch: 7 [266112/702208 (38%)]	Loss: 0.067699Train Epoch: 7 [267008/702208 (38%)]	Loss: 0.035315Train Epoch: 7 [268032/702208 (38%)]	Loss: 0.043833Train Epoch: 7 [269056/702208 (38%)]	Loss: 0.030138Train Epoch: 7 [270080/702208 (38%)]	Loss: 0.102290Train Epoch: 7 [271104/702208 (39%)]	Loss: 0.038818Train Epoch: 7 [272000/702208 (39%)]	Loss: 0.014813Train Epoch: 7 [272128/702208 (39%)]	Loss: 0.018934Train Epoch: 7 [273024/702208 (39%)]	Loss: 0.025618Train Epoch: 7 [274048/702208 (39%)]	Loss: 0.016051Train Epoch: 7 [275072/702208 (39%)]	Loss: 0.062220
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8079 / 8283] 97 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-4488320-total-98.33-class0-97.54-class1-99.78
Train Epoch: 7 [276096/702208 (39%)]	Loss: 0.027556Train Epoch: 7 [277120/702208 (39%)]	Loss: 0.015125Train Epoch: 7 [278016/702208 (40%)]	Loss: 0.021096Train Epoch: 7 [279040/702208 (40%)]	Loss: 0.160586Train Epoch: 7 [280064/702208 (40%)]	Loss: 0.042666Train Epoch: 7 [281088/702208 (40%)]	Loss: 0.052500Train Epoch: 7 [282112/702208 (40%)]	Loss: 0.103358Train Epoch: 7 [283008/702208 (40%)]	Loss: 0.083059Train Epoch: 7 [284032/702208 (40%)]	Loss: 0.044368Train Epoch: 7 [285056/702208 (41%)]	Loss: 0.046017Train Epoch: 7 [286080/702208 (41%)]	Loss: 0.144188Train Epoch: 7 [287104/702208 (41%)]	Loss: 0.033845Train Epoch: 7 [288000/702208 (41%)]	Loss: 0.056476Train Epoch: 7 [288128/702208 (41%)]	Loss: 0.029181Train Epoch: 7 [289024/702208 (41%)]	Loss: 0.053796Train Epoch: 7 [290048/702208 (41%)]	Loss: 0.098317Train Epoch: 7 [291072/702208 (41%)]	Loss: 0.060230Train Epoch: 7 [292096/702208 (42%)]	Loss: 0.047639Train Epoch: 7 [293120/702208 (42%)]	Loss: 0.071421Train Epoch: 7 [294016/702208 (42%)]	Loss: 0.025826Train Epoch: 7 [295040/702208 (42%)]	Loss: 0.041504Train Epoch: 7 [296064/702208 (42%)]	Loss: 0.071552Train Epoch: 7 [297088/702208 (42%)]	Loss: 0.089783Train Epoch: 7 [298112/702208 (42%)]	Loss: 0.015632Train Epoch: 7 [299008/702208 (43%)]	Loss: 0.073523Train Epoch: 7 [300032/702208 (43%)]	Loss: 0.030315
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7979 / 8283] 96 %
Accuracy of the network on test loader class  1: [4516 / 4517] 99 %

Writing model: iterations-4513280-total-97.61999999999999-class0-96.33-class1-99.98

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12312 / 12833] 95 %
Accuracy of the network on train loader class  1: [7088 / 7135] 99 %
Train Epoch: 7 [301056/702208 (43%)]	Loss: 0.033394Train Epoch: 7 [302080/702208 (43%)]	Loss: 0.014583Train Epoch: 7 [303104/702208 (43%)]	Loss: 0.131494Train Epoch: 7 [304000/702208 (43%)]	Loss: 0.029336Train Epoch: 7 [304128/702208 (43%)]	Loss: 0.065736Train Epoch: 7 [305024/702208 (43%)]	Loss: 0.066693Train Epoch: 7 [306048/702208 (44%)]	Loss: 0.053858Train Epoch: 7 [307072/702208 (44%)]	Loss: 0.026293Train Epoch: 7 [308096/702208 (44%)]	Loss: 0.031837Train Epoch: 7 [309120/702208 (44%)]	Loss: 0.075807Train Epoch: 7 [310016/702208 (44%)]	Loss: 0.063617Train Epoch: 7 [311040/702208 (44%)]	Loss: 0.037645Train Epoch: 7 [312064/702208 (44%)]	Loss: 0.147036Train Epoch: 7 [313088/702208 (45%)]	Loss: 0.030400Train Epoch: 7 [314112/702208 (45%)]	Loss: 0.069090Train Epoch: 7 [315008/702208 (45%)]	Loss: 0.074547Train Epoch: 7 [316032/702208 (45%)]	Loss: 0.029103Train Epoch: 7 [317056/702208 (45%)]	Loss: 0.075084Train Epoch: 7 [318080/702208 (45%)]	Loss: 0.154308Train Epoch: 7 [319104/702208 (45%)]	Loss: 0.023934Train Epoch: 7 [320000/702208 (46%)]	Loss: 0.024024Train Epoch: 7 [320128/702208 (46%)]	Loss: 0.055746Train Epoch: 7 [321024/702208 (46%)]	Loss: 0.094471Train Epoch: 7 [322048/702208 (46%)]	Loss: 0.013446Train Epoch: 7 [323072/702208 (46%)]	Loss: 0.023451Train Epoch: 7 [324096/702208 (46%)]	Loss: 0.032439Train Epoch: 7 [325120/702208 (46%)]	Loss: 0.114876
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8032 / 8283] 96 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-4538368-total-97.98-class0-96.97-class1-99.85000000000001
Train Epoch: 7 [326016/702208 (46%)]	Loss: 0.015115Train Epoch: 7 [327040/702208 (47%)]	Loss: 0.137271Train Epoch: 7 [328064/702208 (47%)]	Loss: 0.100656Train Epoch: 7 [329088/702208 (47%)]	Loss: 0.028030Train Epoch: 7 [330112/702208 (47%)]	Loss: 0.050927Train Epoch: 7 [331008/702208 (47%)]	Loss: 0.077174Train Epoch: 7 [332032/702208 (47%)]	Loss: 0.081949Train Epoch: 7 [333056/702208 (47%)]	Loss: 0.024483Train Epoch: 7 [334080/702208 (48%)]	Loss: 0.051045Train Epoch: 7 [335104/702208 (48%)]	Loss: 0.035269Train Epoch: 7 [336000/702208 (48%)]	Loss: 0.070031Train Epoch: 7 [336128/702208 (48%)]	Loss: 0.072292Train Epoch: 7 [337024/702208 (48%)]	Loss: 0.082550Train Epoch: 7 [338048/702208 (48%)]	Loss: 0.065339Train Epoch: 7 [339072/702208 (48%)]	Loss: 0.066763Train Epoch: 7 [340096/702208 (48%)]	Loss: 0.116307Train Epoch: 7 [341120/702208 (49%)]	Loss: 0.065843Train Epoch: 7 [342016/702208 (49%)]	Loss: 0.069057Train Epoch: 7 [343040/702208 (49%)]	Loss: 0.030241Train Epoch: 7 [344064/702208 (49%)]	Loss: 0.020266Train Epoch: 7 [345088/702208 (49%)]	Loss: 0.069167Train Epoch: 7 [346112/702208 (49%)]	Loss: 0.036418Train Epoch: 7 [347008/702208 (49%)]	Loss: 0.033580Train Epoch: 7 [348032/702208 (50%)]	Loss: 0.088700Train Epoch: 7 [349056/702208 (50%)]	Loss: 0.020595Train Epoch: 7 [350080/702208 (50%)]	Loss: 0.056781
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8043 / 8283] 97 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-4563328-total-98.05-class0-97.1-class1-99.8

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12198 / 12833] 95 %
Accuracy of the network on train loader class  1: [7078 / 7135] 99 %
Train Epoch: 7 [351104/702208 (50%)]	Loss: 0.164350Train Epoch: 7 [352000/702208 (50%)]	Loss: 0.041403Train Epoch: 7 [352128/702208 (50%)]	Loss: 0.036994Train Epoch: 7 [353024/702208 (50%)]	Loss: 0.047741Train Epoch: 7 [354048/702208 (50%)]	Loss: 0.051360Train Epoch: 7 [355072/702208 (51%)]	Loss: 0.012887Train Epoch: 7 [356096/702208 (51%)]	Loss: 0.048361Train Epoch: 7 [357120/702208 (51%)]	Loss: 0.062766Train Epoch: 7 [358016/702208 (51%)]	Loss: 0.160585Train Epoch: 7 [359040/702208 (51%)]	Loss: 0.021642Train Epoch: 7 [360064/702208 (51%)]	Loss: 0.023791Train Epoch: 7 [361088/702208 (51%)]	Loss: 0.086935Train Epoch: 7 [362112/702208 (52%)]	Loss: 0.040105Train Epoch: 7 [363008/702208 (52%)]	Loss: 0.033699Train Epoch: 7 [364032/702208 (52%)]	Loss: 0.038986Train Epoch: 7 [365056/702208 (52%)]	Loss: 0.040401Train Epoch: 7 [366080/702208 (52%)]	Loss: 0.071352Train Epoch: 7 [367104/702208 (52%)]	Loss: 0.018085Train Epoch: 7 [368000/702208 (52%)]	Loss: 0.028360Train Epoch: 7 [368128/702208 (52%)]	Loss: 0.043056Train Epoch: 7 [369024/702208 (53%)]	Loss: 0.063349Train Epoch: 7 [370048/702208 (53%)]	Loss: 0.051966Train Epoch: 7 [371072/702208 (53%)]	Loss: 0.020183Train Epoch: 7 [372096/702208 (53%)]	Loss: 0.105562Train Epoch: 7 [373120/702208 (53%)]	Loss: 0.054724Train Epoch: 7 [374016/702208 (53%)]	Loss: 0.029252Train Epoch: 7 [375040/702208 (53%)]	Loss: 0.058353
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8121 / 8283] 98 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-4588288-total-98.61999999999999-class0-98.04-class1-99.69
Train Epoch: 7 [376064/702208 (54%)]	Loss: 0.012348Train Epoch: 7 [377088/702208 (54%)]	Loss: 0.060253Train Epoch: 7 [378112/702208 (54%)]	Loss: 0.084814Train Epoch: 7 [379008/702208 (54%)]	Loss: 0.049752Train Epoch: 7 [380032/702208 (54%)]	Loss: 0.022870Train Epoch: 7 [381056/702208 (54%)]	Loss: 0.110867Train Epoch: 7 [382080/702208 (54%)]	Loss: 0.042205Train Epoch: 7 [383104/702208 (55%)]	Loss: 0.040859Train Epoch: 7 [384000/702208 (55%)]	Loss: 0.086696Train Epoch: 7 [384128/702208 (55%)]	Loss: 0.032174Train Epoch: 7 [385024/702208 (55%)]	Loss: 0.157504Train Epoch: 7 [386048/702208 (55%)]	Loss: 0.083297Train Epoch: 7 [387072/702208 (55%)]	Loss: 0.017932Train Epoch: 7 [388096/702208 (55%)]	Loss: 0.054117Train Epoch: 7 [389120/702208 (55%)]	Loss: 0.143820Train Epoch: 7 [390016/702208 (56%)]	Loss: 0.096011Train Epoch: 7 [391040/702208 (56%)]	Loss: 0.022411Train Epoch: 7 [392064/702208 (56%)]	Loss: 0.053756Train Epoch: 7 [393088/702208 (56%)]	Loss: 0.069745Train Epoch: 7 [394112/702208 (56%)]	Loss: 0.026548Train Epoch: 7 [395008/702208 (56%)]	Loss: 0.071580Train Epoch: 7 [396032/702208 (56%)]	Loss: 0.052180Train Epoch: 7 [397056/702208 (57%)]	Loss: 0.030449Train Epoch: 7 [398080/702208 (57%)]	Loss: 0.052279Train Epoch: 7 [399104/702208 (57%)]	Loss: 0.039793Train Epoch: 7 [400000/702208 (57%)]	Loss: 0.016537
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7977 / 8283] 96 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-4613248-total-97.55-class0-96.31-class1-99.82

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 92 %
Accuracy of the network on train loader class  0: [11562 / 12833] 90 %
Accuracy of the network on train loader class  1: [6973 / 7135] 97 %
Train Epoch: 7 [400128/702208 (57%)]	Loss: 0.065509
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7926 / 8283] 95 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-4613376-total-97.15-class0-95.69-class1-99.82

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 92 %
Accuracy of the network on train loader class  0: [11433 / 12833] 89 %
Accuracy of the network on train loader class  1: [6968 / 7135] 97 %
Train Epoch: 7 [401024/702208 (57%)]	Loss: 0.128708Train Epoch: 7 [402048/702208 (57%)]	Loss: 0.078600Train Epoch: 7 [403072/702208 (57%)]	Loss: 0.029736Train Epoch: 7 [404096/702208 (58%)]	Loss: 0.038859Train Epoch: 7 [405120/702208 (58%)]	Loss: 0.043118Train Epoch: 7 [406016/702208 (58%)]	Loss: 0.058091Train Epoch: 7 [407040/702208 (58%)]	Loss: 0.039876Train Epoch: 7 [408064/702208 (58%)]	Loss: 0.018219Train Epoch: 7 [409088/702208 (58%)]	Loss: 0.023856Train Epoch: 7 [410112/702208 (58%)]	Loss: 0.044156Train Epoch: 7 [411008/702208 (59%)]	Loss: 0.044528Train Epoch: 7 [412032/702208 (59%)]	Loss: 0.077069Train Epoch: 7 [413056/702208 (59%)]	Loss: 0.065702Train Epoch: 7 [414080/702208 (59%)]	Loss: 0.012973Train Epoch: 7 [415104/702208 (59%)]	Loss: 0.040637Train Epoch: 7 [416000/702208 (59%)]	Loss: 0.148361Train Epoch: 7 [416128/702208 (59%)]	Loss: 0.129355Train Epoch: 7 [417024/702208 (59%)]	Loss: 0.074703Train Epoch: 7 [418048/702208 (60%)]	Loss: 0.029007Train Epoch: 7 [419072/702208 (60%)]	Loss: 0.087348Train Epoch: 7 [420096/702208 (60%)]	Loss: 0.045685Train Epoch: 7 [421120/702208 (60%)]	Loss: 0.040205Train Epoch: 7 [422016/702208 (60%)]	Loss: 0.059728Train Epoch: 7 [423040/702208 (60%)]	Loss: 0.072162Train Epoch: 7 [424064/702208 (60%)]	Loss: 0.054064Train Epoch: 7 [425088/702208 (61%)]	Loss: 0.059712
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8098 / 8283] 97 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-4638336-total-98.45-class0-97.77-class1-99.69
Train Epoch: 7 [426112/702208 (61%)]	Loss: 0.044210Train Epoch: 7 [427008/702208 (61%)]	Loss: 0.119925Train Epoch: 7 [428032/702208 (61%)]	Loss: 0.140933Train Epoch: 7 [429056/702208 (61%)]	Loss: 0.034806Train Epoch: 7 [430080/702208 (61%)]	Loss: 0.043616Train Epoch: 7 [431104/702208 (61%)]	Loss: 0.053539Train Epoch: 7 [432000/702208 (62%)]	Loss: 0.059515Train Epoch: 7 [432128/702208 (62%)]	Loss: 0.040456Train Epoch: 7 [433024/702208 (62%)]	Loss: 0.119816Train Epoch: 7 [434048/702208 (62%)]	Loss: 0.068416Train Epoch: 7 [435072/702208 (62%)]	Loss: 0.152669Train Epoch: 7 [436096/702208 (62%)]	Loss: 0.092814Train Epoch: 7 [437120/702208 (62%)]	Loss: 0.100585Train Epoch: 7 [438016/702208 (62%)]	Loss: 0.050744Train Epoch: 7 [439040/702208 (63%)]	Loss: 0.088253Train Epoch: 7 [440064/702208 (63%)]	Loss: 0.072496Train Epoch: 7 [441088/702208 (63%)]	Loss: 0.009469Train Epoch: 7 [442112/702208 (63%)]	Loss: 0.078019Train Epoch: 7 [443008/702208 (63%)]	Loss: 0.024443Train Epoch: 7 [444032/702208 (63%)]	Loss: 0.038460Train Epoch: 7 [445056/702208 (63%)]	Loss: 0.024008Train Epoch: 7 [446080/702208 (64%)]	Loss: 0.021507Train Epoch: 7 [447104/702208 (64%)]	Loss: 0.050200Train Epoch: 7 [448000/702208 (64%)]	Loss: 0.019772Train Epoch: 7 [448128/702208 (64%)]	Loss: 0.080210Train Epoch: 7 [449024/702208 (64%)]	Loss: 0.034521Train Epoch: 7 [450048/702208 (64%)]	Loss: 0.030207
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7748 / 8283] 93 %
Accuracy of the network on test loader class  1: [4515 / 4517] 99 %

Writing model: iterations-4663296-total-95.8-class0-93.54-class1-99.96000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11913 / 12833] 92 %
Accuracy of the network on train loader class  1: [7013 / 7135] 98 %
Train Epoch: 7 [451072/702208 (64%)]	Loss: 0.099069Train Epoch: 7 [452096/702208 (64%)]	Loss: 0.052618Train Epoch: 7 [453120/702208 (65%)]	Loss: 0.053141Train Epoch: 7 [454016/702208 (65%)]	Loss: 0.026131Train Epoch: 7 [455040/702208 (65%)]	Loss: 0.119135Train Epoch: 7 [456064/702208 (65%)]	Loss: 0.066117Train Epoch: 7 [457088/702208 (65%)]	Loss: 0.029536Train Epoch: 7 [458112/702208 (65%)]	Loss: 0.046752Train Epoch: 7 [459008/702208 (65%)]	Loss: 0.039270Train Epoch: 7 [460032/702208 (66%)]	Loss: 0.025081Train Epoch: 7 [461056/702208 (66%)]	Loss: 0.044434Train Epoch: 7 [462080/702208 (66%)]	Loss: 0.048297Train Epoch: 7 [463104/702208 (66%)]	Loss: 0.062359Train Epoch: 7 [464000/702208 (66%)]	Loss: 0.121553Train Epoch: 7 [464128/702208 (66%)]	Loss: 0.013721Train Epoch: 7 [465024/702208 (66%)]	Loss: 0.039950Train Epoch: 7 [466048/702208 (66%)]	Loss: 0.061991Train Epoch: 7 [467072/702208 (67%)]	Loss: 0.070345Train Epoch: 7 [468096/702208 (67%)]	Loss: 0.053715Train Epoch: 7 [469120/702208 (67%)]	Loss: 0.083918Train Epoch: 7 [470016/702208 (67%)]	Loss: 0.011803Train Epoch: 7 [471040/702208 (67%)]	Loss: 0.017325Train Epoch: 7 [472064/702208 (67%)]	Loss: 0.033633Train Epoch: 7 [473088/702208 (67%)]	Loss: 0.038118Train Epoch: 7 [474112/702208 (68%)]	Loss: 0.047812Train Epoch: 7 [475008/702208 (68%)]	Loss: 0.053168
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7998 / 8283] 96 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-4688256-total-97.71-class0-96.56-class1-99.82
Train Epoch: 7 [476032/702208 (68%)]	Loss: 0.072644Train Epoch: 7 [477056/702208 (68%)]	Loss: 0.064133Train Epoch: 7 [478080/702208 (68%)]	Loss: 0.019731Train Epoch: 7 [479104/702208 (68%)]	Loss: 0.055924Train Epoch: 7 [480000/702208 (68%)]	Loss: 0.056456Train Epoch: 7 [480128/702208 (68%)]	Loss: 0.051169Train Epoch: 7 [481024/702208 (69%)]	Loss: 0.065637Train Epoch: 7 [482048/702208 (69%)]	Loss: 0.040416Train Epoch: 7 [483072/702208 (69%)]	Loss: 0.069125Train Epoch: 7 [484096/702208 (69%)]	Loss: 0.042181Train Epoch: 7 [485120/702208 (69%)]	Loss: 0.049856Train Epoch: 7 [486016/702208 (69%)]	Loss: 0.098364Train Epoch: 7 [487040/702208 (69%)]	Loss: 0.019126Train Epoch: 7 [488064/702208 (70%)]	Loss: 0.072134Train Epoch: 7 [489088/702208 (70%)]	Loss: 0.083966Train Epoch: 7 [490112/702208 (70%)]	Loss: 0.055829Train Epoch: 7 [491008/702208 (70%)]	Loss: 0.033559Train Epoch: 7 [492032/702208 (70%)]	Loss: 0.080884Train Epoch: 7 [493056/702208 (70%)]	Loss: 0.042384Train Epoch: 7 [494080/702208 (70%)]	Loss: 0.080920Train Epoch: 7 [495104/702208 (71%)]	Loss: 0.115631Train Epoch: 7 [496000/702208 (71%)]	Loss: 0.060311Train Epoch: 7 [496128/702208 (71%)]	Loss: 0.017531Train Epoch: 7 [497024/702208 (71%)]	Loss: 0.047572Train Epoch: 7 [498048/702208 (71%)]	Loss: 0.034516Train Epoch: 7 [499072/702208 (71%)]	Loss: 0.031776Train Epoch: 7 [500096/702208 (71%)]	Loss: 0.029463
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8053 / 8283] 97 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-4713344-total-98.11999999999999-class0-97.22-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12281 / 12833] 95 %
Accuracy of the network on train loader class  1: [7102 / 7135] 99 %
Train Epoch: 7 [501120/702208 (71%)]	Loss: 0.073520Train Epoch: 7 [502016/702208 (71%)]	Loss: 0.022694Train Epoch: 7 [503040/702208 (72%)]	Loss: 0.067648Train Epoch: 7 [504064/702208 (72%)]	Loss: 0.034972Train Epoch: 7 [505088/702208 (72%)]	Loss: 0.153650Train Epoch: 7 [506112/702208 (72%)]	Loss: 0.048906Train Epoch: 7 [507008/702208 (72%)]	Loss: 0.029723Train Epoch: 7 [508032/702208 (72%)]	Loss: 0.081793Train Epoch: 7 [509056/702208 (72%)]	Loss: 0.033673Train Epoch: 7 [510080/702208 (73%)]	Loss: 0.021952Train Epoch: 7 [511104/702208 (73%)]	Loss: 0.016281Train Epoch: 7 [512000/702208 (73%)]	Loss: 0.041546Train Epoch: 7 [512128/702208 (73%)]	Loss: 0.051156Train Epoch: 7 [513024/702208 (73%)]	Loss: 0.076906Train Epoch: 7 [514048/702208 (73%)]	Loss: 0.083234Train Epoch: 7 [515072/702208 (73%)]	Loss: 0.068973Train Epoch: 7 [516096/702208 (73%)]	Loss: 0.066082Train Epoch: 7 [517120/702208 (74%)]	Loss: 0.057920Train Epoch: 7 [518016/702208 (74%)]	Loss: 0.114441Train Epoch: 7 [519040/702208 (74%)]	Loss: 0.078946Train Epoch: 7 [520064/702208 (74%)]	Loss: 0.102444Train Epoch: 7 [521088/702208 (74%)]	Loss: 0.079770Train Epoch: 7 [522112/702208 (74%)]	Loss: 0.064634Train Epoch: 7 [523008/702208 (74%)]	Loss: 0.032472Train Epoch: 7 [524032/702208 (75%)]	Loss: 0.010830Train Epoch: 7 [525056/702208 (75%)]	Loss: 0.056845
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7922 / 8283] 95 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-4738304-total-97.13000000000001-class0-95.64-class1-99.87
Train Epoch: 7 [526080/702208 (75%)]	Loss: 0.039040Train Epoch: 7 [527104/702208 (75%)]	Loss: 0.055613Train Epoch: 7 [528000/702208 (75%)]	Loss: 0.056353Train Epoch: 7 [528128/702208 (75%)]	Loss: 0.042575Train Epoch: 7 [529024/702208 (75%)]	Loss: 0.031341Train Epoch: 7 [530048/702208 (75%)]	Loss: 0.040124Train Epoch: 7 [531072/702208 (76%)]	Loss: 0.047800Train Epoch: 7 [532096/702208 (76%)]	Loss: 0.051406Train Epoch: 7 [533120/702208 (76%)]	Loss: 0.064435Train Epoch: 7 [534016/702208 (76%)]	Loss: 0.113829Train Epoch: 7 [535040/702208 (76%)]	Loss: 0.060260Train Epoch: 7 [536064/702208 (76%)]	Loss: 0.023405Train Epoch: 7 [537088/702208 (76%)]	Loss: 0.090223Train Epoch: 7 [538112/702208 (77%)]	Loss: 0.045819Train Epoch: 7 [539008/702208 (77%)]	Loss: 0.017330Train Epoch: 7 [540032/702208 (77%)]	Loss: 0.028759Train Epoch: 7 [541056/702208 (77%)]	Loss: 0.045042Train Epoch: 7 [542080/702208 (77%)]	Loss: 0.052958Train Epoch: 7 [543104/702208 (77%)]	Loss: 0.075910Train Epoch: 7 [544000/702208 (77%)]	Loss: 0.056390Train Epoch: 7 [544128/702208 (77%)]	Loss: 0.051361Train Epoch: 7 [545024/702208 (78%)]	Loss: 0.089065Train Epoch: 7 [546048/702208 (78%)]	Loss: 0.038368Train Epoch: 7 [547072/702208 (78%)]	Loss: 0.052401Train Epoch: 7 [548096/702208 (78%)]	Loss: 0.027936Train Epoch: 7 [549120/702208 (78%)]	Loss: 0.029023Train Epoch: 7 [550016/702208 (78%)]	Loss: 0.058493
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8092 / 8283] 97 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-4763264-total-98.45-class0-97.69-class1-99.85000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12297 / 12833] 95 %
Accuracy of the network on train loader class  1: [7109 / 7135] 99 %
Train Epoch: 7 [551040/702208 (78%)]	Loss: 0.046692Train Epoch: 7 [552064/702208 (79%)]	Loss: 0.050084Train Epoch: 7 [553088/702208 (79%)]	Loss: 0.080328Train Epoch: 7 [554112/702208 (79%)]	Loss: 0.017789Train Epoch: 7 [555008/702208 (79%)]	Loss: 0.029111Train Epoch: 7 [556032/702208 (79%)]	Loss: 0.075183Train Epoch: 7 [557056/702208 (79%)]	Loss: 0.080676Train Epoch: 7 [558080/702208 (79%)]	Loss: 0.060311Train Epoch: 7 [559104/702208 (80%)]	Loss: 0.091402Train Epoch: 7 [560000/702208 (80%)]	Loss: 0.042249Train Epoch: 7 [560128/702208 (80%)]	Loss: 0.027875Train Epoch: 7 [561024/702208 (80%)]	Loss: 0.027024Train Epoch: 7 [562048/702208 (80%)]	Loss: 0.049222Train Epoch: 7 [563072/702208 (80%)]	Loss: 0.059142Train Epoch: 7 [564096/702208 (80%)]	Loss: 0.022842Train Epoch: 7 [565120/702208 (80%)]	Loss: 0.014931Train Epoch: 7 [566016/702208 (81%)]	Loss: 0.063156Train Epoch: 7 [567040/702208 (81%)]	Loss: 0.084176Train Epoch: 7 [568064/702208 (81%)]	Loss: 0.046311Train Epoch: 7 [569088/702208 (81%)]	Loss: 0.028847Train Epoch: 7 [570112/702208 (81%)]	Loss: 0.013827Train Epoch: 7 [571008/702208 (81%)]	Loss: 0.033769Train Epoch: 7 [572032/702208 (81%)]	Loss: 0.052026Train Epoch: 7 [573056/702208 (82%)]	Loss: 0.039043Train Epoch: 7 [574080/702208 (82%)]	Loss: 0.043582Train Epoch: 7 [575104/702208 (82%)]	Loss: 0.027800
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8144 / 8283] 98 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-4788352-total-98.72999999999999-class0-98.32-class1-99.49
Train Epoch: 7 [576000/702208 (82%)]	Loss: 0.069376Train Epoch: 7 [576128/702208 (82%)]	Loss: 0.096834Train Epoch: 7 [577024/702208 (82%)]	Loss: 0.069146Train Epoch: 7 [578048/702208 (82%)]	Loss: 0.031808Train Epoch: 7 [579072/702208 (82%)]	Loss: 0.077552Train Epoch: 7 [580096/702208 (83%)]	Loss: 0.034456Train Epoch: 7 [581120/702208 (83%)]	Loss: 0.070237Train Epoch: 7 [582016/702208 (83%)]	Loss: 0.095406Train Epoch: 7 [583040/702208 (83%)]	Loss: 0.025546Train Epoch: 7 [584064/702208 (83%)]	Loss: 0.025116Train Epoch: 7 [585088/702208 (83%)]	Loss: 0.046719Train Epoch: 7 [586112/702208 (83%)]	Loss: 0.028347Train Epoch: 7 [587008/702208 (84%)]	Loss: 0.050282Train Epoch: 7 [588032/702208 (84%)]	Loss: 0.075472Train Epoch: 7 [589056/702208 (84%)]	Loss: 0.035614Train Epoch: 7 [590080/702208 (84%)]	Loss: 0.060270Train Epoch: 7 [591104/702208 (84%)]	Loss: 0.016171Train Epoch: 7 [592000/702208 (84%)]	Loss: 0.105251Train Epoch: 7 [592128/702208 (84%)]	Loss: 0.048361Train Epoch: 7 [593024/702208 (84%)]	Loss: 0.021490Train Epoch: 7 [594048/702208 (85%)]	Loss: 0.108248Train Epoch: 7 [595072/702208 (85%)]	Loss: 0.049250Train Epoch: 7 [596096/702208 (85%)]	Loss: 0.127506Train Epoch: 7 [597120/702208 (85%)]	Loss: 0.037142Train Epoch: 7 [598016/702208 (85%)]	Loss: 0.043289Train Epoch: 7 [599040/702208 (85%)]	Loss: 0.093644Train Epoch: 7 [600064/702208 (85%)]	Loss: 0.140291
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7991 / 8283] 96 %
Accuracy of the network on test loader class  1: [4514 / 4517] 99 %

Writing model: iterations-4813312-total-97.7-class0-96.47-class1-99.92999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12254 / 12833] 95 %
Accuracy of the network on train loader class  1: [7113 / 7135] 99 %
Train Epoch: 7 [601088/702208 (86%)]	Loss: 0.055542Train Epoch: 7 [602112/702208 (86%)]	Loss: 0.025383Train Epoch: 7 [603008/702208 (86%)]	Loss: 0.064695Train Epoch: 7 [604032/702208 (86%)]	Loss: 0.089757Train Epoch: 7 [605056/702208 (86%)]	Loss: 0.089297Train Epoch: 7 [606080/702208 (86%)]	Loss: 0.102351Train Epoch: 7 [607104/702208 (86%)]	Loss: 0.064293Train Epoch: 7 [608000/702208 (87%)]	Loss: 0.064542Train Epoch: 7 [608128/702208 (87%)]	Loss: 0.047918Train Epoch: 7 [609024/702208 (87%)]	Loss: 0.049747Train Epoch: 7 [610048/702208 (87%)]	Loss: 0.098564Train Epoch: 7 [611072/702208 (87%)]	Loss: 0.034833Train Epoch: 7 [612096/702208 (87%)]	Loss: 0.031023Train Epoch: 7 [613120/702208 (87%)]	Loss: 0.056585Train Epoch: 7 [614016/702208 (87%)]	Loss: 0.022928Train Epoch: 7 [615040/702208 (88%)]	Loss: 0.156924Train Epoch: 7 [616064/702208 (88%)]	Loss: 0.060212Train Epoch: 7 [617088/702208 (88%)]	Loss: 0.067066Train Epoch: 7 [618112/702208 (88%)]	Loss: 0.076312Train Epoch: 7 [619008/702208 (88%)]	Loss: 0.019138Train Epoch: 7 [620032/702208 (88%)]	Loss: 0.045074Train Epoch: 7 [621056/702208 (88%)]	Loss: 0.059802Train Epoch: 7 [622080/702208 (89%)]	Loss: 0.017623Train Epoch: 7 [623104/702208 (89%)]	Loss: 0.143196Train Epoch: 7 [624000/702208 (89%)]	Loss: 0.027795Train Epoch: 7 [624128/702208 (89%)]	Loss: 0.049190Train Epoch: 7 [625024/702208 (89%)]	Loss: 0.029857
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8116 / 8283] 97 %
Accuracy of the network on test loader class  1: [4501 / 4517] 99 %

Writing model: iterations-4838272-total-98.57000000000001-class0-97.98-class1-99.65
Train Epoch: 7 [626048/702208 (89%)]	Loss: 0.022675Train Epoch: 7 [627072/702208 (89%)]	Loss: 0.031361Train Epoch: 7 [628096/702208 (89%)]	Loss: 0.051327Train Epoch: 7 [629120/702208 (90%)]	Loss: 0.031261Train Epoch: 7 [630016/702208 (90%)]	Loss: 0.112708Train Epoch: 7 [631040/702208 (90%)]	Loss: 0.024200Train Epoch: 7 [632064/702208 (90%)]	Loss: 0.050258Train Epoch: 7 [633088/702208 (90%)]	Loss: 0.116999Train Epoch: 7 [634112/702208 (90%)]	Loss: 0.055076Train Epoch: 7 [635008/702208 (90%)]	Loss: 0.047398Train Epoch: 7 [636032/702208 (91%)]	Loss: 0.037955Train Epoch: 7 [637056/702208 (91%)]	Loss: 0.062848Train Epoch: 7 [638080/702208 (91%)]	Loss: 0.057916Train Epoch: 7 [639104/702208 (91%)]	Loss: 0.123009Train Epoch: 7 [640000/702208 (91%)]	Loss: 0.049473Train Epoch: 7 [640128/702208 (91%)]	Loss: 0.056871Train Epoch: 7 [641024/702208 (91%)]	Loss: 0.035275Train Epoch: 7 [642048/702208 (91%)]	Loss: 0.047007Train Epoch: 7 [643072/702208 (92%)]	Loss: 0.063204Train Epoch: 7 [644096/702208 (92%)]	Loss: 0.035585Train Epoch: 7 [645120/702208 (92%)]	Loss: 0.110894Train Epoch: 7 [646016/702208 (92%)]	Loss: 0.054485Train Epoch: 7 [647040/702208 (92%)]	Loss: 0.039755Train Epoch: 7 [648064/702208 (92%)]	Loss: 0.066820Train Epoch: 7 [649088/702208 (92%)]	Loss: 0.135156Train Epoch: 7 [650112/702208 (93%)]	Loss: 0.067956
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8129 / 8283] 98 %
Accuracy of the network on test loader class  1: [4501 / 4517] 99 %

Writing model: iterations-4863360-total-98.67-class0-98.14-class1-99.65

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12373 / 12833] 96 %
Accuracy of the network on train loader class  1: [7072 / 7135] 99 %
Train Epoch: 7 [651008/702208 (93%)]	Loss: 0.169968Train Epoch: 7 [652032/702208 (93%)]	Loss: 0.066817Train Epoch: 7 [653056/702208 (93%)]	Loss: 0.035911Train Epoch: 7 [654080/702208 (93%)]	Loss: 0.045247Train Epoch: 7 [655104/702208 (93%)]	Loss: 0.023896Train Epoch: 7 [656000/702208 (93%)]	Loss: 0.035999Train Epoch: 7 [656128/702208 (93%)]	Loss: 0.053841Train Epoch: 7 [657024/702208 (94%)]	Loss: 0.091057Train Epoch: 7 [658048/702208 (94%)]	Loss: 0.019178Train Epoch: 7 [659072/702208 (94%)]	Loss: 0.038062Train Epoch: 7 [660096/702208 (94%)]	Loss: 0.040436Train Epoch: 7 [661120/702208 (94%)]	Loss: 0.075242Train Epoch: 7 [662016/702208 (94%)]	Loss: 0.049562Train Epoch: 7 [663040/702208 (94%)]	Loss: 0.072310Train Epoch: 7 [664064/702208 (95%)]	Loss: 0.065951Train Epoch: 7 [665088/702208 (95%)]	Loss: 0.027531Train Epoch: 7 [666112/702208 (95%)]	Loss: 0.027811Train Epoch: 7 [667008/702208 (95%)]	Loss: 0.056846Train Epoch: 7 [668032/702208 (95%)]	Loss: 0.046061Train Epoch: 7 [669056/702208 (95%)]	Loss: 0.029704Train Epoch: 7 [670080/702208 (95%)]	Loss: 0.043587Train Epoch: 7 [671104/702208 (96%)]	Loss: 0.044811Train Epoch: 7 [672000/702208 (96%)]	Loss: 0.036296Train Epoch: 7 [672128/702208 (96%)]	Loss: 0.049444Train Epoch: 7 [673024/702208 (96%)]	Loss: 0.030684Train Epoch: 7 [674048/702208 (96%)]	Loss: 0.048548Train Epoch: 7 [675072/702208 (96%)]	Loss: 0.070220
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7950 / 8283] 95 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-4888320-total-97.34-class0-95.98-class1-99.85000000000001
Train Epoch: 7 [676096/702208 (96%)]	Loss: 0.035111Train Epoch: 7 [677120/702208 (96%)]	Loss: 0.094707Train Epoch: 7 [678016/702208 (97%)]	Loss: 0.057647Train Epoch: 7 [679040/702208 (97%)]	Loss: 0.036026Train Epoch: 7 [680064/702208 (97%)]	Loss: 0.091511Train Epoch: 7 [681088/702208 (97%)]	Loss: 0.059193Train Epoch: 7 [682112/702208 (97%)]	Loss: 0.022615Train Epoch: 7 [683008/702208 (97%)]	Loss: 0.037450Train Epoch: 7 [684032/702208 (97%)]	Loss: 0.029377Train Epoch: 7 [685056/702208 (98%)]	Loss: 0.037111Train Epoch: 7 [686080/702208 (98%)]	Loss: 0.060468Train Epoch: 7 [687104/702208 (98%)]	Loss: 0.086438Train Epoch: 7 [688000/702208 (98%)]	Loss: 0.244369Train Epoch: 7 [688128/702208 (98%)]	Loss: 0.021199Train Epoch: 7 [689024/702208 (98%)]	Loss: 0.085656Train Epoch: 7 [690048/702208 (98%)]	Loss: 0.081887Train Epoch: 7 [691072/702208 (98%)]	Loss: 0.060725Train Epoch: 7 [692096/702208 (99%)]	Loss: 0.087446Train Epoch: 7 [693120/702208 (99%)]	Loss: 0.030684Train Epoch: 7 [694016/702208 (99%)]	Loss: 0.079186Train Epoch: 7 [695040/702208 (99%)]	Loss: 0.043302Train Epoch: 7 [696064/702208 (99%)]	Loss: 0.077711Train Epoch: 7 [697088/702208 (99%)]	Loss: 0.050347Train Epoch: 7 [698112/702208 (99%)]	Loss: 0.076296Train Epoch: 7 [699008/702208 (100%)]	Loss: 0.060887Train Epoch: 7 [700032/702208 (100%)]	Loss: 0.072574
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8109 / 8283] 97 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %

Writing model: iterations-4913280-total-98.52-class0-97.89999999999999-class1-99.67

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12331 / 12833] 96 %
Accuracy of the network on train loader class  1: [6917 / 7135] 96 %
Train Epoch: 7 [701056/702208 (100%)]	Loss: 0.118541Train Epoch: 7 [702080/702208 (100%)]	Loss: 0.024474
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8113 / 8283] 97 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %
Train Epoch: 8 [1024/702208 (0%)]	Loss: 0.043814Train Epoch: 8 [2048/702208 (0%)]	Loss: 0.045014Train Epoch: 8 [3072/702208 (0%)]	Loss: 0.019240Train Epoch: 8 [4096/702208 (1%)]	Loss: 0.069338Train Epoch: 8 [5120/702208 (1%)]	Loss: 0.052607Train Epoch: 8 [6016/702208 (1%)]	Loss: 0.028827Train Epoch: 8 [7040/702208 (1%)]	Loss: 0.098220Train Epoch: 8 [8064/702208 (1%)]	Loss: 0.043218Train Epoch: 8 [9088/702208 (1%)]	Loss: 0.036932Train Epoch: 8 [10112/702208 (1%)]	Loss: 0.031258Train Epoch: 8 [11008/702208 (2%)]	Loss: 0.025373Train Epoch: 8 [12032/702208 (2%)]	Loss: 0.086777Train Epoch: 8 [13056/702208 (2%)]	Loss: 0.046147Train Epoch: 8 [14080/702208 (2%)]	Loss: 0.010496Train Epoch: 8 [15104/702208 (2%)]	Loss: 0.017435Train Epoch: 8 [16000/702208 (2%)]	Loss: 0.067438Train Epoch: 8 [16128/702208 (2%)]	Loss: 0.030326Train Epoch: 8 [17024/702208 (2%)]	Loss: 0.024329Train Epoch: 8 [18048/702208 (3%)]	Loss: 0.020379Train Epoch: 8 [19072/702208 (3%)]	Loss: 0.077661Train Epoch: 8 [20096/702208 (3%)]	Loss: 0.030612Train Epoch: 8 [21120/702208 (3%)]	Loss: 0.046097Train Epoch: 8 [22016/702208 (3%)]	Loss: 0.064203Train Epoch: 8 [23040/702208 (3%)]	Loss: 0.067437Train Epoch: 8 [24064/702208 (3%)]	Loss: 0.015700Train Epoch: 8 [25088/702208 (4%)]	Loss: 0.083277
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8134 / 8283] 98 %
Accuracy of the network on test loader class  1: [4496 / 4517] 99 %

Writing model: iterations-4940544-total-98.67-class0-98.2-class1-99.53999999999999
Train Epoch: 8 [26112/702208 (4%)]	Loss: 0.131051Train Epoch: 8 [27008/702208 (4%)]	Loss: 0.121125Train Epoch: 8 [28032/702208 (4%)]	Loss: 0.034946Train Epoch: 8 [29056/702208 (4%)]	Loss: 0.019919Train Epoch: 8 [30080/702208 (4%)]	Loss: 0.063510Train Epoch: 8 [31104/702208 (4%)]	Loss: 0.051541Train Epoch: 8 [32000/702208 (5%)]	Loss: 0.034295Train Epoch: 8 [32128/702208 (5%)]	Loss: 0.085175Train Epoch: 8 [33024/702208 (5%)]	Loss: 0.024955Train Epoch: 8 [34048/702208 (5%)]	Loss: 0.037374Train Epoch: 8 [35072/702208 (5%)]	Loss: 0.056079Train Epoch: 8 [36096/702208 (5%)]	Loss: 0.060339Train Epoch: 8 [37120/702208 (5%)]	Loss: 0.076306Train Epoch: 8 [38016/702208 (5%)]	Loss: 0.059264Train Epoch: 8 [39040/702208 (6%)]	Loss: 0.072615Train Epoch: 8 [40064/702208 (6%)]	Loss: 0.017683Train Epoch: 8 [41088/702208 (6%)]	Loss: 0.078925Train Epoch: 8 [42112/702208 (6%)]	Loss: 0.023088Train Epoch: 8 [43008/702208 (6%)]	Loss: 0.030546Train Epoch: 8 [44032/702208 (6%)]	Loss: 0.046432Train Epoch: 8 [45056/702208 (6%)]	Loss: 0.043967Train Epoch: 8 [46080/702208 (7%)]	Loss: 0.055443Train Epoch: 8 [47104/702208 (7%)]	Loss: 0.009304Train Epoch: 8 [48000/702208 (7%)]	Loss: 0.019079Train Epoch: 8 [48128/702208 (7%)]	Loss: 0.045718Train Epoch: 8 [49024/702208 (7%)]	Loss: 0.082097Train Epoch: 8 [50048/702208 (7%)]	Loss: 0.058727
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7962 / 8283] 96 %
Accuracy of the network on test loader class  1: [4517 / 4517] 100 %

Writing model: iterations-4965504-total-97.49-class0-96.12-class1-100.0

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12330 / 12833] 96 %
Accuracy of the network on train loader class  1: [7089 / 7135] 99 %
Train Epoch: 8 [51072/702208 (7%)]	Loss: 0.053559Train Epoch: 8 [52096/702208 (7%)]	Loss: 0.064159Train Epoch: 8 [53120/702208 (8%)]	Loss: 0.080518Train Epoch: 8 [54016/702208 (8%)]	Loss: 0.111293Train Epoch: 8 [55040/702208 (8%)]	Loss: 0.078107Train Epoch: 8 [56064/702208 (8%)]	Loss: 0.023310Train Epoch: 8 [57088/702208 (8%)]	Loss: 0.052671Train Epoch: 8 [58112/702208 (8%)]	Loss: 0.055613Train Epoch: 8 [59008/702208 (8%)]	Loss: 0.077699Train Epoch: 8 [60032/702208 (9%)]	Loss: 0.046246Train Epoch: 8 [61056/702208 (9%)]	Loss: 0.107851Train Epoch: 8 [62080/702208 (9%)]	Loss: 0.072681Train Epoch: 8 [63104/702208 (9%)]	Loss: 0.057484Train Epoch: 8 [64000/702208 (9%)]	Loss: 0.052711Train Epoch: 8 [64128/702208 (9%)]	Loss: 0.050990Train Epoch: 8 [65024/702208 (9%)]	Loss: 0.034913Train Epoch: 8 [66048/702208 (9%)]	Loss: 0.144231Train Epoch: 8 [67072/702208 (10%)]	Loss: 0.153272Train Epoch: 8 [68096/702208 (10%)]	Loss: 0.046068Train Epoch: 8 [69120/702208 (10%)]	Loss: 0.055011Train Epoch: 8 [70016/702208 (10%)]	Loss: 0.029850Train Epoch: 8 [71040/702208 (10%)]	Loss: 0.043931Train Epoch: 8 [72064/702208 (10%)]	Loss: 0.101136Train Epoch: 8 [73088/702208 (10%)]	Loss: 0.049131Train Epoch: 8 [74112/702208 (11%)]	Loss: 0.103926Train Epoch: 8 [75008/702208 (11%)]	Loss: 0.035044
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8153 / 8283] 98 %
Accuracy of the network on test loader class  1: [4498 / 4517] 99 %

Writing model: iterations-4990464-total-98.83999999999999-class0-98.42999999999999-class1-99.58
Train Epoch: 8 [76032/702208 (11%)]	Loss: 0.075372Train Epoch: 8 [77056/702208 (11%)]	Loss: 0.034753Train Epoch: 8 [78080/702208 (11%)]	Loss: 0.062449Train Epoch: 8 [79104/702208 (11%)]	Loss: 0.085103Train Epoch: 8 [80000/702208 (11%)]	Loss: 0.021487Train Epoch: 8 [80128/702208 (11%)]	Loss: 0.055986Train Epoch: 8 [81024/702208 (12%)]	Loss: 0.036915Train Epoch: 8 [82048/702208 (12%)]	Loss: 0.076629Train Epoch: 8 [83072/702208 (12%)]	Loss: 0.046648Train Epoch: 8 [84096/702208 (12%)]	Loss: 0.089936Train Epoch: 8 [85120/702208 (12%)]	Loss: 0.057750Train Epoch: 8 [86016/702208 (12%)]	Loss: 0.035969Train Epoch: 8 [87040/702208 (12%)]	Loss: 0.056318Train Epoch: 8 [88064/702208 (13%)]	Loss: 0.044851Train Epoch: 8 [89088/702208 (13%)]	Loss: 0.058292Train Epoch: 8 [90112/702208 (13%)]	Loss: 0.057983Train Epoch: 8 [91008/702208 (13%)]	Loss: 0.098321Train Epoch: 8 [92032/702208 (13%)]	Loss: 0.161328Train Epoch: 8 [93056/702208 (13%)]	Loss: 0.065782Train Epoch: 8 [94080/702208 (13%)]	Loss: 0.039326Train Epoch: 8 [95104/702208 (14%)]	Loss: 0.041147Train Epoch: 8 [96000/702208 (14%)]	Loss: 0.043771Train Epoch: 8 [96128/702208 (14%)]	Loss: 0.063556Train Epoch: 8 [97024/702208 (14%)]	Loss: 0.045517Train Epoch: 8 [98048/702208 (14%)]	Loss: 0.018397Train Epoch: 8 [99072/702208 (14%)]	Loss: 0.025089Train Epoch: 8 [100096/702208 (14%)]	Loss: 0.044055
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8108 / 8283] 97 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-5015552-total-98.58-class0-97.89-class1-99.85000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12430 / 12833] 96 %
Accuracy of the network on train loader class  1: [7079 / 7135] 99 %
Train Epoch: 8 [101120/702208 (14%)]	Loss: 0.060481Train Epoch: 8 [102016/702208 (15%)]	Loss: 0.048807Train Epoch: 8 [103040/702208 (15%)]	Loss: 0.023767Train Epoch: 8 [104064/702208 (15%)]	Loss: 0.047862Train Epoch: 8 [105088/702208 (15%)]	Loss: 0.034217Train Epoch: 8 [106112/702208 (15%)]	Loss: 0.105731Train Epoch: 8 [107008/702208 (15%)]	Loss: 0.043413Train Epoch: 8 [108032/702208 (15%)]	Loss: 0.019093Train Epoch: 8 [109056/702208 (16%)]	Loss: 0.113307Train Epoch: 8 [110080/702208 (16%)]	Loss: 0.021945Train Epoch: 8 [111104/702208 (16%)]	Loss: 0.074042Train Epoch: 8 [112000/702208 (16%)]	Loss: 0.116668Train Epoch: 8 [112128/702208 (16%)]	Loss: 0.041189Train Epoch: 8 [113024/702208 (16%)]	Loss: 0.015948Train Epoch: 8 [114048/702208 (16%)]	Loss: 0.054624Train Epoch: 8 [115072/702208 (16%)]	Loss: 0.042782Train Epoch: 8 [116096/702208 (17%)]	Loss: 0.100407Train Epoch: 8 [117120/702208 (17%)]	Loss: 0.029927Train Epoch: 8 [118016/702208 (17%)]	Loss: 0.067815Train Epoch: 8 [119040/702208 (17%)]	Loss: 0.033306Train Epoch: 8 [120064/702208 (17%)]	Loss: 0.045006Train Epoch: 8 [121088/702208 (17%)]	Loss: 0.070665Train Epoch: 8 [122112/702208 (17%)]	Loss: 0.076953Train Epoch: 8 [123008/702208 (18%)]	Loss: 0.031840Train Epoch: 8 [124032/702208 (18%)]	Loss: 0.139613Train Epoch: 8 [125056/702208 (18%)]	Loss: 0.044340
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8145 / 8283] 98 %
Accuracy of the network on test loader class  1: [4491 / 4517] 99 %

Writing model: iterations-5040512-total-98.72-class0-98.33-class1-99.42
Train Epoch: 8 [126080/702208 (18%)]	Loss: 0.031003Train Epoch: 8 [127104/702208 (18%)]	Loss: 0.036345Train Epoch: 8 [128000/702208 (18%)]	Loss: 0.025524Train Epoch: 8 [128128/702208 (18%)]	Loss: 0.052677Train Epoch: 8 [129024/702208 (18%)]	Loss: 0.040644Train Epoch: 8 [130048/702208 (19%)]	Loss: 0.031288Train Epoch: 8 [131072/702208 (19%)]	Loss: 0.025155Train Epoch: 8 [132096/702208 (19%)]	Loss: 0.119285Train Epoch: 8 [133120/702208 (19%)]	Loss: 0.034506Train Epoch: 8 [134016/702208 (19%)]	Loss: 0.024031Train Epoch: 8 [135040/702208 (19%)]	Loss: 0.063478Train Epoch: 8 [136064/702208 (19%)]	Loss: 0.110736Train Epoch: 8 [137088/702208 (20%)]	Loss: 0.061262Train Epoch: 8 [138112/702208 (20%)]	Loss: 0.028757Train Epoch: 8 [139008/702208 (20%)]	Loss: 0.040537Train Epoch: 8 [140032/702208 (20%)]	Loss: 0.064919Train Epoch: 8 [141056/702208 (20%)]	Loss: 0.082740Train Epoch: 8 [142080/702208 (20%)]	Loss: 0.156092Train Epoch: 8 [143104/702208 (20%)]	Loss: 0.021833Train Epoch: 8 [144000/702208 (21%)]	Loss: 0.071513Train Epoch: 8 [144128/702208 (21%)]	Loss: 0.050342Train Epoch: 8 [145024/702208 (21%)]	Loss: 0.048147Train Epoch: 8 [146048/702208 (21%)]	Loss: 0.023419Train Epoch: 8 [147072/702208 (21%)]	Loss: 0.020393Train Epoch: 8 [148096/702208 (21%)]	Loss: 0.037470Train Epoch: 8 [149120/702208 (21%)]	Loss: 0.052716Train Epoch: 8 [150016/702208 (21%)]	Loss: 0.061848
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8040 / 8283] 97 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-5065472-total-98.07000000000001-class0-97.07000000000001-class1-99.91

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12359 / 12833] 96 %
Accuracy of the network on train loader class  1: [7100 / 7135] 99 %
Train Epoch: 8 [151040/702208 (22%)]	Loss: 0.046136Train Epoch: 8 [152064/702208 (22%)]	Loss: 0.075924Train Epoch: 8 [153088/702208 (22%)]	Loss: 0.007412Train Epoch: 8 [154112/702208 (22%)]	Loss: 0.011321Train Epoch: 8 [155008/702208 (22%)]	Loss: 0.050939Train Epoch: 8 [156032/702208 (22%)]	Loss: 0.053770Train Epoch: 8 [157056/702208 (22%)]	Loss: 0.037959Train Epoch: 8 [158080/702208 (23%)]	Loss: 0.043146Train Epoch: 8 [159104/702208 (23%)]	Loss: 0.039172Train Epoch: 8 [160000/702208 (23%)]	Loss: 0.055773Train Epoch: 8 [160128/702208 (23%)]	Loss: 0.049770Train Epoch: 8 [161024/702208 (23%)]	Loss: 0.057970Train Epoch: 8 [162048/702208 (23%)]	Loss: 0.050684Train Epoch: 8 [163072/702208 (23%)]	Loss: 0.123819Train Epoch: 8 [164096/702208 (23%)]	Loss: 0.063366Train Epoch: 8 [165120/702208 (24%)]	Loss: 0.042786Train Epoch: 8 [166016/702208 (24%)]	Loss: 0.125195Train Epoch: 8 [167040/702208 (24%)]	Loss: 0.036455Train Epoch: 8 [168064/702208 (24%)]	Loss: 0.130159Train Epoch: 8 [169088/702208 (24%)]	Loss: 0.023860Train Epoch: 8 [170112/702208 (24%)]	Loss: 0.113323Train Epoch: 8 [171008/702208 (24%)]	Loss: 0.006692Train Epoch: 8 [172032/702208 (24%)]	Loss: 0.059121Train Epoch: 8 [173056/702208 (25%)]	Loss: 0.058515Train Epoch: 8 [174080/702208 (25%)]	Loss: 0.026802Train Epoch: 8 [175104/702208 (25%)]	Loss: 0.074157
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8037 / 8283] 97 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-5090560-total-97.98-class0-97.03-class1-99.72999999999999
Train Epoch: 8 [176000/702208 (25%)]	Loss: 0.041284Train Epoch: 8 [176128/702208 (25%)]	Loss: 0.018450Train Epoch: 8 [177024/702208 (25%)]	Loss: 0.037823Train Epoch: 8 [178048/702208 (25%)]	Loss: 0.047599Train Epoch: 8 [179072/702208 (26%)]	Loss: 0.074973Train Epoch: 8 [180096/702208 (26%)]	Loss: 0.047271Train Epoch: 8 [181120/702208 (26%)]	Loss: 0.099583Train Epoch: 8 [182016/702208 (26%)]	Loss: 0.031060Train Epoch: 8 [183040/702208 (26%)]	Loss: 0.113223Train Epoch: 8 [184064/702208 (26%)]	Loss: 0.030352Train Epoch: 8 [185088/702208 (26%)]	Loss: 0.038225Train Epoch: 8 [186112/702208 (27%)]	Loss: 0.039502Train Epoch: 8 [187008/702208 (27%)]	Loss: 0.027800Train Epoch: 8 [188032/702208 (27%)]	Loss: 0.052847Train Epoch: 8 [189056/702208 (27%)]	Loss: 0.038340Train Epoch: 8 [190080/702208 (27%)]	Loss: 0.026133Train Epoch: 8 [191104/702208 (27%)]	Loss: 0.114638Train Epoch: 8 [192000/702208 (27%)]	Loss: 0.020438Train Epoch: 8 [192128/702208 (27%)]	Loss: 0.027154Train Epoch: 8 [193024/702208 (27%)]	Loss: 0.046172Train Epoch: 8 [194048/702208 (28%)]	Loss: 0.036989Train Epoch: 8 [195072/702208 (28%)]	Loss: 0.023035Train Epoch: 8 [196096/702208 (28%)]	Loss: 0.049968Train Epoch: 8 [197120/702208 (28%)]	Loss: 0.080277Train Epoch: 8 [198016/702208 (28%)]	Loss: 0.076150Train Epoch: 8 [199040/702208 (28%)]	Loss: 0.053310Train Epoch: 8 [200064/702208 (28%)]	Loss: 0.056434
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 99 %
Accuracy of the network on test loader class  0: [8185 / 8283] 98 %
Accuracy of the network on test loader class  1: [4488 / 4517] 99 %

Writing model: iterations-5115520-total-99.00999999999999-class0-98.82-class1-99.36

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11947 / 12833] 93 %
Accuracy of the network on train loader class  1: [6997 / 7135] 98 %
Train Epoch: 8 [201088/702208 (29%)]	Loss: 0.054412Train Epoch: 8 [202112/702208 (29%)]	Loss: 0.053243Train Epoch: 8 [203008/702208 (29%)]	Loss: 0.121493Train Epoch: 8 [204032/702208 (29%)]	Loss: 0.039266Train Epoch: 8 [205056/702208 (29%)]	Loss: 0.025694Train Epoch: 8 [206080/702208 (29%)]	Loss: 0.028475Train Epoch: 8 [207104/702208 (29%)]	Loss: 0.023798Train Epoch: 8 [208000/702208 (30%)]	Loss: 0.023714Train Epoch: 8 [208128/702208 (30%)]	Loss: 0.032006Train Epoch: 8 [209024/702208 (30%)]	Loss: 0.019173Train Epoch: 8 [210048/702208 (30%)]	Loss: 0.042422Train Epoch: 8 [211072/702208 (30%)]	Loss: 0.047482Train Epoch: 8 [212096/702208 (30%)]	Loss: 0.031377Train Epoch: 8 [213120/702208 (30%)]	Loss: 0.025171Train Epoch: 8 [214016/702208 (30%)]	Loss: 0.038304Train Epoch: 8 [215040/702208 (31%)]	Loss: 0.090368Train Epoch: 8 [216064/702208 (31%)]	Loss: 0.129909Train Epoch: 8 [217088/702208 (31%)]	Loss: 0.086413Train Epoch: 8 [218112/702208 (31%)]	Loss: 0.037358Train Epoch: 8 [219008/702208 (31%)]	Loss: 0.016222Train Epoch: 8 [220032/702208 (31%)]	Loss: 0.086641Train Epoch: 8 [221056/702208 (31%)]	Loss: 0.098394Train Epoch: 8 [222080/702208 (32%)]	Loss: 0.057254Train Epoch: 8 [223104/702208 (32%)]	Loss: 0.050246Train Epoch: 8 [224000/702208 (32%)]	Loss: 0.189228Train Epoch: 8 [224128/702208 (32%)]	Loss: 0.037463Train Epoch: 8 [225024/702208 (32%)]	Loss: 0.036177
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8090 / 8283] 97 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-5140480-total-98.41-class0-97.67-class1-99.78
Train Epoch: 8 [226048/702208 (32%)]	Loss: 0.023926Train Epoch: 8 [227072/702208 (32%)]	Loss: 0.058837Train Epoch: 8 [228096/702208 (32%)]	Loss: 0.074547Train Epoch: 8 [229120/702208 (33%)]	Loss: 0.058392Train Epoch: 8 [230016/702208 (33%)]	Loss: 0.043575Train Epoch: 8 [231040/702208 (33%)]	Loss: 0.035924Train Epoch: 8 [232064/702208 (33%)]	Loss: 0.078160Train Epoch: 8 [233088/702208 (33%)]	Loss: 0.034226Train Epoch: 8 [234112/702208 (33%)]	Loss: 0.146185Train Epoch: 8 [235008/702208 (33%)]	Loss: 0.044657Train Epoch: 8 [236032/702208 (34%)]	Loss: 0.030327Train Epoch: 8 [237056/702208 (34%)]	Loss: 0.032299Train Epoch: 8 [238080/702208 (34%)]	Loss: 0.055037Train Epoch: 8 [239104/702208 (34%)]	Loss: 0.064078Train Epoch: 8 [240000/702208 (34%)]	Loss: 0.019126Train Epoch: 8 [240128/702208 (34%)]	Loss: 0.021789Train Epoch: 8 [241024/702208 (34%)]	Loss: 0.035239Train Epoch: 8 [242048/702208 (34%)]	Loss: 0.044823Train Epoch: 8 [243072/702208 (35%)]	Loss: 0.081016Train Epoch: 8 [244096/702208 (35%)]	Loss: 0.025518Train Epoch: 8 [245120/702208 (35%)]	Loss: 0.064671Train Epoch: 8 [246016/702208 (35%)]	Loss: 0.082368Train Epoch: 8 [247040/702208 (35%)]	Loss: 0.068945Train Epoch: 8 [248064/702208 (35%)]	Loss: 0.043807Train Epoch: 8 [249088/702208 (35%)]	Loss: 0.037287Train Epoch: 8 [250112/702208 (36%)]	Loss: 0.019604
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8029 / 8283] 96 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-5165568-total-97.96000000000001-class0-96.93-class1-99.85000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12340 / 12833] 96 %
Accuracy of the network on train loader class  1: [7095 / 7135] 99 %
Train Epoch: 8 [251008/702208 (36%)]	Loss: 0.043225Train Epoch: 8 [252032/702208 (36%)]	Loss: 0.015618Train Epoch: 8 [253056/702208 (36%)]	Loss: 0.060258Train Epoch: 8 [254080/702208 (36%)]	Loss: 0.077034Train Epoch: 8 [255104/702208 (36%)]	Loss: 0.118024Train Epoch: 8 [256000/702208 (36%)]	Loss: 0.028957Train Epoch: 8 [256128/702208 (36%)]	Loss: 0.032831Train Epoch: 8 [257024/702208 (37%)]	Loss: 0.076238Train Epoch: 8 [258048/702208 (37%)]	Loss: 0.030987Train Epoch: 8 [259072/702208 (37%)]	Loss: 0.055965Train Epoch: 8 [260096/702208 (37%)]	Loss: 0.021516Train Epoch: 8 [261120/702208 (37%)]	Loss: 0.023781Train Epoch: 8 [262016/702208 (37%)]	Loss: 0.052154Train Epoch: 8 [263040/702208 (37%)]	Loss: 0.021387Train Epoch: 8 [264064/702208 (38%)]	Loss: 0.012284Train Epoch: 8 [265088/702208 (38%)]	Loss: 0.033173Train Epoch: 8 [266112/702208 (38%)]	Loss: 0.070208Train Epoch: 8 [267008/702208 (38%)]	Loss: 0.107984Train Epoch: 8 [268032/702208 (38%)]	Loss: 0.061874Train Epoch: 8 [269056/702208 (38%)]	Loss: 0.065477Train Epoch: 8 [270080/702208 (38%)]	Loss: 0.060959Train Epoch: 8 [271104/702208 (39%)]	Loss: 0.024613Train Epoch: 8 [272000/702208 (39%)]	Loss: 0.033684Train Epoch: 8 [272128/702208 (39%)]	Loss: 0.047969Train Epoch: 8 [273024/702208 (39%)]	Loss: 0.028384Train Epoch: 8 [274048/702208 (39%)]	Loss: 0.058857Train Epoch: 8 [275072/702208 (39%)]	Loss: 0.070247
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 84 %
Accuracy of the network on test loader class  0: [6300 / 8283] 76 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-5190528-total-84.47-class0-76.06-class1-99.89
Train Epoch: 8 [276096/702208 (39%)]	Loss: 0.028992Train Epoch: 8 [277120/702208 (39%)]	Loss: 0.080335Train Epoch: 8 [278016/702208 (40%)]	Loss: 0.029221Train Epoch: 8 [279040/702208 (40%)]	Loss: 0.045674Train Epoch: 8 [280064/702208 (40%)]	Loss: 0.062741Train Epoch: 8 [281088/702208 (40%)]	Loss: 0.045592Train Epoch: 8 [282112/702208 (40%)]	Loss: 0.038332Train Epoch: 8 [283008/702208 (40%)]	Loss: 0.028985Train Epoch: 8 [284032/702208 (40%)]	Loss: 0.036748Train Epoch: 8 [285056/702208 (41%)]	Loss: 0.029516Train Epoch: 8 [286080/702208 (41%)]	Loss: 0.023070Train Epoch: 8 [287104/702208 (41%)]	Loss: 0.039014Train Epoch: 8 [288000/702208 (41%)]	Loss: 0.030635Train Epoch: 8 [288128/702208 (41%)]	Loss: 0.076414Train Epoch: 8 [289024/702208 (41%)]	Loss: 0.030291Train Epoch: 8 [290048/702208 (41%)]	Loss: 0.040958Train Epoch: 8 [291072/702208 (41%)]	Loss: 0.053625Train Epoch: 8 [292096/702208 (42%)]	Loss: 0.043240Train Epoch: 8 [293120/702208 (42%)]	Loss: 0.030818Train Epoch: 8 [294016/702208 (42%)]	Loss: 0.055490Train Epoch: 8 [295040/702208 (42%)]	Loss: 0.039962Train Epoch: 8 [296064/702208 (42%)]	Loss: 0.089209Train Epoch: 8 [297088/702208 (42%)]	Loss: 0.066203Train Epoch: 8 [298112/702208 (42%)]	Loss: 0.061458Train Epoch: 8 [299008/702208 (43%)]	Loss: 0.038982Train Epoch: 8 [300032/702208 (43%)]	Loss: 0.024023
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8040 / 8283] 97 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-5215488-total-98.07000000000001-class0-97.07000000000001-class1-99.91

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12318 / 12833] 95 %
Accuracy of the network on train loader class  1: [7093 / 7135] 99 %
Train Epoch: 8 [301056/702208 (43%)]	Loss: 0.058578Train Epoch: 8 [302080/702208 (43%)]	Loss: 0.098641Train Epoch: 8 [303104/702208 (43%)]	Loss: 0.056490Train Epoch: 8 [304000/702208 (43%)]	Loss: 0.032416Train Epoch: 8 [304128/702208 (43%)]	Loss: 0.038318Train Epoch: 8 [305024/702208 (43%)]	Loss: 0.035260Train Epoch: 8 [306048/702208 (44%)]	Loss: 0.085680Train Epoch: 8 [307072/702208 (44%)]	Loss: 0.091394Train Epoch: 8 [308096/702208 (44%)]	Loss: 0.028013Train Epoch: 8 [309120/702208 (44%)]	Loss: 0.018123Train Epoch: 8 [310016/702208 (44%)]	Loss: 0.041921Train Epoch: 8 [311040/702208 (44%)]	Loss: 0.033922Train Epoch: 8 [312064/702208 (44%)]	Loss: 0.060300Train Epoch: 8 [313088/702208 (45%)]	Loss: 0.037956Train Epoch: 8 [314112/702208 (45%)]	Loss: 0.056809Train Epoch: 8 [315008/702208 (45%)]	Loss: 0.102704Train Epoch: 8 [316032/702208 (45%)]	Loss: 0.044633Train Epoch: 8 [317056/702208 (45%)]	Loss: 0.140581Train Epoch: 8 [318080/702208 (45%)]	Loss: 0.089014Train Epoch: 8 [319104/702208 (45%)]	Loss: 0.053306Train Epoch: 8 [320000/702208 (46%)]	Loss: 0.053756Train Epoch: 8 [320128/702208 (46%)]	Loss: 0.018969Train Epoch: 8 [321024/702208 (46%)]	Loss: 0.053303Train Epoch: 8 [322048/702208 (46%)]	Loss: 0.049907Train Epoch: 8 [323072/702208 (46%)]	Loss: 0.048762Train Epoch: 8 [324096/702208 (46%)]	Loss: 0.078098Train Epoch: 8 [325120/702208 (46%)]	Loss: 0.026175
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8086 / 8283] 97 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-5240576-total-98.41-class0-97.61999999999999-class1-99.85000000000001
Train Epoch: 8 [326016/702208 (46%)]	Loss: 0.051390Train Epoch: 8 [327040/702208 (47%)]	Loss: 0.070923Train Epoch: 8 [328064/702208 (47%)]	Loss: 0.093153Train Epoch: 8 [329088/702208 (47%)]	Loss: 0.020247Train Epoch: 8 [330112/702208 (47%)]	Loss: 0.077853Train Epoch: 8 [331008/702208 (47%)]	Loss: 0.040675Train Epoch: 8 [332032/702208 (47%)]	Loss: 0.050251Train Epoch: 8 [333056/702208 (47%)]	Loss: 0.086663Train Epoch: 8 [334080/702208 (48%)]	Loss: 0.108971Train Epoch: 8 [335104/702208 (48%)]	Loss: 0.064447Train Epoch: 8 [336000/702208 (48%)]	Loss: 0.027370Train Epoch: 8 [336128/702208 (48%)]	Loss: 0.057694Train Epoch: 8 [337024/702208 (48%)]	Loss: 0.035083Train Epoch: 8 [338048/702208 (48%)]	Loss: 0.020507Train Epoch: 8 [339072/702208 (48%)]	Loss: 0.076256Train Epoch: 8 [340096/702208 (48%)]	Loss: 0.032112Train Epoch: 8 [341120/702208 (49%)]	Loss: 0.038002Train Epoch: 8 [342016/702208 (49%)]	Loss: 0.033301Train Epoch: 8 [343040/702208 (49%)]	Loss: 0.084313Train Epoch: 8 [344064/702208 (49%)]	Loss: 0.094880Train Epoch: 8 [345088/702208 (49%)]	Loss: 0.080305Train Epoch: 8 [346112/702208 (49%)]	Loss: 0.030268Train Epoch: 8 [347008/702208 (49%)]	Loss: 0.057603Train Epoch: 8 [348032/702208 (50%)]	Loss: 0.150948Train Epoch: 8 [349056/702208 (50%)]	Loss: 0.047162Train Epoch: 8 [350080/702208 (50%)]	Loss: 0.097093
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8113 / 8283] 97 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-5265536-total-98.57000000000001-class0-97.95-class1-99.71

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12457 / 12833] 97 %
Accuracy of the network on train loader class  1: [7083 / 7135] 99 %
Train Epoch: 8 [351104/702208 (50%)]	Loss: 0.052672Train Epoch: 8 [352000/702208 (50%)]	Loss: 0.056417Train Epoch: 8 [352128/702208 (50%)]	Loss: 0.037300Train Epoch: 8 [353024/702208 (50%)]	Loss: 0.043374Train Epoch: 8 [354048/702208 (50%)]	Loss: 0.055550Train Epoch: 8 [355072/702208 (51%)]	Loss: 0.025324Train Epoch: 8 [356096/702208 (51%)]	Loss: 0.125116Train Epoch: 8 [357120/702208 (51%)]	Loss: 0.035315Train Epoch: 8 [358016/702208 (51%)]	Loss: 0.041537Train Epoch: 8 [359040/702208 (51%)]	Loss: 0.031711Train Epoch: 8 [360064/702208 (51%)]	Loss: 0.077220Train Epoch: 8 [361088/702208 (51%)]	Loss: 0.113407Train Epoch: 8 [362112/702208 (52%)]	Loss: 0.013918Train Epoch: 8 [363008/702208 (52%)]	Loss: 0.057198Train Epoch: 8 [364032/702208 (52%)]	Loss: 0.027701Train Epoch: 8 [365056/702208 (52%)]	Loss: 0.021021Train Epoch: 8 [366080/702208 (52%)]	Loss: 0.034749Train Epoch: 8 [367104/702208 (52%)]	Loss: 0.012717Train Epoch: 8 [368000/702208 (52%)]	Loss: 0.020758Train Epoch: 8 [368128/702208 (52%)]	Loss: 0.087708Train Epoch: 8 [369024/702208 (53%)]	Loss: 0.015925Train Epoch: 8 [370048/702208 (53%)]	Loss: 0.049282Train Epoch: 8 [371072/702208 (53%)]	Loss: 0.093512Train Epoch: 8 [372096/702208 (53%)]	Loss: 0.039054Train Epoch: 8 [373120/702208 (53%)]	Loss: 0.016273Train Epoch: 8 [374016/702208 (53%)]	Loss: 0.021504Train Epoch: 8 [375040/702208 (53%)]	Loss: 0.118420
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8069 / 8283] 97 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-5290496-total-98.22999999999999-class0-97.42-class1-99.71
Train Epoch: 8 [376064/702208 (54%)]	Loss: 0.097668Train Epoch: 8 [377088/702208 (54%)]	Loss: 0.030952Train Epoch: 8 [378112/702208 (54%)]	Loss: 0.074901Train Epoch: 8 [379008/702208 (54%)]	Loss: 0.027134Train Epoch: 8 [380032/702208 (54%)]	Loss: 0.067789Train Epoch: 8 [381056/702208 (54%)]	Loss: 0.058199Train Epoch: 8 [382080/702208 (54%)]	Loss: 0.108342Train Epoch: 8 [383104/702208 (55%)]	Loss: 0.025203Train Epoch: 8 [384000/702208 (55%)]	Loss: 0.096658Train Epoch: 8 [384128/702208 (55%)]	Loss: 0.035688Train Epoch: 8 [385024/702208 (55%)]	Loss: 0.034236Train Epoch: 8 [386048/702208 (55%)]	Loss: 0.039324Train Epoch: 8 [387072/702208 (55%)]	Loss: 0.089869Train Epoch: 8 [388096/702208 (55%)]	Loss: 0.026832Train Epoch: 8 [389120/702208 (55%)]	Loss: 0.087431Train Epoch: 8 [390016/702208 (56%)]	Loss: 0.063688Train Epoch: 8 [391040/702208 (56%)]	Loss: 0.027587Train Epoch: 8 [392064/702208 (56%)]	Loss: 0.016372Train Epoch: 8 [393088/702208 (56%)]	Loss: 0.026051Train Epoch: 8 [394112/702208 (56%)]	Loss: 0.023518Train Epoch: 8 [395008/702208 (56%)]	Loss: 0.031768Train Epoch: 8 [396032/702208 (56%)]	Loss: 0.020781Train Epoch: 8 [397056/702208 (57%)]	Loss: 0.063729Train Epoch: 8 [398080/702208 (57%)]	Loss: 0.050268Train Epoch: 8 [399104/702208 (57%)]	Loss: 0.063337Train Epoch: 8 [400000/702208 (57%)]	Loss: 0.052156
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8002 / 8283] 96 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-5315456-total-97.75-class0-96.61-class1-99.85000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12131 / 12833] 94 %
Accuracy of the network on train loader class  1: [7006 / 7135] 98 %
Train Epoch: 8 [400128/702208 (57%)]	Loss: 0.037055
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8002 / 8283] 96 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-5315584-total-97.72999999999999-class0-96.61-class1-99.8

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 95 %
Accuracy of the network on train loader class  0: [12167 / 12833] 94 %
Accuracy of the network on train loader class  1: [6991 / 7135] 97 %
Train Epoch: 8 [401024/702208 (57%)]	Loss: 0.039582Train Epoch: 8 [402048/702208 (57%)]	Loss: 0.037220Train Epoch: 8 [403072/702208 (57%)]	Loss: 0.117692Train Epoch: 8 [404096/702208 (58%)]	Loss: 0.053270Train Epoch: 8 [405120/702208 (58%)]	Loss: 0.057273Train Epoch: 8 [406016/702208 (58%)]	Loss: 0.077120Train Epoch: 8 [407040/702208 (58%)]	Loss: 0.014682Train Epoch: 8 [408064/702208 (58%)]	Loss: 0.030031Train Epoch: 8 [409088/702208 (58%)]	Loss: 0.013261Train Epoch: 8 [410112/702208 (58%)]	Loss: 0.051811Train Epoch: 8 [411008/702208 (59%)]	Loss: 0.068794Train Epoch: 8 [412032/702208 (59%)]	Loss: 0.018292Train Epoch: 8 [413056/702208 (59%)]	Loss: 0.045521Train Epoch: 8 [414080/702208 (59%)]	Loss: 0.072886Train Epoch: 8 [415104/702208 (59%)]	Loss: 0.072807Train Epoch: 8 [416000/702208 (59%)]	Loss: 0.033815Train Epoch: 8 [416128/702208 (59%)]	Loss: 0.064651Train Epoch: 8 [417024/702208 (59%)]	Loss: 0.044179Train Epoch: 8 [418048/702208 (60%)]	Loss: 0.033283Train Epoch: 8 [419072/702208 (60%)]	Loss: 0.104610Train Epoch: 8 [420096/702208 (60%)]	Loss: 0.062965Train Epoch: 8 [421120/702208 (60%)]	Loss: 0.019859Train Epoch: 8 [422016/702208 (60%)]	Loss: 0.106696Train Epoch: 8 [423040/702208 (60%)]	Loss: 0.069062Train Epoch: 8 [424064/702208 (60%)]	Loss: 0.038264Train Epoch: 8 [425088/702208 (61%)]	Loss: 0.042267
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7989 / 8283] 96 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-5340544-total-97.65-class0-96.45-class1-99.85000000000001
Train Epoch: 8 [426112/702208 (61%)]	Loss: 0.067651Train Epoch: 8 [427008/702208 (61%)]	Loss: 0.041670Train Epoch: 8 [428032/702208 (61%)]	Loss: 0.057051Train Epoch: 8 [429056/702208 (61%)]	Loss: 0.083958Train Epoch: 8 [430080/702208 (61%)]	Loss: 0.084573Train Epoch: 8 [431104/702208 (61%)]	Loss: 0.047592Train Epoch: 8 [432000/702208 (62%)]	Loss: 0.043339Train Epoch: 8 [432128/702208 (62%)]	Loss: 0.071561Train Epoch: 8 [433024/702208 (62%)]	Loss: 0.093255Train Epoch: 8 [434048/702208 (62%)]	Loss: 0.031224Train Epoch: 8 [435072/702208 (62%)]	Loss: 0.106581Train Epoch: 8 [436096/702208 (62%)]	Loss: 0.066673Train Epoch: 8 [437120/702208 (62%)]	Loss: 0.039217Train Epoch: 8 [438016/702208 (62%)]	Loss: 0.030398Train Epoch: 8 [439040/702208 (63%)]	Loss: 0.051690Train Epoch: 8 [440064/702208 (63%)]	Loss: 0.048561Train Epoch: 8 [441088/702208 (63%)]	Loss: 0.060728Train Epoch: 8 [442112/702208 (63%)]	Loss: 0.080644Train Epoch: 8 [443008/702208 (63%)]	Loss: 0.072790Train Epoch: 8 [444032/702208 (63%)]	Loss: 0.080192Train Epoch: 8 [445056/702208 (63%)]	Loss: 0.026239Train Epoch: 8 [446080/702208 (64%)]	Loss: 0.102028Train Epoch: 8 [447104/702208 (64%)]	Loss: 0.056068Train Epoch: 8 [448000/702208 (64%)]	Loss: 0.128251Train Epoch: 8 [448128/702208 (64%)]	Loss: 0.122305Train Epoch: 8 [449024/702208 (64%)]	Loss: 0.060426Train Epoch: 8 [450048/702208 (64%)]	Loss: 0.068517
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8091 / 8283] 97 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-5365504-total-98.41-class0-97.68-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12283 / 12833] 95 %
Accuracy of the network on train loader class  1: [7116 / 7135] 99 %
Train Epoch: 8 [451072/702208 (64%)]	Loss: 0.033291Train Epoch: 8 [452096/702208 (64%)]	Loss: 0.061704Train Epoch: 8 [453120/702208 (65%)]	Loss: 0.043825Train Epoch: 8 [454016/702208 (65%)]	Loss: 0.054820Train Epoch: 8 [455040/702208 (65%)]	Loss: 0.031115Train Epoch: 8 [456064/702208 (65%)]	Loss: 0.036517Train Epoch: 8 [457088/702208 (65%)]	Loss: 0.084669Train Epoch: 8 [458112/702208 (65%)]	Loss: 0.030184Train Epoch: 8 [459008/702208 (65%)]	Loss: 0.087981Train Epoch: 8 [460032/702208 (66%)]	Loss: 0.065819Train Epoch: 8 [461056/702208 (66%)]	Loss: 0.026097Train Epoch: 8 [462080/702208 (66%)]	Loss: 0.046629Train Epoch: 8 [463104/702208 (66%)]	Loss: 0.025971Train Epoch: 8 [464000/702208 (66%)]	Loss: 0.028800Train Epoch: 8 [464128/702208 (66%)]	Loss: 0.053039Train Epoch: 8 [465024/702208 (66%)]	Loss: 0.042182Train Epoch: 8 [466048/702208 (66%)]	Loss: 0.022207Train Epoch: 8 [467072/702208 (67%)]	Loss: 0.014638Train Epoch: 8 [468096/702208 (67%)]	Loss: 0.041166Train Epoch: 8 [469120/702208 (67%)]	Loss: 0.039845Train Epoch: 8 [470016/702208 (67%)]	Loss: 0.075458Train Epoch: 8 [471040/702208 (67%)]	Loss: 0.044964Train Epoch: 8 [472064/702208 (67%)]	Loss: 0.012376Train Epoch: 8 [473088/702208 (67%)]	Loss: 0.032908Train Epoch: 8 [474112/702208 (68%)]	Loss: 0.030194Train Epoch: 8 [475008/702208 (68%)]	Loss: 0.120159
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8103 / 8283] 97 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-5390464-total-98.52-class0-97.83-class1-99.8
Train Epoch: 8 [476032/702208 (68%)]	Loss: 0.047944Train Epoch: 8 [477056/702208 (68%)]	Loss: 0.074168Train Epoch: 8 [478080/702208 (68%)]	Loss: 0.044545Train Epoch: 8 [479104/702208 (68%)]	Loss: 0.062685Train Epoch: 8 [480000/702208 (68%)]	Loss: 0.105239Train Epoch: 8 [480128/702208 (68%)]	Loss: 0.065549Train Epoch: 8 [481024/702208 (69%)]	Loss: 0.024947Train Epoch: 8 [482048/702208 (69%)]	Loss: 0.032466Train Epoch: 8 [483072/702208 (69%)]	Loss: 0.063091Train Epoch: 8 [484096/702208 (69%)]	Loss: 0.171042Train Epoch: 8 [485120/702208 (69%)]	Loss: 0.030685Train Epoch: 8 [486016/702208 (69%)]	Loss: 0.039576Train Epoch: 8 [487040/702208 (69%)]	Loss: 0.033959Train Epoch: 8 [488064/702208 (70%)]	Loss: 0.020435Train Epoch: 8 [489088/702208 (70%)]	Loss: 0.033186Train Epoch: 8 [490112/702208 (70%)]	Loss: 0.069044Train Epoch: 8 [491008/702208 (70%)]	Loss: 0.019338Train Epoch: 8 [492032/702208 (70%)]	Loss: 0.052286Train Epoch: 8 [493056/702208 (70%)]	Loss: 0.067830Train Epoch: 8 [494080/702208 (70%)]	Loss: 0.051782Train Epoch: 8 [495104/702208 (71%)]	Loss: 0.034713Train Epoch: 8 [496000/702208 (71%)]	Loss: 0.027207Train Epoch: 8 [496128/702208 (71%)]	Loss: 0.053383Train Epoch: 8 [497024/702208 (71%)]	Loss: 0.026888Train Epoch: 8 [498048/702208 (71%)]	Loss: 0.088167Train Epoch: 8 [499072/702208 (71%)]	Loss: 0.076974Train Epoch: 8 [500096/702208 (71%)]	Loss: 0.030844
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7996 / 8283] 96 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-5415552-total-97.72-class0-96.54-class1-99.89

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12306 / 12833] 95 %
Accuracy of the network on train loader class  1: [7116 / 7135] 99 %
Train Epoch: 8 [501120/702208 (71%)]	Loss: 0.025103Train Epoch: 8 [502016/702208 (71%)]	Loss: 0.035128Train Epoch: 8 [503040/702208 (72%)]	Loss: 0.055838Train Epoch: 8 [504064/702208 (72%)]	Loss: 0.049662Train Epoch: 8 [505088/702208 (72%)]	Loss: 0.031575Train Epoch: 8 [506112/702208 (72%)]	Loss: 0.030209Train Epoch: 8 [507008/702208 (72%)]	Loss: 0.026675Train Epoch: 8 [508032/702208 (72%)]	Loss: 0.038599Train Epoch: 8 [509056/702208 (72%)]	Loss: 0.059821Train Epoch: 8 [510080/702208 (73%)]	Loss: 0.014018Train Epoch: 8 [511104/702208 (73%)]	Loss: 0.075089Train Epoch: 8 [512000/702208 (73%)]	Loss: 0.030201Train Epoch: 8 [512128/702208 (73%)]	Loss: 0.013356Train Epoch: 8 [513024/702208 (73%)]	Loss: 0.047208Train Epoch: 8 [514048/702208 (73%)]	Loss: 0.039987Train Epoch: 8 [515072/702208 (73%)]	Loss: 0.061460Train Epoch: 8 [516096/702208 (73%)]	Loss: 0.079788Train Epoch: 8 [517120/702208 (74%)]	Loss: 0.024218Train Epoch: 8 [518016/702208 (74%)]	Loss: 0.036761Train Epoch: 8 [519040/702208 (74%)]	Loss: 0.026768Train Epoch: 8 [520064/702208 (74%)]	Loss: 0.025215Train Epoch: 8 [521088/702208 (74%)]	Loss: 0.061402Train Epoch: 8 [522112/702208 (74%)]	Loss: 0.112948Train Epoch: 8 [523008/702208 (74%)]	Loss: 0.064091Train Epoch: 8 [524032/702208 (75%)]	Loss: 0.052034Train Epoch: 8 [525056/702208 (75%)]	Loss: 0.014476
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8127 / 8283] 98 %
Accuracy of the network on test loader class  1: [4498 / 4517] 99 %

Writing model: iterations-5440512-total-98.63-class0-98.11999999999999-class1-99.58
Train Epoch: 8 [526080/702208 (75%)]	Loss: 0.019282Train Epoch: 8 [527104/702208 (75%)]	Loss: 0.098089Train Epoch: 8 [528000/702208 (75%)]	Loss: 0.083506Train Epoch: 8 [528128/702208 (75%)]	Loss: 0.056947Train Epoch: 8 [529024/702208 (75%)]	Loss: 0.160088Train Epoch: 8 [530048/702208 (75%)]	Loss: 0.020766Train Epoch: 8 [531072/702208 (76%)]	Loss: 0.025943Train Epoch: 8 [532096/702208 (76%)]	Loss: 0.085760Train Epoch: 8 [533120/702208 (76%)]	Loss: 0.015513Train Epoch: 8 [534016/702208 (76%)]	Loss: 0.107507Train Epoch: 8 [535040/702208 (76%)]	Loss: 0.063804Train Epoch: 8 [536064/702208 (76%)]	Loss: 0.035564Train Epoch: 8 [537088/702208 (76%)]	Loss: 0.075596Train Epoch: 8 [538112/702208 (77%)]	Loss: 0.085999Train Epoch: 8 [539008/702208 (77%)]	Loss: 0.058457Train Epoch: 8 [540032/702208 (77%)]	Loss: 0.051776Train Epoch: 8 [541056/702208 (77%)]	Loss: 0.063196Train Epoch: 8 [542080/702208 (77%)]	Loss: 0.084796Train Epoch: 8 [543104/702208 (77%)]	Loss: 0.024364Train Epoch: 8 [544000/702208 (77%)]	Loss: 0.040590Train Epoch: 8 [544128/702208 (77%)]	Loss: 0.033604Train Epoch: 8 [545024/702208 (78%)]	Loss: 0.038364Train Epoch: 8 [546048/702208 (78%)]	Loss: 0.064298Train Epoch: 8 [547072/702208 (78%)]	Loss: 0.019086Train Epoch: 8 [548096/702208 (78%)]	Loss: 0.022349Train Epoch: 8 [549120/702208 (78%)]	Loss: 0.013066Train Epoch: 8 [550016/702208 (78%)]	Loss: 0.026430
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8040 / 8283] 97 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-5465472-total-98.04-class0-97.07000000000001-class1-99.82

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11882 / 12833] 92 %
Accuracy of the network on train loader class  1: [7069 / 7135] 99 %
Train Epoch: 8 [551040/702208 (78%)]	Loss: 0.021847Train Epoch: 8 [552064/702208 (79%)]	Loss: 0.039174Train Epoch: 8 [553088/702208 (79%)]	Loss: 0.027954Train Epoch: 8 [554112/702208 (79%)]	Loss: 0.033571Train Epoch: 8 [555008/702208 (79%)]	Loss: 0.018339Train Epoch: 8 [556032/702208 (79%)]	Loss: 0.032667Train Epoch: 8 [557056/702208 (79%)]	Loss: 0.019495Train Epoch: 8 [558080/702208 (79%)]	Loss: 0.034684Train Epoch: 8 [559104/702208 (80%)]	Loss: 0.098382Train Epoch: 8 [560000/702208 (80%)]	Loss: 0.045038Train Epoch: 8 [560128/702208 (80%)]	Loss: 0.057383Train Epoch: 8 [561024/702208 (80%)]	Loss: 0.039760Train Epoch: 8 [562048/702208 (80%)]	Loss: 0.010628Train Epoch: 8 [563072/702208 (80%)]	Loss: 0.056300Train Epoch: 8 [564096/702208 (80%)]	Loss: 0.033258Train Epoch: 8 [565120/702208 (80%)]	Loss: 0.077417Train Epoch: 8 [566016/702208 (81%)]	Loss: 0.090405Train Epoch: 8 [567040/702208 (81%)]	Loss: 0.019771Train Epoch: 8 [568064/702208 (81%)]	Loss: 0.085069Train Epoch: 8 [569088/702208 (81%)]	Loss: 0.078353Train Epoch: 8 [570112/702208 (81%)]	Loss: 0.066590Train Epoch: 8 [571008/702208 (81%)]	Loss: 0.044552Train Epoch: 8 [572032/702208 (81%)]	Loss: 0.057119Train Epoch: 8 [573056/702208 (82%)]	Loss: 0.023227Train Epoch: 8 [574080/702208 (82%)]	Loss: 0.042605Train Epoch: 8 [575104/702208 (82%)]	Loss: 0.014563
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8096 / 8283] 97 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-5490560-total-98.45-class0-97.74000000000001-class1-99.76
Train Epoch: 8 [576000/702208 (82%)]	Loss: 0.047553Train Epoch: 8 [576128/702208 (82%)]	Loss: 0.105460Train Epoch: 8 [577024/702208 (82%)]	Loss: 0.048238Train Epoch: 8 [578048/702208 (82%)]	Loss: 0.043798Train Epoch: 8 [579072/702208 (82%)]	Loss: 0.094091Train Epoch: 8 [580096/702208 (83%)]	Loss: 0.048474Train Epoch: 8 [581120/702208 (83%)]	Loss: 0.017650Train Epoch: 8 [582016/702208 (83%)]	Loss: 0.057542Train Epoch: 8 [583040/702208 (83%)]	Loss: 0.036939Train Epoch: 8 [584064/702208 (83%)]	Loss: 0.018815Train Epoch: 8 [585088/702208 (83%)]	Loss: 0.054219Train Epoch: 8 [586112/702208 (83%)]	Loss: 0.054383Train Epoch: 8 [587008/702208 (84%)]	Loss: 0.085275Train Epoch: 8 [588032/702208 (84%)]	Loss: 0.013018Train Epoch: 8 [589056/702208 (84%)]	Loss: 0.052591Train Epoch: 8 [590080/702208 (84%)]	Loss: 0.015555Train Epoch: 8 [591104/702208 (84%)]	Loss: 0.068663Train Epoch: 8 [592000/702208 (84%)]	Loss: 0.076744Train Epoch: 8 [592128/702208 (84%)]	Loss: 0.068764Train Epoch: 8 [593024/702208 (84%)]	Loss: 0.039243Train Epoch: 8 [594048/702208 (85%)]	Loss: 0.049940Train Epoch: 8 [595072/702208 (85%)]	Loss: 0.019931Train Epoch: 8 [596096/702208 (85%)]	Loss: 0.023321Train Epoch: 8 [597120/702208 (85%)]	Loss: 0.038499Train Epoch: 8 [598016/702208 (85%)]	Loss: 0.024240Train Epoch: 8 [599040/702208 (85%)]	Loss: 0.038650Train Epoch: 8 [600064/702208 (85%)]	Loss: 0.100193
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8071 / 8283] 97 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-5515520-total-98.25-class0-97.44-class1-99.72999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12398 / 12833] 96 %
Accuracy of the network on train loader class  1: [7097 / 7135] 99 %
Train Epoch: 8 [601088/702208 (86%)]	Loss: 0.166436Train Epoch: 8 [602112/702208 (86%)]	Loss: 0.077854Train Epoch: 8 [603008/702208 (86%)]	Loss: 0.019854Train Epoch: 8 [604032/702208 (86%)]	Loss: 0.016068Train Epoch: 8 [605056/702208 (86%)]	Loss: 0.030029Train Epoch: 8 [606080/702208 (86%)]	Loss: 0.022999Train Epoch: 8 [607104/702208 (86%)]	Loss: 0.105133Train Epoch: 8 [608000/702208 (87%)]	Loss: 0.063127Train Epoch: 8 [608128/702208 (87%)]	Loss: 0.022351Train Epoch: 8 [609024/702208 (87%)]	Loss: 0.005637Train Epoch: 8 [610048/702208 (87%)]	Loss: 0.024116Train Epoch: 8 [611072/702208 (87%)]	Loss: 0.027194Train Epoch: 8 [612096/702208 (87%)]	Loss: 0.056435Train Epoch: 8 [613120/702208 (87%)]	Loss: 0.021882Train Epoch: 8 [614016/702208 (87%)]	Loss: 0.050338Train Epoch: 8 [615040/702208 (88%)]	Loss: 0.052866Train Epoch: 8 [616064/702208 (88%)]	Loss: 0.032281Train Epoch: 8 [617088/702208 (88%)]	Loss: 0.061144Train Epoch: 8 [618112/702208 (88%)]	Loss: 0.061322Train Epoch: 8 [619008/702208 (88%)]	Loss: 0.014830Train Epoch: 8 [620032/702208 (88%)]	Loss: 0.080629Train Epoch: 8 [621056/702208 (88%)]	Loss: 0.024492Train Epoch: 8 [622080/702208 (89%)]	Loss: 0.089166Train Epoch: 8 [623104/702208 (89%)]	Loss: 0.128938Train Epoch: 8 [624000/702208 (89%)]	Loss: 0.022961Train Epoch: 8 [624128/702208 (89%)]	Loss: 0.095442Train Epoch: 8 [625024/702208 (89%)]	Loss: 0.031354
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8026 / 8283] 96 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-5540480-total-97.94-class0-96.89999999999999-class1-99.85000000000001
Train Epoch: 8 [626048/702208 (89%)]	Loss: 0.052340Train Epoch: 8 [627072/702208 (89%)]	Loss: 0.077962Train Epoch: 8 [628096/702208 (89%)]	Loss: 0.085854Train Epoch: 8 [629120/702208 (90%)]	Loss: 0.021080Train Epoch: 8 [630016/702208 (90%)]	Loss: 0.041262Train Epoch: 8 [631040/702208 (90%)]	Loss: 0.045191Train Epoch: 8 [632064/702208 (90%)]	Loss: 0.027642Train Epoch: 8 [633088/702208 (90%)]	Loss: 0.032031Train Epoch: 8 [634112/702208 (90%)]	Loss: 0.026118Train Epoch: 8 [635008/702208 (90%)]	Loss: 0.027916Train Epoch: 8 [636032/702208 (91%)]	Loss: 0.037961Train Epoch: 8 [637056/702208 (91%)]	Loss: 0.042582Train Epoch: 8 [638080/702208 (91%)]	Loss: 0.058663Train Epoch: 8 [639104/702208 (91%)]	Loss: 0.086527Train Epoch: 8 [640000/702208 (91%)]	Loss: 0.056519Train Epoch: 8 [640128/702208 (91%)]	Loss: 0.090715Train Epoch: 8 [641024/702208 (91%)]	Loss: 0.067385Train Epoch: 8 [642048/702208 (91%)]	Loss: 0.036640Train Epoch: 8 [643072/702208 (92%)]	Loss: 0.059440Train Epoch: 8 [644096/702208 (92%)]	Loss: 0.017922Train Epoch: 8 [645120/702208 (92%)]	Loss: 0.161497Train Epoch: 8 [646016/702208 (92%)]	Loss: 0.017383Train Epoch: 8 [647040/702208 (92%)]	Loss: 0.049737Train Epoch: 8 [648064/702208 (92%)]	Loss: 0.029562Train Epoch: 8 [649088/702208 (92%)]	Loss: 0.058907Train Epoch: 8 [650112/702208 (93%)]	Loss: 0.071015
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8118 / 8283] 98 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-5565568-total-98.61-class0-98.00999999999999-class1-99.71

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12421 / 12833] 96 %
Accuracy of the network on train loader class  1: [7112 / 7135] 99 %
Train Epoch: 8 [651008/702208 (93%)]	Loss: 0.036638Train Epoch: 8 [652032/702208 (93%)]	Loss: 0.061216Train Epoch: 8 [653056/702208 (93%)]	Loss: 0.040747Train Epoch: 8 [654080/702208 (93%)]	Loss: 0.031319Train Epoch: 8 [655104/702208 (93%)]	Loss: 0.047284Train Epoch: 8 [656000/702208 (93%)]	Loss: 0.073119Train Epoch: 8 [656128/702208 (93%)]	Loss: 0.022684Train Epoch: 8 [657024/702208 (94%)]	Loss: 0.030666Train Epoch: 8 [658048/702208 (94%)]	Loss: 0.088027Train Epoch: 8 [659072/702208 (94%)]	Loss: 0.021553Train Epoch: 8 [660096/702208 (94%)]	Loss: 0.069395Train Epoch: 8 [661120/702208 (94%)]	Loss: 0.054568Train Epoch: 8 [662016/702208 (94%)]	Loss: 0.031679Train Epoch: 8 [663040/702208 (94%)]	Loss: 0.092251Train Epoch: 8 [664064/702208 (95%)]	Loss: 0.044927Train Epoch: 8 [665088/702208 (95%)]	Loss: 0.056604Train Epoch: 8 [666112/702208 (95%)]	Loss: 0.036906Train Epoch: 8 [667008/702208 (95%)]	Loss: 0.077356Train Epoch: 8 [668032/702208 (95%)]	Loss: 0.075362Train Epoch: 8 [669056/702208 (95%)]	Loss: 0.044438Train Epoch: 8 [670080/702208 (95%)]	Loss: 0.132055Train Epoch: 8 [671104/702208 (96%)]	Loss: 0.059675Train Epoch: 8 [672000/702208 (96%)]	Loss: 0.078904Train Epoch: 8 [672128/702208 (96%)]	Loss: 0.054522Train Epoch: 8 [673024/702208 (96%)]	Loss: 0.045048Train Epoch: 8 [674048/702208 (96%)]	Loss: 0.052454Train Epoch: 8 [675072/702208 (96%)]	Loss: 0.097125
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7973 / 8283] 96 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-5590528-total-97.55-class0-96.26-class1-99.91
Train Epoch: 8 [676096/702208 (96%)]	Loss: 0.024836Train Epoch: 8 [677120/702208 (96%)]	Loss: 0.075646Train Epoch: 8 [678016/702208 (97%)]	Loss: 0.051259Train Epoch: 8 [679040/702208 (97%)]	Loss: 0.053658Train Epoch: 8 [680064/702208 (97%)]	Loss: 0.054358Train Epoch: 8 [681088/702208 (97%)]	Loss: 0.019806Train Epoch: 8 [682112/702208 (97%)]	Loss: 0.024606Train Epoch: 8 [683008/702208 (97%)]	Loss: 0.018020Train Epoch: 8 [684032/702208 (97%)]	Loss: 0.125848Train Epoch: 8 [685056/702208 (98%)]	Loss: 0.023197Train Epoch: 8 [686080/702208 (98%)]	Loss: 0.050771Train Epoch: 8 [687104/702208 (98%)]	Loss: 0.026199Train Epoch: 8 [688000/702208 (98%)]	Loss: 0.043705Train Epoch: 8 [688128/702208 (98%)]	Loss: 0.024642Train Epoch: 8 [689024/702208 (98%)]	Loss: 0.022954Train Epoch: 8 [690048/702208 (98%)]	Loss: 0.073513Train Epoch: 8 [691072/702208 (98%)]	Loss: 0.134807Train Epoch: 8 [692096/702208 (99%)]	Loss: 0.053408Train Epoch: 8 [693120/702208 (99%)]	Loss: 0.025193Train Epoch: 8 [694016/702208 (99%)]	Loss: 0.050060Train Epoch: 8 [695040/702208 (99%)]	Loss: 0.053596Train Epoch: 8 [696064/702208 (99%)]	Loss: 0.031585Train Epoch: 8 [697088/702208 (99%)]	Loss: 0.057601Train Epoch: 8 [698112/702208 (99%)]	Loss: 0.030440Train Epoch: 8 [699008/702208 (100%)]	Loss: 0.079108Train Epoch: 8 [700032/702208 (100%)]	Loss: 0.061983
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8084 / 8283] 97 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-5615488-total-98.38-class0-97.6-class1-99.8

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12152 / 12833] 94 %
Accuracy of the network on train loader class  1: [7079 / 7135] 99 %
Train Epoch: 8 [701056/702208 (100%)]	Loss: 0.058904Train Epoch: 8 [702080/702208 (100%)]	Loss: 0.051746
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8141 / 8283] 98 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %
Train Epoch: 9 [1024/702208 (0%)]	Loss: 0.031025Train Epoch: 9 [2048/702208 (0%)]	Loss: 0.030072Train Epoch: 9 [3072/702208 (0%)]	Loss: 0.040664Train Epoch: 9 [4096/702208 (1%)]	Loss: 0.010126Train Epoch: 9 [5120/702208 (1%)]	Loss: 0.021961Train Epoch: 9 [6016/702208 (1%)]	Loss: 0.039725Train Epoch: 9 [7040/702208 (1%)]	Loss: 0.059127Train Epoch: 9 [8064/702208 (1%)]	Loss: 0.069535Train Epoch: 9 [9088/702208 (1%)]	Loss: 0.078236Train Epoch: 9 [10112/702208 (1%)]	Loss: 0.016698Train Epoch: 9 [11008/702208 (2%)]	Loss: 0.062563Train Epoch: 9 [12032/702208 (2%)]	Loss: 0.034610Train Epoch: 9 [13056/702208 (2%)]	Loss: 0.071878Train Epoch: 9 [14080/702208 (2%)]	Loss: 0.057007Train Epoch: 9 [15104/702208 (2%)]	Loss: 0.074550Train Epoch: 9 [16000/702208 (2%)]	Loss: 0.036134Train Epoch: 9 [16128/702208 (2%)]	Loss: 0.105007Train Epoch: 9 [17024/702208 (2%)]	Loss: 0.030813Train Epoch: 9 [18048/702208 (3%)]	Loss: 0.032133Train Epoch: 9 [19072/702208 (3%)]	Loss: 0.089775Train Epoch: 9 [20096/702208 (3%)]	Loss: 0.041700Train Epoch: 9 [21120/702208 (3%)]	Loss: 0.050981Train Epoch: 9 [22016/702208 (3%)]	Loss: 0.027536Train Epoch: 9 [23040/702208 (3%)]	Loss: 0.080954Train Epoch: 9 [24064/702208 (3%)]	Loss: 0.084977Train Epoch: 9 [25088/702208 (4%)]	Loss: 0.056051
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8125 / 8283] 98 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-5642752-total-98.69-class0-98.09-class1-99.78
Train Epoch: 9 [26112/702208 (4%)]	Loss: 0.021329Train Epoch: 9 [27008/702208 (4%)]	Loss: 0.019750Train Epoch: 9 [28032/702208 (4%)]	Loss: 0.057832Train Epoch: 9 [29056/702208 (4%)]	Loss: 0.048343Train Epoch: 9 [30080/702208 (4%)]	Loss: 0.027922Train Epoch: 9 [31104/702208 (4%)]	Loss: 0.050828Train Epoch: 9 [32000/702208 (5%)]	Loss: 0.028522Train Epoch: 9 [32128/702208 (5%)]	Loss: 0.056905Train Epoch: 9 [33024/702208 (5%)]	Loss: 0.096487Train Epoch: 9 [34048/702208 (5%)]	Loss: 0.026112Train Epoch: 9 [35072/702208 (5%)]	Loss: 0.027275Train Epoch: 9 [36096/702208 (5%)]	Loss: 0.049277Train Epoch: 9 [37120/702208 (5%)]	Loss: 0.052818Train Epoch: 9 [38016/702208 (5%)]	Loss: 0.095840Train Epoch: 9 [39040/702208 (6%)]	Loss: 0.055048Train Epoch: 9 [40064/702208 (6%)]	Loss: 0.033111Train Epoch: 9 [41088/702208 (6%)]	Loss: 0.027989Train Epoch: 9 [42112/702208 (6%)]	Loss: 0.076892Train Epoch: 9 [43008/702208 (6%)]	Loss: 0.030920Train Epoch: 9 [44032/702208 (6%)]	Loss: 0.022936Train Epoch: 9 [45056/702208 (6%)]	Loss: 0.143226Train Epoch: 9 [46080/702208 (7%)]	Loss: 0.038955Train Epoch: 9 [47104/702208 (7%)]	Loss: 0.064178Train Epoch: 9 [48000/702208 (7%)]	Loss: 0.039747Train Epoch: 9 [48128/702208 (7%)]	Loss: 0.057209Train Epoch: 9 [49024/702208 (7%)]	Loss: 0.036356Train Epoch: 9 [50048/702208 (7%)]	Loss: 0.054936
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8140 / 8283] 98 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-5667712-total-98.8-class0-98.27-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 98 %
Accuracy of the network on train loader class  0: [12469 / 12833] 97 %
Accuracy of the network on train loader class  1: [7103 / 7135] 99 %
Train Epoch: 9 [51072/702208 (7%)]	Loss: 0.077594Train Epoch: 9 [52096/702208 (7%)]	Loss: 0.046986Train Epoch: 9 [53120/702208 (8%)]	Loss: 0.016274Train Epoch: 9 [54016/702208 (8%)]	Loss: 0.049504Train Epoch: 9 [55040/702208 (8%)]	Loss: 0.069334Train Epoch: 9 [56064/702208 (8%)]	Loss: 0.185861Train Epoch: 9 [57088/702208 (8%)]	Loss: 0.035722Train Epoch: 9 [58112/702208 (8%)]	Loss: 0.012821Train Epoch: 9 [59008/702208 (8%)]	Loss: 0.079357Train Epoch: 9 [60032/702208 (9%)]	Loss: 0.030562Train Epoch: 9 [61056/702208 (9%)]	Loss: 0.028803Train Epoch: 9 [62080/702208 (9%)]	Loss: 0.047237Train Epoch: 9 [63104/702208 (9%)]	Loss: 0.145526Train Epoch: 9 [64000/702208 (9%)]	Loss: 0.022335Train Epoch: 9 [64128/702208 (9%)]	Loss: 0.061619Train Epoch: 9 [65024/702208 (9%)]	Loss: 0.051108Train Epoch: 9 [66048/702208 (9%)]	Loss: 0.027183Train Epoch: 9 [67072/702208 (10%)]	Loss: 0.082123Train Epoch: 9 [68096/702208 (10%)]	Loss: 0.029348Train Epoch: 9 [69120/702208 (10%)]	Loss: 0.033170Train Epoch: 9 [70016/702208 (10%)]	Loss: 0.094311Train Epoch: 9 [71040/702208 (10%)]	Loss: 0.081511Train Epoch: 9 [72064/702208 (10%)]	Loss: 0.015552Train Epoch: 9 [73088/702208 (10%)]	Loss: 0.020017Train Epoch: 9 [74112/702208 (11%)]	Loss: 0.032261Train Epoch: 9 [75008/702208 (11%)]	Loss: 0.019840
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8134 / 8283] 98 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-5692672-total-98.76-class0-98.2-class1-99.78
Train Epoch: 9 [76032/702208 (11%)]	Loss: 0.093075Train Epoch: 9 [77056/702208 (11%)]	Loss: 0.022051Train Epoch: 9 [78080/702208 (11%)]	Loss: 0.033208Train Epoch: 9 [79104/702208 (11%)]	Loss: 0.053593Train Epoch: 9 [80000/702208 (11%)]	Loss: 0.052730Train Epoch: 9 [80128/702208 (11%)]	Loss: 0.014494Train Epoch: 9 [81024/702208 (12%)]	Loss: 0.035509Train Epoch: 9 [82048/702208 (12%)]	Loss: 0.033517Train Epoch: 9 [83072/702208 (12%)]	Loss: 0.020870Train Epoch: 9 [84096/702208 (12%)]	Loss: 0.024312Train Epoch: 9 [85120/702208 (12%)]	Loss: 0.033284Train Epoch: 9 [86016/702208 (12%)]	Loss: 0.039651Train Epoch: 9 [87040/702208 (12%)]	Loss: 0.054621Train Epoch: 9 [88064/702208 (13%)]	Loss: 0.058073Train Epoch: 9 [89088/702208 (13%)]	Loss: 0.013038Train Epoch: 9 [90112/702208 (13%)]	Loss: 0.012972Train Epoch: 9 [91008/702208 (13%)]	Loss: 0.030138Train Epoch: 9 [92032/702208 (13%)]	Loss: 0.024882Train Epoch: 9 [93056/702208 (13%)]	Loss: 0.022255Train Epoch: 9 [94080/702208 (13%)]	Loss: 0.034581Train Epoch: 9 [95104/702208 (14%)]	Loss: 0.045519Train Epoch: 9 [96000/702208 (14%)]	Loss: 0.019621Train Epoch: 9 [96128/702208 (14%)]	Loss: 0.022907Train Epoch: 9 [97024/702208 (14%)]	Loss: 0.047411Train Epoch: 9 [98048/702208 (14%)]	Loss: 0.130274Train Epoch: 9 [99072/702208 (14%)]	Loss: 0.026113Train Epoch: 9 [100096/702208 (14%)]	Loss: 0.010548
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8057 / 8283] 97 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-5717760-total-98.18-class0-97.27-class1-99.85000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 94 %
Accuracy of the network on train loader class  0: [11884 / 12833] 92 %
Accuracy of the network on train loader class  1: [6977 / 7135] 97 %
Train Epoch: 9 [101120/702208 (14%)]	Loss: 0.030779Train Epoch: 9 [102016/702208 (15%)]	Loss: 0.022974Train Epoch: 9 [103040/702208 (15%)]	Loss: 0.056327Train Epoch: 9 [104064/702208 (15%)]	Loss: 0.019365Train Epoch: 9 [105088/702208 (15%)]	Loss: 0.135079Train Epoch: 9 [106112/702208 (15%)]	Loss: 0.019565Train Epoch: 9 [107008/702208 (15%)]	Loss: 0.044026Train Epoch: 9 [108032/702208 (15%)]	Loss: 0.053622Train Epoch: 9 [109056/702208 (16%)]	Loss: 0.040926Train Epoch: 9 [110080/702208 (16%)]	Loss: 0.008327Train Epoch: 9 [111104/702208 (16%)]	Loss: 0.036917Train Epoch: 9 [112000/702208 (16%)]	Loss: 0.027002Train Epoch: 9 [112128/702208 (16%)]	Loss: 0.098290Train Epoch: 9 [113024/702208 (16%)]	Loss: 0.035920Train Epoch: 9 [114048/702208 (16%)]	Loss: 0.083752Train Epoch: 9 [115072/702208 (16%)]	Loss: 0.064844Train Epoch: 9 [116096/702208 (17%)]	Loss: 0.021159Train Epoch: 9 [117120/702208 (17%)]	Loss: 0.040720Train Epoch: 9 [118016/702208 (17%)]	Loss: 0.107666Train Epoch: 9 [119040/702208 (17%)]	Loss: 0.058844Train Epoch: 9 [120064/702208 (17%)]	Loss: 0.107928Train Epoch: 9 [121088/702208 (17%)]	Loss: 0.024471Train Epoch: 9 [122112/702208 (17%)]	Loss: 0.052417Train Epoch: 9 [123008/702208 (18%)]	Loss: 0.034204Train Epoch: 9 [124032/702208 (18%)]	Loss: 0.058198Train Epoch: 9 [125056/702208 (18%)]	Loss: 0.025600
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8043 / 8283] 97 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-5742720-total-98.06-class0-97.1-class1-99.82
Train Epoch: 9 [126080/702208 (18%)]	Loss: 0.052292Train Epoch: 9 [127104/702208 (18%)]	Loss: 0.046751Train Epoch: 9 [128000/702208 (18%)]	Loss: 0.133441Train Epoch: 9 [128128/702208 (18%)]	Loss: 0.130170Train Epoch: 9 [129024/702208 (18%)]	Loss: 0.044363Train Epoch: 9 [130048/702208 (19%)]	Loss: 0.066013Train Epoch: 9 [131072/702208 (19%)]	Loss: 0.067853Train Epoch: 9 [132096/702208 (19%)]	Loss: 0.104005Train Epoch: 9 [133120/702208 (19%)]	Loss: 0.042896Train Epoch: 9 [134016/702208 (19%)]	Loss: 0.044768Train Epoch: 9 [135040/702208 (19%)]	Loss: 0.073187Train Epoch: 9 [136064/702208 (19%)]	Loss: 0.074403Train Epoch: 9 [137088/702208 (20%)]	Loss: 0.052973Train Epoch: 9 [138112/702208 (20%)]	Loss: 0.035907Train Epoch: 9 [139008/702208 (20%)]	Loss: 0.034606Train Epoch: 9 [140032/702208 (20%)]	Loss: 0.042709Train Epoch: 9 [141056/702208 (20%)]	Loss: 0.034150Train Epoch: 9 [142080/702208 (20%)]	Loss: 0.057931Train Epoch: 9 [143104/702208 (20%)]	Loss: 0.048296Train Epoch: 9 [144000/702208 (21%)]	Loss: 0.021017Train Epoch: 9 [144128/702208 (21%)]	Loss: 0.060706Train Epoch: 9 [145024/702208 (21%)]	Loss: 0.079035Train Epoch: 9 [146048/702208 (21%)]	Loss: 0.057724Train Epoch: 9 [147072/702208 (21%)]	Loss: 0.016724Train Epoch: 9 [148096/702208 (21%)]	Loss: 0.071038Train Epoch: 9 [149120/702208 (21%)]	Loss: 0.203101Train Epoch: 9 [150016/702208 (21%)]	Loss: 0.072235
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8068 / 8283] 97 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-5767680-total-98.27-class0-97.39999999999999-class1-99.87

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12325 / 12833] 96 %
Accuracy of the network on train loader class  1: [7097 / 7135] 99 %
Train Epoch: 9 [151040/702208 (22%)]	Loss: 0.039318Train Epoch: 9 [152064/702208 (22%)]	Loss: 0.040921Train Epoch: 9 [153088/702208 (22%)]	Loss: 0.066608Train Epoch: 9 [154112/702208 (22%)]	Loss: 0.091961Train Epoch: 9 [155008/702208 (22%)]	Loss: 0.009941Train Epoch: 9 [156032/702208 (22%)]	Loss: 0.024285Train Epoch: 9 [157056/702208 (22%)]	Loss: 0.019723Train Epoch: 9 [158080/702208 (23%)]	Loss: 0.093088Train Epoch: 9 [159104/702208 (23%)]	Loss: 0.029363Train Epoch: 9 [160000/702208 (23%)]	Loss: 0.075816Train Epoch: 9 [160128/702208 (23%)]	Loss: 0.037975Train Epoch: 9 [161024/702208 (23%)]	Loss: 0.219513Train Epoch: 9 [162048/702208 (23%)]	Loss: 0.049693Train Epoch: 9 [163072/702208 (23%)]	Loss: 0.049155Train Epoch: 9 [164096/702208 (23%)]	Loss: 0.065733Train Epoch: 9 [165120/702208 (24%)]	Loss: 0.048695Train Epoch: 9 [166016/702208 (24%)]	Loss: 0.033757Train Epoch: 9 [167040/702208 (24%)]	Loss: 0.037882Train Epoch: 9 [168064/702208 (24%)]	Loss: 0.028987Train Epoch: 9 [169088/702208 (24%)]	Loss: 0.040883Train Epoch: 9 [170112/702208 (24%)]	Loss: 0.047143Train Epoch: 9 [171008/702208 (24%)]	Loss: 0.036473Train Epoch: 9 [172032/702208 (24%)]	Loss: 0.051531Train Epoch: 9 [173056/702208 (25%)]	Loss: 0.051843Train Epoch: 9 [174080/702208 (25%)]	Loss: 0.056958Train Epoch: 9 [175104/702208 (25%)]	Loss: 0.019311
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8143 / 8283] 98 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-5792768-total-98.81-class0-98.31-class1-99.72999999999999
Train Epoch: 9 [176000/702208 (25%)]	Loss: 0.054822Train Epoch: 9 [176128/702208 (25%)]	Loss: 0.142887Train Epoch: 9 [177024/702208 (25%)]	Loss: 0.022100Train Epoch: 9 [178048/702208 (25%)]	Loss: 0.018855Train Epoch: 9 [179072/702208 (26%)]	Loss: 0.052568Train Epoch: 9 [180096/702208 (26%)]	Loss: 0.049672Train Epoch: 9 [181120/702208 (26%)]	Loss: 0.073051Train Epoch: 9 [182016/702208 (26%)]	Loss: 0.081618Train Epoch: 9 [183040/702208 (26%)]	Loss: 0.033117Train Epoch: 9 [184064/702208 (26%)]	Loss: 0.049124Train Epoch: 9 [185088/702208 (26%)]	Loss: 0.027623Train Epoch: 9 [186112/702208 (27%)]	Loss: 0.069567Train Epoch: 9 [187008/702208 (27%)]	Loss: 0.026763Train Epoch: 9 [188032/702208 (27%)]	Loss: 0.043342Train Epoch: 9 [189056/702208 (27%)]	Loss: 0.071725Train Epoch: 9 [190080/702208 (27%)]	Loss: 0.036673Train Epoch: 9 [191104/702208 (27%)]	Loss: 0.055386Train Epoch: 9 [192000/702208 (27%)]	Loss: 0.088661Train Epoch: 9 [192128/702208 (27%)]	Loss: 0.026263Train Epoch: 9 [193024/702208 (27%)]	Loss: 0.082624Train Epoch: 9 [194048/702208 (28%)]	Loss: 0.053796Train Epoch: 9 [195072/702208 (28%)]	Loss: 0.067303Train Epoch: 9 [196096/702208 (28%)]	Loss: 0.017647Train Epoch: 9 [197120/702208 (28%)]	Loss: 0.010249Train Epoch: 9 [198016/702208 (28%)]	Loss: 0.017882Train Epoch: 9 [199040/702208 (28%)]	Loss: 0.095197Train Epoch: 9 [200064/702208 (28%)]	Loss: 0.016245
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8072 / 8283] 97 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-5817728-total-98.31-class0-97.45-class1-99.89

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12461 / 12833] 97 %
Accuracy of the network on train loader class  1: [7106 / 7135] 99 %
Train Epoch: 9 [201088/702208 (29%)]	Loss: 0.046056Train Epoch: 9 [202112/702208 (29%)]	Loss: 0.043186Train Epoch: 9 [203008/702208 (29%)]	Loss: 0.016400Train Epoch: 9 [204032/702208 (29%)]	Loss: 0.011887Train Epoch: 9 [205056/702208 (29%)]	Loss: 0.007099Train Epoch: 9 [206080/702208 (29%)]	Loss: 0.051092Train Epoch: 9 [207104/702208 (29%)]	Loss: 0.059645Train Epoch: 9 [208000/702208 (30%)]	Loss: 0.014233Train Epoch: 9 [208128/702208 (30%)]	Loss: 0.032252Train Epoch: 9 [209024/702208 (30%)]	Loss: 0.077755Train Epoch: 9 [210048/702208 (30%)]	Loss: 0.019946Train Epoch: 9 [211072/702208 (30%)]	Loss: 0.067920Train Epoch: 9 [212096/702208 (30%)]	Loss: 0.064762Train Epoch: 9 [213120/702208 (30%)]	Loss: 0.041666Train Epoch: 9 [214016/702208 (30%)]	Loss: 0.032369Train Epoch: 9 [215040/702208 (31%)]	Loss: 0.093213Train Epoch: 9 [216064/702208 (31%)]	Loss: 0.016098Train Epoch: 9 [217088/702208 (31%)]	Loss: 0.025011Train Epoch: 9 [218112/702208 (31%)]	Loss: 0.031284Train Epoch: 9 [219008/702208 (31%)]	Loss: 0.074998Train Epoch: 9 [220032/702208 (31%)]	Loss: 0.035704Train Epoch: 9 [221056/702208 (31%)]	Loss: 0.047863Train Epoch: 9 [222080/702208 (32%)]	Loss: 0.063133Train Epoch: 9 [223104/702208 (32%)]	Loss: 0.107733Train Epoch: 9 [224000/702208 (32%)]	Loss: 0.050380Train Epoch: 9 [224128/702208 (32%)]	Loss: 0.066304Train Epoch: 9 [225024/702208 (32%)]	Loss: 0.063158
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8004 / 8283] 96 %
Accuracy of the network on test loader class  1: [4514 / 4517] 99 %

Writing model: iterations-5842688-total-97.8-class0-96.63000000000001-class1-99.92999999999999
Train Epoch: 9 [226048/702208 (32%)]	Loss: 0.055502Train Epoch: 9 [227072/702208 (32%)]	Loss: 0.026533Train Epoch: 9 [228096/702208 (32%)]	Loss: 0.053453Train Epoch: 9 [229120/702208 (33%)]	Loss: 0.013045Train Epoch: 9 [230016/702208 (33%)]	Loss: 0.041256Train Epoch: 9 [231040/702208 (33%)]	Loss: 0.018144Train Epoch: 9 [232064/702208 (33%)]	Loss: 0.058806Train Epoch: 9 [233088/702208 (33%)]	Loss: 0.063860Train Epoch: 9 [234112/702208 (33%)]	Loss: 0.045902Train Epoch: 9 [235008/702208 (33%)]	Loss: 0.040200Train Epoch: 9 [236032/702208 (34%)]	Loss: 0.009998Train Epoch: 9 [237056/702208 (34%)]	Loss: 0.045876Train Epoch: 9 [238080/702208 (34%)]	Loss: 0.083668Train Epoch: 9 [239104/702208 (34%)]	Loss: 0.006192Train Epoch: 9 [240000/702208 (34%)]	Loss: 0.035054Train Epoch: 9 [240128/702208 (34%)]	Loss: 0.060559Train Epoch: 9 [241024/702208 (34%)]	Loss: 0.101835Train Epoch: 9 [242048/702208 (34%)]	Loss: 0.014489Train Epoch: 9 [243072/702208 (35%)]	Loss: 0.033618Train Epoch: 9 [244096/702208 (35%)]	Loss: 0.111629Train Epoch: 9 [245120/702208 (35%)]	Loss: 0.019541Train Epoch: 9 [246016/702208 (35%)]	Loss: 0.023830Train Epoch: 9 [247040/702208 (35%)]	Loss: 0.021443Train Epoch: 9 [248064/702208 (35%)]	Loss: 0.006973Train Epoch: 9 [249088/702208 (35%)]	Loss: 0.034333Train Epoch: 9 [250112/702208 (36%)]	Loss: 0.025721
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8133 / 8283] 98 %
Accuracy of the network on test loader class  1: [4504 / 4517] 99 %

Writing model: iterations-5867776-total-98.72999999999999-class0-98.19-class1-99.71

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12388 / 12833] 96 %
Accuracy of the network on train loader class  1: [7109 / 7135] 99 %
Train Epoch: 9 [251008/702208 (36%)]	Loss: 0.038458Train Epoch: 9 [252032/702208 (36%)]	Loss: 0.025539Train Epoch: 9 [253056/702208 (36%)]	Loss: 0.043335Train Epoch: 9 [254080/702208 (36%)]	Loss: 0.073217Train Epoch: 9 [255104/702208 (36%)]	Loss: 0.089745Train Epoch: 9 [256000/702208 (36%)]	Loss: 0.053719Train Epoch: 9 [256128/702208 (36%)]	Loss: 0.065075Train Epoch: 9 [257024/702208 (37%)]	Loss: 0.022719Train Epoch: 9 [258048/702208 (37%)]	Loss: 0.019640Train Epoch: 9 [259072/702208 (37%)]	Loss: 0.024484Train Epoch: 9 [260096/702208 (37%)]	Loss: 0.027877Train Epoch: 9 [261120/702208 (37%)]	Loss: 0.051650Train Epoch: 9 [262016/702208 (37%)]	Loss: 0.031100Train Epoch: 9 [263040/702208 (37%)]	Loss: 0.079575Train Epoch: 9 [264064/702208 (38%)]	Loss: 0.183761Train Epoch: 9 [265088/702208 (38%)]	Loss: 0.044855Train Epoch: 9 [266112/702208 (38%)]	Loss: 0.049878Train Epoch: 9 [267008/702208 (38%)]	Loss: 0.026465Train Epoch: 9 [268032/702208 (38%)]	Loss: 0.012927Train Epoch: 9 [269056/702208 (38%)]	Loss: 0.095242Train Epoch: 9 [270080/702208 (38%)]	Loss: 0.044544Train Epoch: 9 [271104/702208 (39%)]	Loss: 0.026121Train Epoch: 9 [272000/702208 (39%)]	Loss: 0.038009Train Epoch: 9 [272128/702208 (39%)]	Loss: 0.087791Train Epoch: 9 [273024/702208 (39%)]	Loss: 0.028243Train Epoch: 9 [274048/702208 (39%)]	Loss: 0.082347Train Epoch: 9 [275072/702208 (39%)]	Loss: 0.025211
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8104 / 8283] 97 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-5892736-total-98.52-class0-97.84-class1-99.78
Train Epoch: 9 [276096/702208 (39%)]	Loss: 0.029647Train Epoch: 9 [277120/702208 (39%)]	Loss: 0.031369Train Epoch: 9 [278016/702208 (40%)]	Loss: 0.029119Train Epoch: 9 [279040/702208 (40%)]	Loss: 0.011170Train Epoch: 9 [280064/702208 (40%)]	Loss: 0.022323Train Epoch: 9 [281088/702208 (40%)]	Loss: 0.036808Train Epoch: 9 [282112/702208 (40%)]	Loss: 0.164333Train Epoch: 9 [283008/702208 (40%)]	Loss: 0.054264Train Epoch: 9 [284032/702208 (40%)]	Loss: 0.023864Train Epoch: 9 [285056/702208 (41%)]	Loss: 0.040133Train Epoch: 9 [286080/702208 (41%)]	Loss: 0.016938Train Epoch: 9 [287104/702208 (41%)]	Loss: 0.046035Train Epoch: 9 [288000/702208 (41%)]	Loss: 0.034176Train Epoch: 9 [288128/702208 (41%)]	Loss: 0.059760Train Epoch: 9 [289024/702208 (41%)]	Loss: 0.117485Train Epoch: 9 [290048/702208 (41%)]	Loss: 0.028942Train Epoch: 9 [291072/702208 (41%)]	Loss: 0.054327Train Epoch: 9 [292096/702208 (42%)]	Loss: 0.023709Train Epoch: 9 [293120/702208 (42%)]	Loss: 0.013595Train Epoch: 9 [294016/702208 (42%)]	Loss: 0.073540Train Epoch: 9 [295040/702208 (42%)]	Loss: 0.043414Train Epoch: 9 [296064/702208 (42%)]	Loss: 0.040774Train Epoch: 9 [297088/702208 (42%)]	Loss: 0.033357Train Epoch: 9 [298112/702208 (42%)]	Loss: 0.036976Train Epoch: 9 [299008/702208 (43%)]	Loss: 0.018324Train Epoch: 9 [300032/702208 (43%)]	Loss: 0.064501
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8061 / 8283] 97 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-5917696-total-98.22999999999999-class0-97.32-class1-99.89

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12352 / 12833] 96 %
Accuracy of the network on train loader class  1: [7111 / 7135] 99 %
Train Epoch: 9 [301056/702208 (43%)]	Loss: 0.039901Train Epoch: 9 [302080/702208 (43%)]	Loss: 0.043670Train Epoch: 9 [303104/702208 (43%)]	Loss: 0.120463Train Epoch: 9 [304000/702208 (43%)]	Loss: 0.051244Train Epoch: 9 [304128/702208 (43%)]	Loss: 0.021535Train Epoch: 9 [305024/702208 (43%)]	Loss: 0.027190Train Epoch: 9 [306048/702208 (44%)]	Loss: 0.021229Train Epoch: 9 [307072/702208 (44%)]	Loss: 0.048897Train Epoch: 9 [308096/702208 (44%)]	Loss: 0.018507Train Epoch: 9 [309120/702208 (44%)]	Loss: 0.037273Train Epoch: 9 [310016/702208 (44%)]	Loss: 0.041731Train Epoch: 9 [311040/702208 (44%)]	Loss: 0.080890Train Epoch: 9 [312064/702208 (44%)]	Loss: 0.081185Train Epoch: 9 [313088/702208 (45%)]	Loss: 0.049430Train Epoch: 9 [314112/702208 (45%)]	Loss: 0.053811Train Epoch: 9 [315008/702208 (45%)]	Loss: 0.027968Train Epoch: 9 [316032/702208 (45%)]	Loss: 0.048030Train Epoch: 9 [317056/702208 (45%)]	Loss: 0.057650Train Epoch: 9 [318080/702208 (45%)]	Loss: 0.012016Train Epoch: 9 [319104/702208 (45%)]	Loss: 0.032965Train Epoch: 9 [320000/702208 (46%)]	Loss: 0.113263Train Epoch: 9 [320128/702208 (46%)]	Loss: 0.035729Train Epoch: 9 [321024/702208 (46%)]	Loss: 0.012873Train Epoch: 9 [322048/702208 (46%)]	Loss: 0.028267Train Epoch: 9 [323072/702208 (46%)]	Loss: 0.022324Train Epoch: 9 [324096/702208 (46%)]	Loss: 0.033062Train Epoch: 9 [325120/702208 (46%)]	Loss: 0.054377
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8054 / 8283] 97 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-5942784-total-98.18-class0-97.24000000000001-class1-99.91
Train Epoch: 9 [326016/702208 (46%)]	Loss: 0.013503Train Epoch: 9 [327040/702208 (47%)]	Loss: 0.048003Train Epoch: 9 [328064/702208 (47%)]	Loss: 0.079925Train Epoch: 9 [329088/702208 (47%)]	Loss: 0.043882Train Epoch: 9 [330112/702208 (47%)]	Loss: 0.031309Train Epoch: 9 [331008/702208 (47%)]	Loss: 0.078554Train Epoch: 9 [332032/702208 (47%)]	Loss: 0.022618Train Epoch: 9 [333056/702208 (47%)]	Loss: 0.033379Train Epoch: 9 [334080/702208 (48%)]	Loss: 0.025232Train Epoch: 9 [335104/702208 (48%)]	Loss: 0.119587Train Epoch: 9 [336000/702208 (48%)]	Loss: 0.083482Train Epoch: 9 [336128/702208 (48%)]	Loss: 0.065412Train Epoch: 9 [337024/702208 (48%)]	Loss: 0.050431Train Epoch: 9 [338048/702208 (48%)]	Loss: 0.067479Train Epoch: 9 [339072/702208 (48%)]	Loss: 0.060486Train Epoch: 9 [340096/702208 (48%)]	Loss: 0.031539Train Epoch: 9 [341120/702208 (49%)]	Loss: 0.012836Train Epoch: 9 [342016/702208 (49%)]	Loss: 0.088047Train Epoch: 9 [343040/702208 (49%)]	Loss: 0.046039Train Epoch: 9 [344064/702208 (49%)]	Loss: 0.061721Train Epoch: 9 [345088/702208 (49%)]	Loss: 0.050998Train Epoch: 9 [346112/702208 (49%)]	Loss: 0.031473Train Epoch: 9 [347008/702208 (49%)]	Loss: 0.031943Train Epoch: 9 [348032/702208 (50%)]	Loss: 0.041417Train Epoch: 9 [349056/702208 (50%)]	Loss: 0.060544Train Epoch: 9 [350080/702208 (50%)]	Loss: 0.080627
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7948 / 8283] 95 %
Accuracy of the network on test loader class  1: [4517 / 4517] 100 %

Writing model: iterations-5967744-total-97.38-class0-95.96000000000001-class1-100.0

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12356 / 12833] 96 %
Accuracy of the network on train loader class  1: [7110 / 7135] 99 %
Train Epoch: 9 [351104/702208 (50%)]	Loss: 0.053388Train Epoch: 9 [352000/702208 (50%)]	Loss: 0.054304Train Epoch: 9 [352128/702208 (50%)]	Loss: 0.069474Train Epoch: 9 [353024/702208 (50%)]	Loss: 0.046636Train Epoch: 9 [354048/702208 (50%)]	Loss: 0.048913Train Epoch: 9 [355072/702208 (51%)]	Loss: 0.065739Train Epoch: 9 [356096/702208 (51%)]	Loss: 0.078847Train Epoch: 9 [357120/702208 (51%)]	Loss: 0.034158Train Epoch: 9 [358016/702208 (51%)]	Loss: 0.045947Train Epoch: 9 [359040/702208 (51%)]	Loss: 0.024566Train Epoch: 9 [360064/702208 (51%)]	Loss: 0.032461Train Epoch: 9 [361088/702208 (51%)]	Loss: 0.053537Train Epoch: 9 [362112/702208 (52%)]	Loss: 0.031036Train Epoch: 9 [363008/702208 (52%)]	Loss: 0.039873Train Epoch: 9 [364032/702208 (52%)]	Loss: 0.048401Train Epoch: 9 [365056/702208 (52%)]	Loss: 0.043542Train Epoch: 9 [366080/702208 (52%)]	Loss: 0.031305Train Epoch: 9 [367104/702208 (52%)]	Loss: 0.012934Train Epoch: 9 [368000/702208 (52%)]	Loss: 0.039985Train Epoch: 9 [368128/702208 (52%)]	Loss: 0.087411Train Epoch: 9 [369024/702208 (53%)]	Loss: 0.042395Train Epoch: 9 [370048/702208 (53%)]	Loss: 0.045153Train Epoch: 9 [371072/702208 (53%)]	Loss: 0.066910Train Epoch: 9 [372096/702208 (53%)]	Loss: 0.024021Train Epoch: 9 [373120/702208 (53%)]	Loss: 0.105976Train Epoch: 9 [374016/702208 (53%)]	Loss: 0.082016Train Epoch: 9 [375040/702208 (53%)]	Loss: 0.015301
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8107 / 8283] 97 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-5992704-total-98.55000000000001-class0-97.88-class1-99.78
Train Epoch: 9 [376064/702208 (54%)]	Loss: 0.122652Train Epoch: 9 [377088/702208 (54%)]	Loss: 0.019613Train Epoch: 9 [378112/702208 (54%)]	Loss: 0.029651Train Epoch: 9 [379008/702208 (54%)]	Loss: 0.014246Train Epoch: 9 [380032/702208 (54%)]	Loss: 0.023879Train Epoch: 9 [381056/702208 (54%)]	Loss: 0.007095Train Epoch: 9 [382080/702208 (54%)]	Loss: 0.028290Train Epoch: 9 [383104/702208 (55%)]	Loss: 0.052760Train Epoch: 9 [384000/702208 (55%)]	Loss: 0.031428Train Epoch: 9 [384128/702208 (55%)]	Loss: 0.026446Train Epoch: 9 [385024/702208 (55%)]	Loss: 0.101961Train Epoch: 9 [386048/702208 (55%)]	Loss: 0.069464Train Epoch: 9 [387072/702208 (55%)]	Loss: 0.021209Train Epoch: 9 [388096/702208 (55%)]	Loss: 0.045406Train Epoch: 9 [389120/702208 (55%)]	Loss: 0.021190Train Epoch: 9 [390016/702208 (56%)]	Loss: 0.040433Train Epoch: 9 [391040/702208 (56%)]	Loss: 0.041568Train Epoch: 9 [392064/702208 (56%)]	Loss: 0.081369Train Epoch: 9 [393088/702208 (56%)]	Loss: 0.064912Train Epoch: 9 [394112/702208 (56%)]	Loss: 0.040546Train Epoch: 9 [395008/702208 (56%)]	Loss: 0.033102Train Epoch: 9 [396032/702208 (56%)]	Loss: 0.078683Train Epoch: 9 [397056/702208 (57%)]	Loss: 0.021156Train Epoch: 9 [398080/702208 (57%)]	Loss: 0.031863Train Epoch: 9 [399104/702208 (57%)]	Loss: 0.027566Train Epoch: 9 [400000/702208 (57%)]	Loss: 0.030191
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8074 / 8283] 97 %
Accuracy of the network on test loader class  1: [4514 / 4517] 99 %

Writing model: iterations-6017664-total-98.34-class0-97.48-class1-99.92999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12397 / 12833] 96 %
Accuracy of the network on train loader class  1: [7102 / 7135] 99 %
Train Epoch: 9 [400128/702208 (57%)]	Loss: 0.020411
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8032 / 8283] 96 %
Accuracy of the network on test loader class  1: [4514 / 4517] 99 %

Writing model: iterations-6017792-total-98.02-class0-96.97-class1-99.92999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12369 / 12833] 96 %
Accuracy of the network on train loader class  1: [7104 / 7135] 99 %
Train Epoch: 9 [401024/702208 (57%)]	Loss: 0.030071Train Epoch: 9 [402048/702208 (57%)]	Loss: 0.106650Train Epoch: 9 [403072/702208 (57%)]	Loss: 0.014247Train Epoch: 9 [404096/702208 (58%)]	Loss: 0.067839Train Epoch: 9 [405120/702208 (58%)]	Loss: 0.060603Train Epoch: 9 [406016/702208 (58%)]	Loss: 0.021412Train Epoch: 9 [407040/702208 (58%)]	Loss: 0.070539Train Epoch: 9 [408064/702208 (58%)]	Loss: 0.127888Train Epoch: 9 [409088/702208 (58%)]	Loss: 0.041299Train Epoch: 9 [410112/702208 (58%)]	Loss: 0.040872Train Epoch: 9 [411008/702208 (59%)]	Loss: 0.042544Train Epoch: 9 [412032/702208 (59%)]	Loss: 0.228527Train Epoch: 9 [413056/702208 (59%)]	Loss: 0.029623Train Epoch: 9 [414080/702208 (59%)]	Loss: 0.063622Train Epoch: 9 [415104/702208 (59%)]	Loss: 0.007520Train Epoch: 9 [416000/702208 (59%)]	Loss: 0.015334Train Epoch: 9 [416128/702208 (59%)]	Loss: 0.073707Train Epoch: 9 [417024/702208 (59%)]	Loss: 0.016515Train Epoch: 9 [418048/702208 (60%)]	Loss: 0.010585Train Epoch: 9 [419072/702208 (60%)]	Loss: 0.029235Train Epoch: 9 [420096/702208 (60%)]	Loss: 0.069772Train Epoch: 9 [421120/702208 (60%)]	Loss: 0.045321Train Epoch: 9 [422016/702208 (60%)]	Loss: 0.142139Train Epoch: 9 [423040/702208 (60%)]	Loss: 0.012372Train Epoch: 9 [424064/702208 (60%)]	Loss: 0.052712Train Epoch: 9 [425088/702208 (61%)]	Loss: 0.070714
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8085 / 8283] 97 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-6042752-total-98.41-class0-97.61-class1-99.87
Train Epoch: 9 [426112/702208 (61%)]	Loss: 0.043954Train Epoch: 9 [427008/702208 (61%)]	Loss: 0.028826Train Epoch: 9 [428032/702208 (61%)]	Loss: 0.038628Train Epoch: 9 [429056/702208 (61%)]	Loss: 0.014801Train Epoch: 9 [430080/702208 (61%)]	Loss: 0.016794Train Epoch: 9 [431104/702208 (61%)]	Loss: 0.179098Train Epoch: 9 [432000/702208 (62%)]	Loss: 0.067813Train Epoch: 9 [432128/702208 (62%)]	Loss: 0.054241Train Epoch: 9 [433024/702208 (62%)]	Loss: 0.060069Train Epoch: 9 [434048/702208 (62%)]	Loss: 0.049102Train Epoch: 9 [435072/702208 (62%)]	Loss: 0.050895Train Epoch: 9 [436096/702208 (62%)]	Loss: 0.035000Train Epoch: 9 [437120/702208 (62%)]	Loss: 0.011122Train Epoch: 9 [438016/702208 (62%)]	Loss: 0.034496Train Epoch: 9 [439040/702208 (63%)]	Loss: 0.015381Train Epoch: 9 [440064/702208 (63%)]	Loss: 0.024572Train Epoch: 9 [441088/702208 (63%)]	Loss: 0.064521Train Epoch: 9 [442112/702208 (63%)]	Loss: 0.033777Train Epoch: 9 [443008/702208 (63%)]	Loss: 0.036740Train Epoch: 9 [444032/702208 (63%)]	Loss: 0.039421Train Epoch: 9 [445056/702208 (63%)]	Loss: 0.079946Train Epoch: 9 [446080/702208 (64%)]	Loss: 0.042957Train Epoch: 9 [447104/702208 (64%)]	Loss: 0.063478Train Epoch: 9 [448000/702208 (64%)]	Loss: 0.083551Train Epoch: 9 [448128/702208 (64%)]	Loss: 0.022405Train Epoch: 9 [449024/702208 (64%)]	Loss: 0.046368Train Epoch: 9 [450048/702208 (64%)]	Loss: 0.055680
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8027 / 8283] 96 %
Accuracy of the network on test loader class  1: [4516 / 4517] 99 %

Writing model: iterations-6067712-total-97.99-class0-96.91-class1-99.98

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12330 / 12833] 96 %
Accuracy of the network on train loader class  1: [7116 / 7135] 99 %
Train Epoch: 9 [451072/702208 (64%)]	Loss: 0.037847Train Epoch: 9 [452096/702208 (64%)]	Loss: 0.024468Train Epoch: 9 [453120/702208 (65%)]	Loss: 0.039448Train Epoch: 9 [454016/702208 (65%)]	Loss: 0.035428Train Epoch: 9 [455040/702208 (65%)]	Loss: 0.099518Train Epoch: 9 [456064/702208 (65%)]	Loss: 0.039622Train Epoch: 9 [457088/702208 (65%)]	Loss: 0.029883Train Epoch: 9 [458112/702208 (65%)]	Loss: 0.049941Train Epoch: 9 [459008/702208 (65%)]	Loss: 0.058330Train Epoch: 9 [460032/702208 (66%)]	Loss: 0.034394Train Epoch: 9 [461056/702208 (66%)]	Loss: 0.036753Train Epoch: 9 [462080/702208 (66%)]	Loss: 0.030927Train Epoch: 9 [463104/702208 (66%)]	Loss: 0.016421Train Epoch: 9 [464000/702208 (66%)]	Loss: 0.060071Train Epoch: 9 [464128/702208 (66%)]	Loss: 0.042605Train Epoch: 9 [465024/702208 (66%)]	Loss: 0.037541Train Epoch: 9 [466048/702208 (66%)]	Loss: 0.017709Train Epoch: 9 [467072/702208 (67%)]	Loss: 0.110278Train Epoch: 9 [468096/702208 (67%)]	Loss: 0.049051Train Epoch: 9 [469120/702208 (67%)]	Loss: 0.034429Train Epoch: 9 [470016/702208 (67%)]	Loss: 0.113170Train Epoch: 9 [471040/702208 (67%)]	Loss: 0.085875Train Epoch: 9 [472064/702208 (67%)]	Loss: 0.051348Train Epoch: 9 [473088/702208 (67%)]	Loss: 0.054466Train Epoch: 9 [474112/702208 (68%)]	Loss: 0.037889Train Epoch: 9 [475008/702208 (68%)]	Loss: 0.019441
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8122 / 8283] 98 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-6092672-total-98.65-class0-98.06-class1-99.72999999999999
Train Epoch: 9 [476032/702208 (68%)]	Loss: 0.050029Train Epoch: 9 [477056/702208 (68%)]	Loss: 0.056894Train Epoch: 9 [478080/702208 (68%)]	Loss: 0.013243Train Epoch: 9 [479104/702208 (68%)]	Loss: 0.084590Train Epoch: 9 [480000/702208 (68%)]	Loss: 0.081867Train Epoch: 9 [480128/702208 (68%)]	Loss: 0.084808Train Epoch: 9 [481024/702208 (69%)]	Loss: 0.015630Train Epoch: 9 [482048/702208 (69%)]	Loss: 0.049646Train Epoch: 9 [483072/702208 (69%)]	Loss: 0.039705Train Epoch: 9 [484096/702208 (69%)]	Loss: 0.019016Train Epoch: 9 [485120/702208 (69%)]	Loss: 0.076475Train Epoch: 9 [486016/702208 (69%)]	Loss: 0.016267Train Epoch: 9 [487040/702208 (69%)]	Loss: 0.032385Train Epoch: 9 [488064/702208 (70%)]	Loss: 0.036264Train Epoch: 9 [489088/702208 (70%)]	Loss: 0.038992Train Epoch: 9 [490112/702208 (70%)]	Loss: 0.061469Train Epoch: 9 [491008/702208 (70%)]	Loss: 0.063273Train Epoch: 9 [492032/702208 (70%)]	Loss: 0.061579Train Epoch: 9 [493056/702208 (70%)]	Loss: 0.032279Train Epoch: 9 [494080/702208 (70%)]	Loss: 0.065468Train Epoch: 9 [495104/702208 (71%)]	Loss: 0.020500Train Epoch: 9 [496000/702208 (71%)]	Loss: 0.016084Train Epoch: 9 [496128/702208 (71%)]	Loss: 0.028591Train Epoch: 9 [497024/702208 (71%)]	Loss: 0.054642Train Epoch: 9 [498048/702208 (71%)]	Loss: 0.021023Train Epoch: 9 [499072/702208 (71%)]	Loss: 0.047241Train Epoch: 9 [500096/702208 (71%)]	Loss: 0.021776
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8104 / 8283] 97 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-6117760-total-98.52-class0-97.84-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12389 / 12833] 96 %
Accuracy of the network on train loader class  1: [7110 / 7135] 99 %
Train Epoch: 9 [501120/702208 (71%)]	Loss: 0.028654Train Epoch: 9 [502016/702208 (71%)]	Loss: 0.042447Train Epoch: 9 [503040/702208 (72%)]	Loss: 0.074267Train Epoch: 9 [504064/702208 (72%)]	Loss: 0.032176Train Epoch: 9 [505088/702208 (72%)]	Loss: 0.023526Train Epoch: 9 [506112/702208 (72%)]	Loss: 0.049776Train Epoch: 9 [507008/702208 (72%)]	Loss: 0.058569Train Epoch: 9 [508032/702208 (72%)]	Loss: 0.026507Train Epoch: 9 [509056/702208 (72%)]	Loss: 0.037345Train Epoch: 9 [510080/702208 (73%)]	Loss: 0.031694Train Epoch: 9 [511104/702208 (73%)]	Loss: 0.037687Train Epoch: 9 [512000/702208 (73%)]	Loss: 0.017227Train Epoch: 9 [512128/702208 (73%)]	Loss: 0.037652Train Epoch: 9 [513024/702208 (73%)]	Loss: 0.029747Train Epoch: 9 [514048/702208 (73%)]	Loss: 0.051574Train Epoch: 9 [515072/702208 (73%)]	Loss: 0.028439Train Epoch: 9 [516096/702208 (73%)]	Loss: 0.062573Train Epoch: 9 [517120/702208 (74%)]	Loss: 0.019428Train Epoch: 9 [518016/702208 (74%)]	Loss: 0.012956Train Epoch: 9 [519040/702208 (74%)]	Loss: 0.060880Train Epoch: 9 [520064/702208 (74%)]	Loss: 0.095000Train Epoch: 9 [521088/702208 (74%)]	Loss: 0.022028Train Epoch: 9 [522112/702208 (74%)]	Loss: 0.019444Train Epoch: 9 [523008/702208 (74%)]	Loss: 0.023999Train Epoch: 9 [524032/702208 (75%)]	Loss: 0.049582Train Epoch: 9 [525056/702208 (75%)]	Loss: 0.041884
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7972 / 8283] 96 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-6142720-total-97.53-class0-96.25-class1-99.89
Train Epoch: 9 [526080/702208 (75%)]	Loss: 0.058633Train Epoch: 9 [527104/702208 (75%)]	Loss: 0.020299Train Epoch: 9 [528000/702208 (75%)]	Loss: 0.054741Train Epoch: 9 [528128/702208 (75%)]	Loss: 0.014900Train Epoch: 9 [529024/702208 (75%)]	Loss: 0.040138Train Epoch: 9 [530048/702208 (75%)]	Loss: 0.048070Train Epoch: 9 [531072/702208 (76%)]	Loss: 0.022314Train Epoch: 9 [532096/702208 (76%)]	Loss: 0.084897Train Epoch: 9 [533120/702208 (76%)]	Loss: 0.024117Train Epoch: 9 [534016/702208 (76%)]	Loss: 0.044680Train Epoch: 9 [535040/702208 (76%)]	Loss: 0.062646Train Epoch: 9 [536064/702208 (76%)]	Loss: 0.026291Train Epoch: 9 [537088/702208 (76%)]	Loss: 0.040237Train Epoch: 9 [538112/702208 (77%)]	Loss: 0.080862Train Epoch: 9 [539008/702208 (77%)]	Loss: 0.086810Train Epoch: 9 [540032/702208 (77%)]	Loss: 0.021447Train Epoch: 9 [541056/702208 (77%)]	Loss: 0.028317Train Epoch: 9 [542080/702208 (77%)]	Loss: 0.030234Train Epoch: 9 [543104/702208 (77%)]	Loss: 0.066386Train Epoch: 9 [544000/702208 (77%)]	Loss: 0.095420Train Epoch: 9 [544128/702208 (77%)]	Loss: 0.081427Train Epoch: 9 [545024/702208 (78%)]	Loss: 0.034387Train Epoch: 9 [546048/702208 (78%)]	Loss: 0.032784Train Epoch: 9 [547072/702208 (78%)]	Loss: 0.061408Train Epoch: 9 [548096/702208 (78%)]	Loss: 0.023107Train Epoch: 9 [549120/702208 (78%)]	Loss: 0.074627Train Epoch: 9 [550016/702208 (78%)]	Loss: 0.041865
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8116 / 8283] 97 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-6167680-total-98.6-class0-97.98-class1-99.72999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12351 / 12833] 96 %
Accuracy of the network on train loader class  1: [6890 / 7135] 96 %
Train Epoch: 9 [551040/702208 (78%)]	Loss: 0.021298Train Epoch: 9 [552064/702208 (79%)]	Loss: 0.023339Train Epoch: 9 [553088/702208 (79%)]	Loss: 0.050787Train Epoch: 9 [554112/702208 (79%)]	Loss: 0.055099Train Epoch: 9 [555008/702208 (79%)]	Loss: 0.020750Train Epoch: 9 [556032/702208 (79%)]	Loss: 0.085246Train Epoch: 9 [557056/702208 (79%)]	Loss: 0.068693Train Epoch: 9 [558080/702208 (79%)]	Loss: 0.049810Train Epoch: 9 [559104/702208 (80%)]	Loss: 0.049241Train Epoch: 9 [560000/702208 (80%)]	Loss: 0.023180Train Epoch: 9 [560128/702208 (80%)]	Loss: 0.022646Train Epoch: 9 [561024/702208 (80%)]	Loss: 0.085909Train Epoch: 9 [562048/702208 (80%)]	Loss: 0.034583Train Epoch: 9 [563072/702208 (80%)]	Loss: 0.035223Train Epoch: 9 [564096/702208 (80%)]	Loss: 0.087135Train Epoch: 9 [565120/702208 (80%)]	Loss: 0.070239Train Epoch: 9 [566016/702208 (81%)]	Loss: 0.058122Train Epoch: 9 [567040/702208 (81%)]	Loss: 0.018667Train Epoch: 9 [568064/702208 (81%)]	Loss: 0.029000Train Epoch: 9 [569088/702208 (81%)]	Loss: 0.045113Train Epoch: 9 [570112/702208 (81%)]	Loss: 0.053626Train Epoch: 9 [571008/702208 (81%)]	Loss: 0.027910Train Epoch: 9 [572032/702208 (81%)]	Loss: 0.034784Train Epoch: 9 [573056/702208 (82%)]	Loss: 0.050925Train Epoch: 9 [574080/702208 (82%)]	Loss: 0.098982Train Epoch: 9 [575104/702208 (82%)]	Loss: 0.020922
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8140 / 8283] 98 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-6192768-total-98.79-class0-98.27-class1-99.72999999999999
Train Epoch: 9 [576000/702208 (82%)]	Loss: 0.069774Train Epoch: 9 [576128/702208 (82%)]	Loss: 0.016626Train Epoch: 9 [577024/702208 (82%)]	Loss: 0.054207Train Epoch: 9 [578048/702208 (82%)]	Loss: 0.051607Train Epoch: 9 [579072/702208 (82%)]	Loss: 0.048985Train Epoch: 9 [580096/702208 (83%)]	Loss: 0.118377Train Epoch: 9 [581120/702208 (83%)]	Loss: 0.049469Train Epoch: 9 [582016/702208 (83%)]	Loss: 0.127312Train Epoch: 9 [583040/702208 (83%)]	Loss: 0.012393Train Epoch: 9 [584064/702208 (83%)]	Loss: 0.022761Train Epoch: 9 [585088/702208 (83%)]	Loss: 0.029612Train Epoch: 9 [586112/702208 (83%)]	Loss: 0.015953Train Epoch: 9 [587008/702208 (84%)]	Loss: 0.087337Train Epoch: 9 [588032/702208 (84%)]	Loss: 0.139357Train Epoch: 9 [589056/702208 (84%)]	Loss: 0.047960Train Epoch: 9 [590080/702208 (84%)]	Loss: 0.032019Train Epoch: 9 [591104/702208 (84%)]	Loss: 0.049790Train Epoch: 9 [592000/702208 (84%)]	Loss: 0.077719Train Epoch: 9 [592128/702208 (84%)]	Loss: 0.077379Train Epoch: 9 [593024/702208 (84%)]	Loss: 0.057548Train Epoch: 9 [594048/702208 (85%)]	Loss: 0.048565Train Epoch: 9 [595072/702208 (85%)]	Loss: 0.088419Train Epoch: 9 [596096/702208 (85%)]	Loss: 0.096871Train Epoch: 9 [597120/702208 (85%)]	Loss: 0.065661Train Epoch: 9 [598016/702208 (85%)]	Loss: 0.063847Train Epoch: 9 [599040/702208 (85%)]	Loss: 0.048302Train Epoch: 9 [600064/702208 (85%)]	Loss: 0.234429
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8011 / 8283] 96 %
Accuracy of the network on test loader class  1: [4517 / 4517] 100 %

Writing model: iterations-6217728-total-97.88-class0-96.72-class1-100.0

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12425 / 12833] 96 %
Accuracy of the network on train loader class  1: [7100 / 7135] 99 %
Train Epoch: 9 [601088/702208 (86%)]	Loss: 0.018775Train Epoch: 9 [602112/702208 (86%)]	Loss: 0.073860Train Epoch: 9 [603008/702208 (86%)]	Loss: 0.044922Train Epoch: 9 [604032/702208 (86%)]	Loss: 0.049077Train Epoch: 9 [605056/702208 (86%)]	Loss: 0.045902Train Epoch: 9 [606080/702208 (86%)]	Loss: 0.043875Train Epoch: 9 [607104/702208 (86%)]	Loss: 0.155413Train Epoch: 9 [608000/702208 (87%)]	Loss: 0.029152Train Epoch: 9 [608128/702208 (87%)]	Loss: 0.080603Train Epoch: 9 [609024/702208 (87%)]	Loss: 0.064513Train Epoch: 9 [610048/702208 (87%)]	Loss: 0.014614Train Epoch: 9 [611072/702208 (87%)]	Loss: 0.030609Train Epoch: 9 [612096/702208 (87%)]	Loss: 0.021983Train Epoch: 9 [613120/702208 (87%)]	Loss: 0.026053Train Epoch: 9 [614016/702208 (87%)]	Loss: 0.015837Train Epoch: 9 [615040/702208 (88%)]	Loss: 0.103944Train Epoch: 9 [616064/702208 (88%)]	Loss: 0.048067Train Epoch: 9 [617088/702208 (88%)]	Loss: 0.045109Train Epoch: 9 [618112/702208 (88%)]	Loss: 0.076287Train Epoch: 9 [619008/702208 (88%)]	Loss: 0.045257Train Epoch: 9 [620032/702208 (88%)]	Loss: 0.036251Train Epoch: 9 [621056/702208 (88%)]	Loss: 0.070023Train Epoch: 9 [622080/702208 (89%)]	Loss: 0.049643Train Epoch: 9 [623104/702208 (89%)]	Loss: 0.027054Train Epoch: 9 [624000/702208 (89%)]	Loss: 0.036812Train Epoch: 9 [624128/702208 (89%)]	Loss: 0.056407Train Epoch: 9 [625024/702208 (89%)]	Loss: 0.017603
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8067 / 8283] 97 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-6242688-total-98.27-class0-97.39-class1-99.87
Train Epoch: 9 [626048/702208 (89%)]	Loss: 0.058894Train Epoch: 9 [627072/702208 (89%)]	Loss: 0.019700Train Epoch: 9 [628096/702208 (89%)]	Loss: 0.082839Train Epoch: 9 [629120/702208 (90%)]	Loss: 0.008996Train Epoch: 9 [630016/702208 (90%)]	Loss: 0.084864Train Epoch: 9 [631040/702208 (90%)]	Loss: 0.007041Train Epoch: 9 [632064/702208 (90%)]	Loss: 0.072214Train Epoch: 9 [633088/702208 (90%)]	Loss: 0.080760Train Epoch: 9 [634112/702208 (90%)]	Loss: 0.031472Train Epoch: 9 [635008/702208 (90%)]	Loss: 0.061552Train Epoch: 9 [636032/702208 (91%)]	Loss: 0.025913Train Epoch: 9 [637056/702208 (91%)]	Loss: 0.066696Train Epoch: 9 [638080/702208 (91%)]	Loss: 0.025389Train Epoch: 9 [639104/702208 (91%)]	Loss: 0.026013Train Epoch: 9 [640000/702208 (91%)]	Loss: 0.055180Train Epoch: 9 [640128/702208 (91%)]	Loss: 0.044922Train Epoch: 9 [641024/702208 (91%)]	Loss: 0.034959Train Epoch: 9 [642048/702208 (91%)]	Loss: 0.088286Train Epoch: 9 [643072/702208 (92%)]	Loss: 0.031439Train Epoch: 9 [644096/702208 (92%)]	Loss: 0.079164Train Epoch: 9 [645120/702208 (92%)]	Loss: 0.109678Train Epoch: 9 [646016/702208 (92%)]	Loss: 0.065376Train Epoch: 9 [647040/702208 (92%)]	Loss: 0.073314Train Epoch: 9 [648064/702208 (92%)]	Loss: 0.045951Train Epoch: 9 [649088/702208 (92%)]	Loss: 0.047267Train Epoch: 9 [650112/702208 (93%)]	Loss: 0.043519
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8132 / 8283] 98 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %

Writing model: iterations-6267776-total-98.7-class0-98.18-class1-99.67

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12342 / 12833] 96 %
Accuracy of the network on train loader class  1: [7110 / 7135] 99 %
Train Epoch: 9 [651008/702208 (93%)]	Loss: 0.019297Train Epoch: 9 [652032/702208 (93%)]	Loss: 0.019700Train Epoch: 9 [653056/702208 (93%)]	Loss: 0.032055Train Epoch: 9 [654080/702208 (93%)]	Loss: 0.011790Train Epoch: 9 [655104/702208 (93%)]	Loss: 0.040740Train Epoch: 9 [656000/702208 (93%)]	Loss: 0.049337Train Epoch: 9 [656128/702208 (93%)]	Loss: 0.082118Train Epoch: 9 [657024/702208 (94%)]	Loss: 0.056242Train Epoch: 9 [658048/702208 (94%)]	Loss: 0.010686Train Epoch: 9 [659072/702208 (94%)]	Loss: 0.039642Train Epoch: 9 [660096/702208 (94%)]	Loss: 0.028764Train Epoch: 9 [661120/702208 (94%)]	Loss: 0.040882Train Epoch: 9 [662016/702208 (94%)]	Loss: 0.107137Train Epoch: 9 [663040/702208 (94%)]	Loss: 0.021759Train Epoch: 9 [664064/702208 (95%)]	Loss: 0.026487Train Epoch: 9 [665088/702208 (95%)]	Loss: 0.022621Train Epoch: 9 [666112/702208 (95%)]	Loss: 0.087382Train Epoch: 9 [667008/702208 (95%)]	Loss: 0.024475Train Epoch: 9 [668032/702208 (95%)]	Loss: 0.064513Train Epoch: 9 [669056/702208 (95%)]	Loss: 0.021835Train Epoch: 9 [670080/702208 (95%)]	Loss: 0.036189Train Epoch: 9 [671104/702208 (96%)]	Loss: 0.058736Train Epoch: 9 [672000/702208 (96%)]	Loss: 0.061281Train Epoch: 9 [672128/702208 (96%)]	Loss: 0.023987Train Epoch: 9 [673024/702208 (96%)]	Loss: 0.012328Train Epoch: 9 [674048/702208 (96%)]	Loss: 0.050554Train Epoch: 9 [675072/702208 (96%)]	Loss: 0.036028
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8110 / 8283] 97 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-6292736-total-98.59-class0-97.91-class1-99.82
Train Epoch: 9 [676096/702208 (96%)]	Loss: 0.030286Train Epoch: 9 [677120/702208 (96%)]	Loss: 0.009247Train Epoch: 9 [678016/702208 (97%)]	Loss: 0.083586Train Epoch: 9 [679040/702208 (97%)]	Loss: 0.071852Train Epoch: 9 [680064/702208 (97%)]	Loss: 0.009772Train Epoch: 9 [681088/702208 (97%)]	Loss: 0.035142Train Epoch: 9 [682112/702208 (97%)]	Loss: 0.034520Train Epoch: 9 [683008/702208 (97%)]	Loss: 0.064690Train Epoch: 9 [684032/702208 (97%)]	Loss: 0.025551Train Epoch: 9 [685056/702208 (98%)]	Loss: 0.204530Train Epoch: 9 [686080/702208 (98%)]	Loss: 0.046508Train Epoch: 9 [687104/702208 (98%)]	Loss: 0.025483Train Epoch: 9 [688000/702208 (98%)]	Loss: 0.017703Train Epoch: 9 [688128/702208 (98%)]	Loss: 0.060760Train Epoch: 9 [689024/702208 (98%)]	Loss: 0.021818Train Epoch: 9 [690048/702208 (98%)]	Loss: 0.028354Train Epoch: 9 [691072/702208 (98%)]	Loss: 0.076677Train Epoch: 9 [692096/702208 (99%)]	Loss: 0.116797Train Epoch: 9 [693120/702208 (99%)]	Loss: 0.037378Train Epoch: 9 [694016/702208 (99%)]	Loss: 0.024091Train Epoch: 9 [695040/702208 (99%)]	Loss: 0.029911Train Epoch: 9 [696064/702208 (99%)]	Loss: 0.040920Train Epoch: 9 [697088/702208 (99%)]	Loss: 0.097803Train Epoch: 9 [698112/702208 (99%)]	Loss: 0.059641Train Epoch: 9 [699008/702208 (100%)]	Loss: 0.020847Train Epoch: 9 [700032/702208 (100%)]	Loss: 0.053057
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8090 / 8283] 97 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-6317696-total-98.41-class0-97.67-class1-99.78

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12351 / 12833] 96 %
Accuracy of the network on train loader class  1: [7115 / 7135] 99 %
Train Epoch: 9 [701056/702208 (100%)]	Loss: 0.023152Train Epoch: 9 [702080/702208 (100%)]	Loss: 0.014564
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7942 / 8283] 95 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %
Train Epoch: 10 [1024/702208 (0%)]	Loss: 0.064988Train Epoch: 10 [2048/702208 (0%)]	Loss: 0.023802Train Epoch: 10 [3072/702208 (0%)]	Loss: 0.057058Train Epoch: 10 [4096/702208 (1%)]	Loss: 0.054128Train Epoch: 10 [5120/702208 (1%)]	Loss: 0.056337Train Epoch: 10 [6016/702208 (1%)]	Loss: 0.037037Train Epoch: 10 [7040/702208 (1%)]	Loss: 0.018467Train Epoch: 10 [8064/702208 (1%)]	Loss: 0.041201Train Epoch: 10 [9088/702208 (1%)]	Loss: 0.127722Train Epoch: 10 [10112/702208 (1%)]	Loss: 0.053784Train Epoch: 10 [11008/702208 (2%)]	Loss: 0.023890Train Epoch: 10 [12032/702208 (2%)]	Loss: 0.015124Train Epoch: 10 [13056/702208 (2%)]	Loss: 0.110404Train Epoch: 10 [14080/702208 (2%)]	Loss: 0.042397Train Epoch: 10 [15104/702208 (2%)]	Loss: 0.055912Train Epoch: 10 [16000/702208 (2%)]	Loss: 0.042222Train Epoch: 10 [16128/702208 (2%)]	Loss: 0.065484Train Epoch: 10 [17024/702208 (2%)]	Loss: 0.012963Train Epoch: 10 [18048/702208 (3%)]	Loss: 0.014894Train Epoch: 10 [19072/702208 (3%)]	Loss: 0.089297Train Epoch: 10 [20096/702208 (3%)]	Loss: 0.022882Train Epoch: 10 [21120/702208 (3%)]	Loss: 0.112407Train Epoch: 10 [22016/702208 (3%)]	Loss: 0.074372Train Epoch: 10 [23040/702208 (3%)]	Loss: 0.033059Train Epoch: 10 [24064/702208 (3%)]	Loss: 0.030491Train Epoch: 10 [25088/702208 (4%)]	Loss: 0.040707
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8051 / 8283] 97 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-6344960-total-98.11999999999999-class0-97.2-class1-99.8
Train Epoch: 10 [26112/702208 (4%)]	Loss: 0.049523Train Epoch: 10 [27008/702208 (4%)]	Loss: 0.039414Train Epoch: 10 [28032/702208 (4%)]	Loss: 0.050651Train Epoch: 10 [29056/702208 (4%)]	Loss: 0.057445Train Epoch: 10 [30080/702208 (4%)]	Loss: 0.138500Train Epoch: 10 [31104/702208 (4%)]	Loss: 0.032761Train Epoch: 10 [32000/702208 (5%)]	Loss: 0.021025Train Epoch: 10 [32128/702208 (5%)]	Loss: 0.074877Train Epoch: 10 [33024/702208 (5%)]	Loss: 0.078494Train Epoch: 10 [34048/702208 (5%)]	Loss: 0.035260Train Epoch: 10 [35072/702208 (5%)]	Loss: 0.048448Train Epoch: 10 [36096/702208 (5%)]	Loss: 0.050368Train Epoch: 10 [37120/702208 (5%)]	Loss: 0.071166Train Epoch: 10 [38016/702208 (5%)]	Loss: 0.035065Train Epoch: 10 [39040/702208 (6%)]	Loss: 0.071552Train Epoch: 10 [40064/702208 (6%)]	Loss: 0.019608Train Epoch: 10 [41088/702208 (6%)]	Loss: 0.101397Train Epoch: 10 [42112/702208 (6%)]	Loss: 0.043412Train Epoch: 10 [43008/702208 (6%)]	Loss: 0.012533Train Epoch: 10 [44032/702208 (6%)]	Loss: 0.070605Train Epoch: 10 [45056/702208 (6%)]	Loss: 0.041688Train Epoch: 10 [46080/702208 (7%)]	Loss: 0.079182Train Epoch: 10 [47104/702208 (7%)]	Loss: 0.035737Train Epoch: 10 [48000/702208 (7%)]	Loss: 0.057236Train Epoch: 10 [48128/702208 (7%)]	Loss: 0.006865Train Epoch: 10 [49024/702208 (7%)]	Loss: 0.081769Train Epoch: 10 [50048/702208 (7%)]	Loss: 0.042082
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8148 / 8283] 98 %
Accuracy of the network on test loader class  1: [4494 / 4517] 99 %

Writing model: iterations-6369920-total-98.77-class0-98.37-class1-99.49

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12368 / 12833] 96 %
Accuracy of the network on train loader class  1: [6920 / 7135] 96 %
Train Epoch: 10 [51072/702208 (7%)]	Loss: 0.035668Train Epoch: 10 [52096/702208 (7%)]	Loss: 0.043148Train Epoch: 10 [53120/702208 (8%)]	Loss: 0.050791Train Epoch: 10 [54016/702208 (8%)]	Loss: 0.036303Train Epoch: 10 [55040/702208 (8%)]	Loss: 0.034707Train Epoch: 10 [56064/702208 (8%)]	Loss: 0.062817Train Epoch: 10 [57088/702208 (8%)]	Loss: 0.049495Train Epoch: 10 [58112/702208 (8%)]	Loss: 0.051541Train Epoch: 10 [59008/702208 (8%)]	Loss: 0.032291Train Epoch: 10 [60032/702208 (9%)]	Loss: 0.027648Train Epoch: 10 [61056/702208 (9%)]	Loss: 0.034665Train Epoch: 10 [62080/702208 (9%)]	Loss: 0.030257Train Epoch: 10 [63104/702208 (9%)]	Loss: 0.018326Train Epoch: 10 [64000/702208 (9%)]	Loss: 0.063289Train Epoch: 10 [64128/702208 (9%)]	Loss: 0.054130Train Epoch: 10 [65024/702208 (9%)]	Loss: 0.042453Train Epoch: 10 [66048/702208 (9%)]	Loss: 0.066665Train Epoch: 10 [67072/702208 (10%)]	Loss: 0.064387Train Epoch: 10 [68096/702208 (10%)]	Loss: 0.053969Train Epoch: 10 [69120/702208 (10%)]	Loss: 0.034440Train Epoch: 10 [70016/702208 (10%)]	Loss: 0.048868Train Epoch: 10 [71040/702208 (10%)]	Loss: 0.045716Train Epoch: 10 [72064/702208 (10%)]	Loss: 0.025727Train Epoch: 10 [73088/702208 (10%)]	Loss: 0.043352Train Epoch: 10 [74112/702208 (11%)]	Loss: 0.040117Train Epoch: 10 [75008/702208 (11%)]	Loss: 0.041594
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8053 / 8283] 97 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-6394880-total-98.14-class0-97.22-class1-99.82
Train Epoch: 10 [76032/702208 (11%)]	Loss: 0.053725Train Epoch: 10 [77056/702208 (11%)]	Loss: 0.042958Train Epoch: 10 [78080/702208 (11%)]	Loss: 0.071946Train Epoch: 10 [79104/702208 (11%)]	Loss: 0.043316Train Epoch: 10 [80000/702208 (11%)]	Loss: 0.055599Train Epoch: 10 [80128/702208 (11%)]	Loss: 0.076189Train Epoch: 10 [81024/702208 (12%)]	Loss: 0.050001Train Epoch: 10 [82048/702208 (12%)]	Loss: 0.015297Train Epoch: 10 [83072/702208 (12%)]	Loss: 0.037096Train Epoch: 10 [84096/702208 (12%)]	Loss: 0.056685Train Epoch: 10 [85120/702208 (12%)]	Loss: 0.022299Train Epoch: 10 [86016/702208 (12%)]	Loss: 0.011053Train Epoch: 10 [87040/702208 (12%)]	Loss: 0.060484Train Epoch: 10 [88064/702208 (13%)]	Loss: 0.056387Train Epoch: 10 [89088/702208 (13%)]	Loss: 0.025750Train Epoch: 10 [90112/702208 (13%)]	Loss: 0.058727Train Epoch: 10 [91008/702208 (13%)]	Loss: 0.058023Train Epoch: 10 [92032/702208 (13%)]	Loss: 0.026010Train Epoch: 10 [93056/702208 (13%)]	Loss: 0.032050Train Epoch: 10 [94080/702208 (13%)]	Loss: 0.012237Train Epoch: 10 [95104/702208 (14%)]	Loss: 0.053372Train Epoch: 10 [96000/702208 (14%)]	Loss: 0.039576Train Epoch: 10 [96128/702208 (14%)]	Loss: 0.033905Train Epoch: 10 [97024/702208 (14%)]	Loss: 0.019231Train Epoch: 10 [98048/702208 (14%)]	Loss: 0.044624Train Epoch: 10 [99072/702208 (14%)]	Loss: 0.010808Train Epoch: 10 [100096/702208 (14%)]	Loss: 0.052377
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8067 / 8283] 97 %
Accuracy of the network on test loader class  1: [4507 / 4517] 99 %

Writing model: iterations-6419968-total-98.22999999999999-class0-97.39-class1-99.78

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 96 %
Accuracy of the network on train loader class  0: [12302 / 12833] 95 %
Accuracy of the network on train loader class  1: [7020 / 7135] 98 %
Train Epoch: 10 [101120/702208 (14%)]	Loss: 0.027508Train Epoch: 10 [102016/702208 (15%)]	Loss: 0.029039Train Epoch: 10 [103040/702208 (15%)]	Loss: 0.027849Train Epoch: 10 [104064/702208 (15%)]	Loss: 0.037457Train Epoch: 10 [105088/702208 (15%)]	Loss: 0.074843Train Epoch: 10 [106112/702208 (15%)]	Loss: 0.073048Train Epoch: 10 [107008/702208 (15%)]	Loss: 0.033154Train Epoch: 10 [108032/702208 (15%)]	Loss: 0.017470Train Epoch: 10 [109056/702208 (16%)]	Loss: 0.056891Train Epoch: 10 [110080/702208 (16%)]	Loss: 0.047443Train Epoch: 10 [111104/702208 (16%)]	Loss: 0.051456Train Epoch: 10 [112000/702208 (16%)]	Loss: 0.025747Train Epoch: 10 [112128/702208 (16%)]	Loss: 0.093342Train Epoch: 10 [113024/702208 (16%)]	Loss: 0.031342Train Epoch: 10 [114048/702208 (16%)]	Loss: 0.032718Train Epoch: 10 [115072/702208 (16%)]	Loss: 0.019813Train Epoch: 10 [116096/702208 (17%)]	Loss: 0.025115Train Epoch: 10 [117120/702208 (17%)]	Loss: 0.033031Train Epoch: 10 [118016/702208 (17%)]	Loss: 0.119513Train Epoch: 10 [119040/702208 (17%)]	Loss: 0.048864Train Epoch: 10 [120064/702208 (17%)]	Loss: 0.058015Train Epoch: 10 [121088/702208 (17%)]	Loss: 0.035036Train Epoch: 10 [122112/702208 (17%)]	Loss: 0.025586Train Epoch: 10 [123008/702208 (18%)]	Loss: 0.028256Train Epoch: 10 [124032/702208 (18%)]	Loss: 0.045605Train Epoch: 10 [125056/702208 (18%)]	Loss: 0.027611
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8043 / 8283] 97 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-6444928-total-98.07000000000001-class0-97.1-class1-99.85000000000001
Train Epoch: 10 [126080/702208 (18%)]	Loss: 0.042851Train Epoch: 10 [127104/702208 (18%)]	Loss: 0.039475Train Epoch: 10 [128000/702208 (18%)]	Loss: 0.045201Train Epoch: 10 [128128/702208 (18%)]	Loss: 0.083112Train Epoch: 10 [129024/702208 (18%)]	Loss: 0.036439Train Epoch: 10 [130048/702208 (19%)]	Loss: 0.059138Train Epoch: 10 [131072/702208 (19%)]	Loss: 0.025727Train Epoch: 10 [132096/702208 (19%)]	Loss: 0.035787Train Epoch: 10 [133120/702208 (19%)]	Loss: 0.007101Train Epoch: 10 [134016/702208 (19%)]	Loss: 0.019696Train Epoch: 10 [135040/702208 (19%)]	Loss: 0.026649Train Epoch: 10 [136064/702208 (19%)]	Loss: 0.089470Train Epoch: 10 [137088/702208 (20%)]	Loss: 0.061405Train Epoch: 10 [138112/702208 (20%)]	Loss: 0.022879Train Epoch: 10 [139008/702208 (20%)]	Loss: 0.015433Train Epoch: 10 [140032/702208 (20%)]	Loss: 0.041728Train Epoch: 10 [141056/702208 (20%)]	Loss: 0.056583Train Epoch: 10 [142080/702208 (20%)]	Loss: 0.018734Train Epoch: 10 [143104/702208 (20%)]	Loss: 0.012931Train Epoch: 10 [144000/702208 (21%)]	Loss: 0.056299Train Epoch: 10 [144128/702208 (21%)]	Loss: 0.025388Train Epoch: 10 [145024/702208 (21%)]	Loss: 0.144261Train Epoch: 10 [146048/702208 (21%)]	Loss: 0.025031Train Epoch: 10 [147072/702208 (21%)]	Loss: 0.047539Train Epoch: 10 [148096/702208 (21%)]	Loss: 0.059996Train Epoch: 10 [149120/702208 (21%)]	Loss: 0.048678Train Epoch: 10 [150016/702208 (21%)]	Loss: 0.100795
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8082 / 8283] 97 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-6469888-total-98.39-class0-97.57000000000001-class1-99.89

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12448 / 12833] 96 %
Accuracy of the network on train loader class  1: [7105 / 7135] 99 %
Train Epoch: 10 [151040/702208 (22%)]	Loss: 0.043726Train Epoch: 10 [152064/702208 (22%)]	Loss: 0.031489Train Epoch: 10 [153088/702208 (22%)]	Loss: 0.038677Train Epoch: 10 [154112/702208 (22%)]	Loss: 0.091324Train Epoch: 10 [155008/702208 (22%)]	Loss: 0.037370Train Epoch: 10 [156032/702208 (22%)]	Loss: 0.108586Train Epoch: 10 [157056/702208 (22%)]	Loss: 0.051859Train Epoch: 10 [158080/702208 (23%)]	Loss: 0.070557Train Epoch: 10 [159104/702208 (23%)]	Loss: 0.074655Train Epoch: 10 [160000/702208 (23%)]	Loss: 0.038163Train Epoch: 10 [160128/702208 (23%)]	Loss: 0.037287Train Epoch: 10 [161024/702208 (23%)]	Loss: 0.035850Train Epoch: 10 [162048/702208 (23%)]	Loss: 0.057794Train Epoch: 10 [163072/702208 (23%)]	Loss: 0.017861Train Epoch: 10 [164096/702208 (23%)]	Loss: 0.040407Train Epoch: 10 [165120/702208 (24%)]	Loss: 0.023883Train Epoch: 10 [166016/702208 (24%)]	Loss: 0.051597Train Epoch: 10 [167040/702208 (24%)]	Loss: 0.067091Train Epoch: 10 [168064/702208 (24%)]	Loss: 0.020618Train Epoch: 10 [169088/702208 (24%)]	Loss: 0.008643Train Epoch: 10 [170112/702208 (24%)]	Loss: 0.023425Train Epoch: 10 [171008/702208 (24%)]	Loss: 0.053411Train Epoch: 10 [172032/702208 (24%)]	Loss: 0.039484Train Epoch: 10 [173056/702208 (25%)]	Loss: 0.039380Train Epoch: 10 [174080/702208 (25%)]	Loss: 0.013001Train Epoch: 10 [175104/702208 (25%)]	Loss: 0.012042
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8105 / 8283] 97 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-6494976-total-98.52-class0-97.85000000000001-class1-99.72999999999999
Train Epoch: 10 [176000/702208 (25%)]	Loss: 0.026988Train Epoch: 10 [176128/702208 (25%)]	Loss: 0.021292Train Epoch: 10 [177024/702208 (25%)]	Loss: 0.010230Train Epoch: 10 [178048/702208 (25%)]	Loss: 0.170081Train Epoch: 10 [179072/702208 (26%)]	Loss: 0.017848Train Epoch: 10 [180096/702208 (26%)]	Loss: 0.031533Train Epoch: 10 [181120/702208 (26%)]	Loss: 0.086744Train Epoch: 10 [182016/702208 (26%)]	Loss: 0.073617Train Epoch: 10 [183040/702208 (26%)]	Loss: 0.062646Train Epoch: 10 [184064/702208 (26%)]	Loss: 0.049765Train Epoch: 10 [185088/702208 (26%)]	Loss: 0.013411Train Epoch: 10 [186112/702208 (27%)]	Loss: 0.008876Train Epoch: 10 [187008/702208 (27%)]	Loss: 0.020095Train Epoch: 10 [188032/702208 (27%)]	Loss: 0.016916Train Epoch: 10 [189056/702208 (27%)]	Loss: 0.039313Train Epoch: 10 [190080/702208 (27%)]	Loss: 0.027384Train Epoch: 10 [191104/702208 (27%)]	Loss: 0.119910Train Epoch: 10 [192000/702208 (27%)]	Loss: 0.021217Train Epoch: 10 [192128/702208 (27%)]	Loss: 0.027267Train Epoch: 10 [193024/702208 (27%)]	Loss: 0.050750Train Epoch: 10 [194048/702208 (28%)]	Loss: 0.014882Train Epoch: 10 [195072/702208 (28%)]	Loss: 0.024890Train Epoch: 10 [196096/702208 (28%)]	Loss: 0.026960Train Epoch: 10 [197120/702208 (28%)]	Loss: 0.038292Train Epoch: 10 [198016/702208 (28%)]	Loss: 0.028565Train Epoch: 10 [199040/702208 (28%)]	Loss: 0.043767Train Epoch: 10 [200064/702208 (28%)]	Loss: 0.022815
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8129 / 8283] 98 %
Accuracy of the network on test loader class  1: [4503 / 4517] 99 %

Writing model: iterations-6519936-total-98.69-class0-98.14-class1-99.69

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12397 / 12833] 96 %
Accuracy of the network on train loader class  1: [7054 / 7135] 98 %
Train Epoch: 10 [201088/702208 (29%)]	Loss: 0.043530Train Epoch: 10 [202112/702208 (29%)]	Loss: 0.045074Train Epoch: 10 [203008/702208 (29%)]	Loss: 0.084443Train Epoch: 10 [204032/702208 (29%)]	Loss: 0.016368Train Epoch: 10 [205056/702208 (29%)]	Loss: 0.020696Train Epoch: 10 [206080/702208 (29%)]	Loss: 0.034138Train Epoch: 10 [207104/702208 (29%)]	Loss: 0.037686Train Epoch: 10 [208000/702208 (30%)]	Loss: 0.134376Train Epoch: 10 [208128/702208 (30%)]	Loss: 0.029108Train Epoch: 10 [209024/702208 (30%)]	Loss: 0.030339Train Epoch: 10 [210048/702208 (30%)]	Loss: 0.024688Train Epoch: 10 [211072/702208 (30%)]	Loss: 0.063551Train Epoch: 10 [212096/702208 (30%)]	Loss: 0.047368Train Epoch: 10 [213120/702208 (30%)]	Loss: 0.109254Train Epoch: 10 [214016/702208 (30%)]	Loss: 0.121286Train Epoch: 10 [215040/702208 (31%)]	Loss: 0.060466Train Epoch: 10 [216064/702208 (31%)]	Loss: 0.034720Train Epoch: 10 [217088/702208 (31%)]	Loss: 0.038278Train Epoch: 10 [218112/702208 (31%)]	Loss: 0.036857Train Epoch: 10 [219008/702208 (31%)]	Loss: 0.027266Train Epoch: 10 [220032/702208 (31%)]	Loss: 0.072807Train Epoch: 10 [221056/702208 (31%)]	Loss: 0.042243Train Epoch: 10 [222080/702208 (32%)]	Loss: 0.046173Train Epoch: 10 [223104/702208 (32%)]	Loss: 0.019586Train Epoch: 10 [224000/702208 (32%)]	Loss: 0.013395Train Epoch: 10 [224128/702208 (32%)]	Loss: 0.022217Train Epoch: 10 [225024/702208 (32%)]	Loss: 0.036652
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8068 / 8283] 97 %
Accuracy of the network on test loader class  1: [4509 / 4517] 99 %

Writing model: iterations-6544896-total-98.26-class0-97.39999999999999-class1-99.82
Train Epoch: 10 [226048/702208 (32%)]	Loss: 0.042728Train Epoch: 10 [227072/702208 (32%)]	Loss: 0.027066Train Epoch: 10 [228096/702208 (32%)]	Loss: 0.076781Train Epoch: 10 [229120/702208 (33%)]	Loss: 0.155550Train Epoch: 10 [230016/702208 (33%)]	Loss: 0.034597Train Epoch: 10 [231040/702208 (33%)]	Loss: 0.054585Train Epoch: 10 [232064/702208 (33%)]	Loss: 0.060392Train Epoch: 10 [233088/702208 (33%)]	Loss: 0.047859Train Epoch: 10 [234112/702208 (33%)]	Loss: 0.039549Train Epoch: 10 [235008/702208 (33%)]	Loss: 0.032866Train Epoch: 10 [236032/702208 (34%)]	Loss: 0.056555Train Epoch: 10 [237056/702208 (34%)]	Loss: 0.125841Train Epoch: 10 [238080/702208 (34%)]	Loss: 0.075960Train Epoch: 10 [239104/702208 (34%)]	Loss: 0.022555Train Epoch: 10 [240000/702208 (34%)]	Loss: 0.024244Train Epoch: 10 [240128/702208 (34%)]	Loss: 0.024861Train Epoch: 10 [241024/702208 (34%)]	Loss: 0.041605Train Epoch: 10 [242048/702208 (34%)]	Loss: 0.017083Train Epoch: 10 [243072/702208 (35%)]	Loss: 0.031436Train Epoch: 10 [244096/702208 (35%)]	Loss: 0.052845Train Epoch: 10 [245120/702208 (35%)]	Loss: 0.041328Train Epoch: 10 [246016/702208 (35%)]	Loss: 0.029646Train Epoch: 10 [247040/702208 (35%)]	Loss: 0.026131Train Epoch: 10 [248064/702208 (35%)]	Loss: 0.033726Train Epoch: 10 [249088/702208 (35%)]	Loss: 0.025351Train Epoch: 10 [250112/702208 (36%)]	Loss: 0.065252
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8112 / 8283] 97 %
Accuracy of the network on test loader class  1: [4506 / 4517] 99 %

Writing model: iterations-6569984-total-98.58-class0-97.94-class1-99.76

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12434 / 12833] 96 %
Accuracy of the network on train loader class  1: [7115 / 7135] 99 %
Train Epoch: 10 [251008/702208 (36%)]	Loss: 0.017014Train Epoch: 10 [252032/702208 (36%)]	Loss: 0.035661Train Epoch: 10 [253056/702208 (36%)]	Loss: 0.028092Train Epoch: 10 [254080/702208 (36%)]	Loss: 0.076498Train Epoch: 10 [255104/702208 (36%)]	Loss: 0.043584Train Epoch: 10 [256000/702208 (36%)]	Loss: 0.017283Train Epoch: 10 [256128/702208 (36%)]	Loss: 0.027591Train Epoch: 10 [257024/702208 (37%)]	Loss: 0.056124Train Epoch: 10 [258048/702208 (37%)]	Loss: 0.033507Train Epoch: 10 [259072/702208 (37%)]	Loss: 0.151067Train Epoch: 10 [260096/702208 (37%)]	Loss: 0.088100Train Epoch: 10 [261120/702208 (37%)]	Loss: 0.032741Train Epoch: 10 [262016/702208 (37%)]	Loss: 0.025486Train Epoch: 10 [263040/702208 (37%)]	Loss: 0.042640Train Epoch: 10 [264064/702208 (38%)]	Loss: 0.067029Train Epoch: 10 [265088/702208 (38%)]	Loss: 0.136599Train Epoch: 10 [266112/702208 (38%)]	Loss: 0.060222Train Epoch: 10 [267008/702208 (38%)]	Loss: 0.126911Train Epoch: 10 [268032/702208 (38%)]	Loss: 0.100451Train Epoch: 10 [269056/702208 (38%)]	Loss: 0.047025Train Epoch: 10 [270080/702208 (38%)]	Loss: 0.034750Train Epoch: 10 [271104/702208 (39%)]	Loss: 0.052859Train Epoch: 10 [272000/702208 (39%)]	Loss: 0.057130Train Epoch: 10 [272128/702208 (39%)]	Loss: 0.078324Train Epoch: 10 [273024/702208 (39%)]	Loss: 0.087144Train Epoch: 10 [274048/702208 (39%)]	Loss: 0.035502Train Epoch: 10 [275072/702208 (39%)]	Loss: 0.034548
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8046 / 8283] 97 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-6594944-total-98.1-class0-97.14-class1-99.87
Train Epoch: 10 [276096/702208 (39%)]	Loss: 0.051546Train Epoch: 10 [277120/702208 (39%)]	Loss: 0.036499Train Epoch: 10 [278016/702208 (40%)]	Loss: 0.024868Train Epoch: 10 [279040/702208 (40%)]	Loss: 0.037296Train Epoch: 10 [280064/702208 (40%)]	Loss: 0.052169Train Epoch: 10 [281088/702208 (40%)]	Loss: 0.083480Train Epoch: 10 [282112/702208 (40%)]	Loss: 0.031167Train Epoch: 10 [283008/702208 (40%)]	Loss: 0.051208Train Epoch: 10 [284032/702208 (40%)]	Loss: 0.027135Train Epoch: 10 [285056/702208 (41%)]	Loss: 0.014287Train Epoch: 10 [286080/702208 (41%)]	Loss: 0.021583Train Epoch: 10 [287104/702208 (41%)]	Loss: 0.087860Train Epoch: 10 [288000/702208 (41%)]	Loss: 0.026056Train Epoch: 10 [288128/702208 (41%)]	Loss: 0.048781Train Epoch: 10 [289024/702208 (41%)]	Loss: 0.025835Train Epoch: 10 [290048/702208 (41%)]	Loss: 0.084526Train Epoch: 10 [291072/702208 (41%)]	Loss: 0.024754Train Epoch: 10 [292096/702208 (42%)]	Loss: 0.059231Train Epoch: 10 [293120/702208 (42%)]	Loss: 0.052164Train Epoch: 10 [294016/702208 (42%)]	Loss: 0.097955Train Epoch: 10 [295040/702208 (42%)]	Loss: 0.024818Train Epoch: 10 [296064/702208 (42%)]	Loss: 0.034563Train Epoch: 10 [297088/702208 (42%)]	Loss: 0.075480Train Epoch: 10 [298112/702208 (42%)]	Loss: 0.037258Train Epoch: 10 [299008/702208 (43%)]	Loss: 0.026230Train Epoch: 10 [300032/702208 (43%)]	Loss: 0.024793
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7982 / 8283] 96 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %

Writing model: iterations-6619904-total-97.6-class0-96.37-class1-99.87

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12416 / 12833] 96 %
Accuracy of the network on train loader class  1: [7107 / 7135] 99 %
Train Epoch: 10 [301056/702208 (43%)]	Loss: 0.227247Train Epoch: 10 [302080/702208 (43%)]	Loss: 0.025780Train Epoch: 10 [303104/702208 (43%)]	Loss: 0.047197Train Epoch: 10 [304000/702208 (43%)]	Loss: 0.079972Train Epoch: 10 [304128/702208 (43%)]	Loss: 0.053266Train Epoch: 10 [305024/702208 (43%)]	Loss: 0.028395Train Epoch: 10 [306048/702208 (44%)]	Loss: 0.056990Train Epoch: 10 [307072/702208 (44%)]	Loss: 0.034987Train Epoch: 10 [308096/702208 (44%)]	Loss: 0.020603Train Epoch: 10 [309120/702208 (44%)]	Loss: 0.162162Train Epoch: 10 [310016/702208 (44%)]	Loss: 0.028598Train Epoch: 10 [311040/702208 (44%)]	Loss: 0.048509Train Epoch: 10 [312064/702208 (44%)]	Loss: 0.061056Train Epoch: 10 [313088/702208 (45%)]	Loss: 0.138475Train Epoch: 10 [314112/702208 (45%)]	Loss: 0.034167Train Epoch: 10 [315008/702208 (45%)]	Loss: 0.029354Train Epoch: 10 [316032/702208 (45%)]	Loss: 0.042760Train Epoch: 10 [317056/702208 (45%)]	Loss: 0.022387Train Epoch: 10 [318080/702208 (45%)]	Loss: 0.018730Train Epoch: 10 [319104/702208 (45%)]	Loss: 0.103561Train Epoch: 10 [320000/702208 (46%)]	Loss: 0.076144Train Epoch: 10 [320128/702208 (46%)]	Loss: 0.031395Train Epoch: 10 [321024/702208 (46%)]	Loss: 0.041559Train Epoch: 10 [322048/702208 (46%)]	Loss: 0.031572Train Epoch: 10 [323072/702208 (46%)]	Loss: 0.024098Train Epoch: 10 [324096/702208 (46%)]	Loss: 0.050583Train Epoch: 10 [325120/702208 (46%)]	Loss: 0.076500
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8065 / 8283] 97 %
Accuracy of the network on test loader class  1: [4514 / 4517] 99 %

Writing model: iterations-6644992-total-98.27-class0-97.37-class1-99.92999999999999
Train Epoch: 10 [326016/702208 (46%)]	Loss: 0.040994Train Epoch: 10 [327040/702208 (47%)]	Loss: 0.020581Train Epoch: 10 [328064/702208 (47%)]	Loss: 0.020715Train Epoch: 10 [329088/702208 (47%)]	Loss: 0.030023Train Epoch: 10 [330112/702208 (47%)]	Loss: 0.012820Train Epoch: 10 [331008/702208 (47%)]	Loss: 0.016883Train Epoch: 10 [332032/702208 (47%)]	Loss: 0.072303Train Epoch: 10 [333056/702208 (47%)]	Loss: 0.050626Train Epoch: 10 [334080/702208 (48%)]	Loss: 0.037253Train Epoch: 10 [335104/702208 (48%)]	Loss: 0.032645Train Epoch: 10 [336000/702208 (48%)]	Loss: 0.081571Train Epoch: 10 [336128/702208 (48%)]	Loss: 0.030442Train Epoch: 10 [337024/702208 (48%)]	Loss: 0.029005Train Epoch: 10 [338048/702208 (48%)]	Loss: 0.042665Train Epoch: 10 [339072/702208 (48%)]	Loss: 0.030719Train Epoch: 10 [340096/702208 (48%)]	Loss: 0.058637Train Epoch: 10 [341120/702208 (49%)]	Loss: 0.086961Train Epoch: 10 [342016/702208 (49%)]	Loss: 0.049019Train Epoch: 10 [343040/702208 (49%)]	Loss: 0.065385Train Epoch: 10 [344064/702208 (49%)]	Loss: 0.044134Train Epoch: 10 [345088/702208 (49%)]	Loss: 0.028352Train Epoch: 10 [346112/702208 (49%)]	Loss: 0.085998Train Epoch: 10 [347008/702208 (49%)]	Loss: 0.036244Train Epoch: 10 [348032/702208 (50%)]	Loss: 0.019561Train Epoch: 10 [349056/702208 (50%)]	Loss: 0.060549Train Epoch: 10 [350080/702208 (50%)]	Loss: 0.041177
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8001 / 8283] 96 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-6669952-total-97.77-class0-96.6-class1-99.91

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12365 / 12833] 96 %
Accuracy of the network on train loader class  1: [7112 / 7135] 99 %
Train Epoch: 10 [351104/702208 (50%)]	Loss: 0.043618Train Epoch: 10 [352000/702208 (50%)]	Loss: 0.070921Train Epoch: 10 [352128/702208 (50%)]	Loss: 0.108058Train Epoch: 10 [353024/702208 (50%)]	Loss: 0.042916Train Epoch: 10 [354048/702208 (50%)]	Loss: 0.017015Train Epoch: 10 [355072/702208 (51%)]	Loss: 0.028969Train Epoch: 10 [356096/702208 (51%)]	Loss: 0.034239Train Epoch: 10 [357120/702208 (51%)]	Loss: 0.029901Train Epoch: 10 [358016/702208 (51%)]	Loss: 0.055968Train Epoch: 10 [359040/702208 (51%)]	Loss: 0.032001Train Epoch: 10 [360064/702208 (51%)]	Loss: 0.030380Train Epoch: 10 [361088/702208 (51%)]	Loss: 0.036550Train Epoch: 10 [362112/702208 (52%)]	Loss: 0.066206Train Epoch: 10 [363008/702208 (52%)]	Loss: 0.014151Train Epoch: 10 [364032/702208 (52%)]	Loss: 0.027756Train Epoch: 10 [365056/702208 (52%)]	Loss: 0.034713Train Epoch: 10 [366080/702208 (52%)]	Loss: 0.046470Train Epoch: 10 [367104/702208 (52%)]	Loss: 0.069280Train Epoch: 10 [368000/702208 (52%)]	Loss: 0.023285Train Epoch: 10 [368128/702208 (52%)]	Loss: 0.041915Train Epoch: 10 [369024/702208 (53%)]	Loss: 0.029687Train Epoch: 10 [370048/702208 (53%)]	Loss: 0.067932Train Epoch: 10 [371072/702208 (53%)]	Loss: 0.043648Train Epoch: 10 [372096/702208 (53%)]	Loss: 0.075703Train Epoch: 10 [373120/702208 (53%)]	Loss: 0.104882Train Epoch: 10 [374016/702208 (53%)]	Loss: 0.040302Train Epoch: 10 [375040/702208 (53%)]	Loss: 0.015166
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 95 %
Accuracy of the network on test loader class  0: [7730 / 8283] 93 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-6694912-total-95.63000000000001-class0-93.32000000000001-class1-99.85000000000001
Train Epoch: 10 [376064/702208 (54%)]	Loss: 0.034608Train Epoch: 10 [377088/702208 (54%)]	Loss: 0.040636Train Epoch: 10 [378112/702208 (54%)]	Loss: 0.094610Train Epoch: 10 [379008/702208 (54%)]	Loss: 0.041086Train Epoch: 10 [380032/702208 (54%)]	Loss: 0.032444Train Epoch: 10 [381056/702208 (54%)]	Loss: 0.031296Train Epoch: 10 [382080/702208 (54%)]	Loss: 0.027317Train Epoch: 10 [383104/702208 (55%)]	Loss: 0.020839Train Epoch: 10 [384000/702208 (55%)]	Loss: 0.082556Train Epoch: 10 [384128/702208 (55%)]	Loss: 0.035870Train Epoch: 10 [385024/702208 (55%)]	Loss: 0.046026Train Epoch: 10 [386048/702208 (55%)]	Loss: 0.058431Train Epoch: 10 [387072/702208 (55%)]	Loss: 0.031917Train Epoch: 10 [388096/702208 (55%)]	Loss: 0.098026Train Epoch: 10 [389120/702208 (55%)]	Loss: 0.087978Train Epoch: 10 [390016/702208 (56%)]	Loss: 0.029298Train Epoch: 10 [391040/702208 (56%)]	Loss: 0.023672Train Epoch: 10 [392064/702208 (56%)]	Loss: 0.051291Train Epoch: 10 [393088/702208 (56%)]	Loss: 0.032315Train Epoch: 10 [394112/702208 (56%)]	Loss: 0.059245Train Epoch: 10 [395008/702208 (56%)]	Loss: 0.033074Train Epoch: 10 [396032/702208 (56%)]	Loss: 0.022795Train Epoch: 10 [397056/702208 (57%)]	Loss: 0.050040Train Epoch: 10 [398080/702208 (57%)]	Loss: 0.075521Train Epoch: 10 [399104/702208 (57%)]	Loss: 0.030482Train Epoch: 10 [400000/702208 (57%)]	Loss: 0.042614
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8023 / 8283] 96 %
Accuracy of the network on test loader class  1: [4516 / 4517] 99 %

Writing model: iterations-6719872-total-97.96000000000001-class0-96.86-class1-99.98

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12387 / 12833] 96 %
Accuracy of the network on train loader class  1: [7117 / 7135] 99 %
Train Epoch: 10 [400128/702208 (57%)]	Loss: 0.084052
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8018 / 8283] 96 %
Accuracy of the network on test loader class  1: [4516 / 4517] 99 %

Writing model: iterations-6720000-total-97.92-class0-96.8-class1-99.98

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12401 / 12833] 96 %
Accuracy of the network on train loader class  1: [7114 / 7135] 99 %
Train Epoch: 10 [401024/702208 (57%)]	Loss: 0.042938Train Epoch: 10 [402048/702208 (57%)]	Loss: 0.016724Train Epoch: 10 [403072/702208 (57%)]	Loss: 0.024468Train Epoch: 10 [404096/702208 (58%)]	Loss: 0.041469Train Epoch: 10 [405120/702208 (58%)]	Loss: 0.021530Train Epoch: 10 [406016/702208 (58%)]	Loss: 0.052454Train Epoch: 10 [407040/702208 (58%)]	Loss: 0.023498Train Epoch: 10 [408064/702208 (58%)]	Loss: 0.108503Train Epoch: 10 [409088/702208 (58%)]	Loss: 0.036276Train Epoch: 10 [410112/702208 (58%)]	Loss: 0.035191Train Epoch: 10 [411008/702208 (59%)]	Loss: 0.053113Train Epoch: 10 [412032/702208 (59%)]	Loss: 0.017868Train Epoch: 10 [413056/702208 (59%)]	Loss: 0.013980Train Epoch: 10 [414080/702208 (59%)]	Loss: 0.049433Train Epoch: 10 [415104/702208 (59%)]	Loss: 0.179313Train Epoch: 10 [416000/702208 (59%)]	Loss: 0.062276Train Epoch: 10 [416128/702208 (59%)]	Loss: 0.045379Train Epoch: 10 [417024/702208 (59%)]	Loss: 0.020669Train Epoch: 10 [418048/702208 (60%)]	Loss: 0.055918Train Epoch: 10 [419072/702208 (60%)]	Loss: 0.051361Train Epoch: 10 [420096/702208 (60%)]	Loss: 0.099126Train Epoch: 10 [421120/702208 (60%)]	Loss: 0.016128Train Epoch: 10 [422016/702208 (60%)]	Loss: 0.053328Train Epoch: 10 [423040/702208 (60%)]	Loss: 0.033562Train Epoch: 10 [424064/702208 (60%)]	Loss: 0.066625Train Epoch: 10 [425088/702208 (61%)]	Loss: 0.011924
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8056 / 8283] 97 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-6744960-total-98.2-class0-97.26-class1-99.91
Train Epoch: 10 [426112/702208 (61%)]	Loss: 0.012326Train Epoch: 10 [427008/702208 (61%)]	Loss: 0.016394Train Epoch: 10 [428032/702208 (61%)]	Loss: 0.065580Train Epoch: 10 [429056/702208 (61%)]	Loss: 0.037499Train Epoch: 10 [430080/702208 (61%)]	Loss: 0.021678Train Epoch: 10 [431104/702208 (61%)]	Loss: 0.081541Train Epoch: 10 [432000/702208 (62%)]	Loss: 0.044140Train Epoch: 10 [432128/702208 (62%)]	Loss: 0.031428Train Epoch: 10 [433024/702208 (62%)]	Loss: 0.020574Train Epoch: 10 [434048/702208 (62%)]	Loss: 0.026369Train Epoch: 10 [435072/702208 (62%)]	Loss: 0.042787Train Epoch: 10 [436096/702208 (62%)]	Loss: 0.054628Train Epoch: 10 [437120/702208 (62%)]	Loss: 0.036772Train Epoch: 10 [438016/702208 (62%)]	Loss: 0.054497Train Epoch: 10 [439040/702208 (63%)]	Loss: 0.025963Train Epoch: 10 [440064/702208 (63%)]	Loss: 0.030753Train Epoch: 10 [441088/702208 (63%)]	Loss: 0.219847Train Epoch: 10 [442112/702208 (63%)]	Loss: 0.122928Train Epoch: 10 [443008/702208 (63%)]	Loss: 0.048614Train Epoch: 10 [444032/702208 (63%)]	Loss: 0.048560Train Epoch: 10 [445056/702208 (63%)]	Loss: 0.027360Train Epoch: 10 [446080/702208 (64%)]	Loss: 0.042928Train Epoch: 10 [447104/702208 (64%)]	Loss: 0.045416Train Epoch: 10 [448000/702208 (64%)]	Loss: 0.084603Train Epoch: 10 [448128/702208 (64%)]	Loss: 0.110578Train Epoch: 10 [449024/702208 (64%)]	Loss: 0.029410Train Epoch: 10 [450048/702208 (64%)]	Loss: 0.106681
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8011 / 8283] 96 %
Accuracy of the network on test loader class  1: [4516 / 4517] 99 %

Writing model: iterations-6769920-total-97.87-class0-96.72-class1-99.98

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12290 / 12833] 95 %
Accuracy of the network on train loader class  1: [7116 / 7135] 99 %
Train Epoch: 10 [451072/702208 (64%)]	Loss: 0.022493Train Epoch: 10 [452096/702208 (64%)]	Loss: 0.032623Train Epoch: 10 [453120/702208 (65%)]	Loss: 0.047544Train Epoch: 10 [454016/702208 (65%)]	Loss: 0.095240Train Epoch: 10 [455040/702208 (65%)]	Loss: 0.030892Train Epoch: 10 [456064/702208 (65%)]	Loss: 0.059123Train Epoch: 10 [457088/702208 (65%)]	Loss: 0.047188Train Epoch: 10 [458112/702208 (65%)]	Loss: 0.026424Train Epoch: 10 [459008/702208 (65%)]	Loss: 0.023400Train Epoch: 10 [460032/702208 (66%)]	Loss: 0.029606Train Epoch: 10 [461056/702208 (66%)]	Loss: 0.034747Train Epoch: 10 [462080/702208 (66%)]	Loss: 0.062722Train Epoch: 10 [463104/702208 (66%)]	Loss: 0.019550Train Epoch: 10 [464000/702208 (66%)]	Loss: 0.040562Train Epoch: 10 [464128/702208 (66%)]	Loss: 0.041794Train Epoch: 10 [465024/702208 (66%)]	Loss: 0.027484Train Epoch: 10 [466048/702208 (66%)]	Loss: 0.061048Train Epoch: 10 [467072/702208 (67%)]	Loss: 0.058939Train Epoch: 10 [468096/702208 (67%)]	Loss: 0.051871Train Epoch: 10 [469120/702208 (67%)]	Loss: 0.042568Train Epoch: 10 [470016/702208 (67%)]	Loss: 0.014200Train Epoch: 10 [471040/702208 (67%)]	Loss: 0.031040Train Epoch: 10 [472064/702208 (67%)]	Loss: 0.077940Train Epoch: 10 [473088/702208 (67%)]	Loss: 0.008759Train Epoch: 10 [474112/702208 (68%)]	Loss: 0.052189Train Epoch: 10 [475008/702208 (68%)]	Loss: 0.016557
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8145 / 8283] 98 %
Accuracy of the network on test loader class  1: [4502 / 4517] 99 %

Writing model: iterations-6794880-total-98.8-class0-98.33-class1-99.67
Train Epoch: 10 [476032/702208 (68%)]	Loss: 0.116764Train Epoch: 10 [477056/702208 (68%)]	Loss: 0.088409Train Epoch: 10 [478080/702208 (68%)]	Loss: 0.040087Train Epoch: 10 [479104/702208 (68%)]	Loss: 0.037793Train Epoch: 10 [480000/702208 (68%)]	Loss: 0.070211Train Epoch: 10 [480128/702208 (68%)]	Loss: 0.059756Train Epoch: 10 [481024/702208 (69%)]	Loss: 0.041488Train Epoch: 10 [482048/702208 (69%)]	Loss: 0.060826Train Epoch: 10 [483072/702208 (69%)]	Loss: 0.062728Train Epoch: 10 [484096/702208 (69%)]	Loss: 0.093928Train Epoch: 10 [485120/702208 (69%)]	Loss: 0.075139Train Epoch: 10 [486016/702208 (69%)]	Loss: 0.013179Train Epoch: 10 [487040/702208 (69%)]	Loss: 0.042708Train Epoch: 10 [488064/702208 (70%)]	Loss: 0.023691Train Epoch: 10 [489088/702208 (70%)]	Loss: 0.031861Train Epoch: 10 [490112/702208 (70%)]	Loss: 0.027349Train Epoch: 10 [491008/702208 (70%)]	Loss: 0.025911Train Epoch: 10 [492032/702208 (70%)]	Loss: 0.031945Train Epoch: 10 [493056/702208 (70%)]	Loss: 0.036307Train Epoch: 10 [494080/702208 (70%)]	Loss: 0.032517Train Epoch: 10 [495104/702208 (71%)]	Loss: 0.038754Train Epoch: 10 [496000/702208 (71%)]	Loss: 0.061378Train Epoch: 10 [496128/702208 (71%)]	Loss: 0.019903Train Epoch: 10 [497024/702208 (71%)]	Loss: 0.032164Train Epoch: 10 [498048/702208 (71%)]	Loss: 0.054759Train Epoch: 10 [499072/702208 (71%)]	Loss: 0.057367Train Epoch: 10 [500096/702208 (71%)]	Loss: 0.036574
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8131 / 8283] 98 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-6819968-total-98.76-class0-98.16-class1-99.85000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 98 %
Accuracy of the network on train loader class  0: [12486 / 12833] 97 %
Accuracy of the network on train loader class  1: [7098 / 7135] 99 %
Train Epoch: 10 [501120/702208 (71%)]	Loss: 0.080057Train Epoch: 10 [502016/702208 (71%)]	Loss: 0.058654Train Epoch: 10 [503040/702208 (72%)]	Loss: 0.024928Train Epoch: 10 [504064/702208 (72%)]	Loss: 0.031521Train Epoch: 10 [505088/702208 (72%)]	Loss: 0.016343Train Epoch: 10 [506112/702208 (72%)]	Loss: 0.020008Train Epoch: 10 [507008/702208 (72%)]	Loss: 0.012024Train Epoch: 10 [508032/702208 (72%)]	Loss: 0.023437Train Epoch: 10 [509056/702208 (72%)]	Loss: 0.026324Train Epoch: 10 [510080/702208 (73%)]	Loss: 0.030523Train Epoch: 10 [511104/702208 (73%)]	Loss: 0.035810Train Epoch: 10 [512000/702208 (73%)]	Loss: 0.058550Train Epoch: 10 [512128/702208 (73%)]	Loss: 0.114868Train Epoch: 10 [513024/702208 (73%)]	Loss: 0.079792Train Epoch: 10 [514048/702208 (73%)]	Loss: 0.024690Train Epoch: 10 [515072/702208 (73%)]	Loss: 0.037403Train Epoch: 10 [516096/702208 (73%)]	Loss: 0.047100Train Epoch: 10 [517120/702208 (74%)]	Loss: 0.043438Train Epoch: 10 [518016/702208 (74%)]	Loss: 0.169988Train Epoch: 10 [519040/702208 (74%)]	Loss: 0.077353Train Epoch: 10 [520064/702208 (74%)]	Loss: 0.078772Train Epoch: 10 [521088/702208 (74%)]	Loss: 0.041330Train Epoch: 10 [522112/702208 (74%)]	Loss: 0.032797Train Epoch: 10 [523008/702208 (74%)]	Loss: 0.016745Train Epoch: 10 [524032/702208 (75%)]	Loss: 0.075778Train Epoch: 10 [525056/702208 (75%)]	Loss: 0.046595
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8093 / 8283] 97 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-6844928-total-98.48-class0-97.71-class1-99.91
Train Epoch: 10 [526080/702208 (75%)]	Loss: 0.141785Train Epoch: 10 [527104/702208 (75%)]	Loss: 0.041403Train Epoch: 10 [528000/702208 (75%)]	Loss: 0.036115Train Epoch: 10 [528128/702208 (75%)]	Loss: 0.033310Train Epoch: 10 [529024/702208 (75%)]	Loss: 0.031003Train Epoch: 10 [530048/702208 (75%)]	Loss: 0.018170Train Epoch: 10 [531072/702208 (76%)]	Loss: 0.044188Train Epoch: 10 [532096/702208 (76%)]	Loss: 0.093946Train Epoch: 10 [533120/702208 (76%)]	Loss: 0.040422Train Epoch: 10 [534016/702208 (76%)]	Loss: 0.045912Train Epoch: 10 [535040/702208 (76%)]	Loss: 0.044805Train Epoch: 10 [536064/702208 (76%)]	Loss: 0.113304Train Epoch: 10 [537088/702208 (76%)]	Loss: 0.033849Train Epoch: 10 [538112/702208 (77%)]	Loss: 0.027516Train Epoch: 10 [539008/702208 (77%)]	Loss: 0.017646Train Epoch: 10 [540032/702208 (77%)]	Loss: 0.065607Train Epoch: 10 [541056/702208 (77%)]	Loss: 0.052398Train Epoch: 10 [542080/702208 (77%)]	Loss: 0.025213Train Epoch: 10 [543104/702208 (77%)]	Loss: 0.034480Train Epoch: 10 [544000/702208 (77%)]	Loss: 0.079847Train Epoch: 10 [544128/702208 (77%)]	Loss: 0.031036Train Epoch: 10 [545024/702208 (78%)]	Loss: 0.029750Train Epoch: 10 [546048/702208 (78%)]	Loss: 0.020652Train Epoch: 10 [547072/702208 (78%)]	Loss: 0.066743Train Epoch: 10 [548096/702208 (78%)]	Loss: 0.024522Train Epoch: 10 [549120/702208 (78%)]	Loss: 0.026678Train Epoch: 10 [550016/702208 (78%)]	Loss: 0.058722
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8139 / 8283] 98 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-6869888-total-98.82-class0-98.26-class1-99.85000000000001

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 98 %
Accuracy of the network on train loader class  0: [12477 / 12833] 97 %
Accuracy of the network on train loader class  1: [7109 / 7135] 99 %
Train Epoch: 10 [551040/702208 (78%)]	Loss: 0.082011Train Epoch: 10 [552064/702208 (79%)]	Loss: 0.033297Train Epoch: 10 [553088/702208 (79%)]	Loss: 0.037976Train Epoch: 10 [554112/702208 (79%)]	Loss: 0.047800Train Epoch: 10 [555008/702208 (79%)]	Loss: 0.069703Train Epoch: 10 [556032/702208 (79%)]	Loss: 0.038656Train Epoch: 10 [557056/702208 (79%)]	Loss: 0.024325Train Epoch: 10 [558080/702208 (79%)]	Loss: 0.067254Train Epoch: 10 [559104/702208 (80%)]	Loss: 0.024030Train Epoch: 10 [560000/702208 (80%)]	Loss: 0.122208Train Epoch: 10 [560128/702208 (80%)]	Loss: 0.021835Train Epoch: 10 [561024/702208 (80%)]	Loss: 0.010952Train Epoch: 10 [562048/702208 (80%)]	Loss: 0.062592Train Epoch: 10 [563072/702208 (80%)]	Loss: 0.041807Train Epoch: 10 [564096/702208 (80%)]	Loss: 0.032058Train Epoch: 10 [565120/702208 (80%)]	Loss: 0.044674Train Epoch: 10 [566016/702208 (81%)]	Loss: 0.100482Train Epoch: 10 [567040/702208 (81%)]	Loss: 0.014416Train Epoch: 10 [568064/702208 (81%)]	Loss: 0.097364Train Epoch: 10 [569088/702208 (81%)]	Loss: 0.018176Train Epoch: 10 [570112/702208 (81%)]	Loss: 0.035647Train Epoch: 10 [571008/702208 (81%)]	Loss: 0.043602Train Epoch: 10 [572032/702208 (81%)]	Loss: 0.032230Train Epoch: 10 [573056/702208 (82%)]	Loss: 0.015067Train Epoch: 10 [574080/702208 (82%)]	Loss: 0.090518Train Epoch: 10 [575104/702208 (82%)]	Loss: 0.090863
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8104 / 8283] 97 %
Accuracy of the network on test loader class  1: [4510 / 4517] 99 %

Writing model: iterations-6894976-total-98.55000000000001-class0-97.84-class1-99.85000000000001
Train Epoch: 10 [576000/702208 (82%)]	Loss: 0.012161Train Epoch: 10 [576128/702208 (82%)]	Loss: 0.028141Train Epoch: 10 [577024/702208 (82%)]	Loss: 0.118519Train Epoch: 10 [578048/702208 (82%)]	Loss: 0.047108Train Epoch: 10 [579072/702208 (82%)]	Loss: 0.059313Train Epoch: 10 [580096/702208 (83%)]	Loss: 0.034586Train Epoch: 10 [581120/702208 (83%)]	Loss: 0.040380Train Epoch: 10 [582016/702208 (83%)]	Loss: 0.028869Train Epoch: 10 [583040/702208 (83%)]	Loss: 0.020518Train Epoch: 10 [584064/702208 (83%)]	Loss: 0.010711Train Epoch: 10 [585088/702208 (83%)]	Loss: 0.103705Train Epoch: 10 [586112/702208 (83%)]	Loss: 0.031367Train Epoch: 10 [587008/702208 (84%)]	Loss: 0.211483Train Epoch: 10 [588032/702208 (84%)]	Loss: 0.043162Train Epoch: 10 [589056/702208 (84%)]	Loss: 0.057076Train Epoch: 10 [590080/702208 (84%)]	Loss: 0.063673Train Epoch: 10 [591104/702208 (84%)]	Loss: 0.047952Train Epoch: 10 [592000/702208 (84%)]	Loss: 0.024423Train Epoch: 10 [592128/702208 (84%)]	Loss: 0.057801Train Epoch: 10 [593024/702208 (84%)]	Loss: 0.014421Train Epoch: 10 [594048/702208 (85%)]	Loss: 0.025254Train Epoch: 10 [595072/702208 (85%)]	Loss: 0.024736Train Epoch: 10 [596096/702208 (85%)]	Loss: 0.026024Train Epoch: 10 [597120/702208 (85%)]	Loss: 0.023440Train Epoch: 10 [598016/702208 (85%)]	Loss: 0.056227Train Epoch: 10 [599040/702208 (85%)]	Loss: 0.048389Train Epoch: 10 [600064/702208 (85%)]	Loss: 0.087153
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8118 / 8283] 98 %
Accuracy of the network on test loader class  1: [4508 / 4517] 99 %

Writing model: iterations-6919936-total-98.64-class0-98.00999999999999-class1-99.8

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12421 / 12833] 96 %
Accuracy of the network on train loader class  1: [7106 / 7135] 99 %
Train Epoch: 10 [601088/702208 (86%)]	Loss: 0.039278Train Epoch: 10 [602112/702208 (86%)]	Loss: 0.099497Train Epoch: 10 [603008/702208 (86%)]	Loss: 0.026375Train Epoch: 10 [604032/702208 (86%)]	Loss: 0.018664Train Epoch: 10 [605056/702208 (86%)]	Loss: 0.033773Train Epoch: 10 [606080/702208 (86%)]	Loss: 0.207614Train Epoch: 10 [607104/702208 (86%)]	Loss: 0.069079Train Epoch: 10 [608000/702208 (87%)]	Loss: 0.089570Train Epoch: 10 [608128/702208 (87%)]	Loss: 0.016908Train Epoch: 10 [609024/702208 (87%)]	Loss: 0.024813Train Epoch: 10 [610048/702208 (87%)]	Loss: 0.032288Train Epoch: 10 [611072/702208 (87%)]	Loss: 0.022976Train Epoch: 10 [612096/702208 (87%)]	Loss: 0.059454Train Epoch: 10 [613120/702208 (87%)]	Loss: 0.115984Train Epoch: 10 [614016/702208 (87%)]	Loss: 0.023021Train Epoch: 10 [615040/702208 (88%)]	Loss: 0.051405Train Epoch: 10 [616064/702208 (88%)]	Loss: 0.074738Train Epoch: 10 [617088/702208 (88%)]	Loss: 0.095579Train Epoch: 10 [618112/702208 (88%)]	Loss: 0.048267Train Epoch: 10 [619008/702208 (88%)]	Loss: 0.033651Train Epoch: 10 [620032/702208 (88%)]	Loss: 0.063340Train Epoch: 10 [621056/702208 (88%)]	Loss: 0.071582Train Epoch: 10 [622080/702208 (89%)]	Loss: 0.071281Train Epoch: 10 [623104/702208 (89%)]	Loss: 0.020230Train Epoch: 10 [624000/702208 (89%)]	Loss: 0.022683Train Epoch: 10 [624128/702208 (89%)]	Loss: 0.039657Train Epoch: 10 [625024/702208 (89%)]	Loss: 0.049609
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8112 / 8283] 97 %
Accuracy of the network on test loader class  1: [4513 / 4517] 99 %

Writing model: iterations-6944896-total-98.63-class0-97.94-class1-99.91
Train Epoch: 10 [626048/702208 (89%)]	Loss: 0.061022Train Epoch: 10 [627072/702208 (89%)]	Loss: 0.084069Train Epoch: 10 [628096/702208 (89%)]	Loss: 0.045266Train Epoch: 10 [629120/702208 (90%)]	Loss: 0.028705Train Epoch: 10 [630016/702208 (90%)]	Loss: 0.068909Train Epoch: 10 [631040/702208 (90%)]	Loss: 0.050102Train Epoch: 10 [632064/702208 (90%)]	Loss: 0.016127Train Epoch: 10 [633088/702208 (90%)]	Loss: 0.029181Train Epoch: 10 [634112/702208 (90%)]	Loss: 0.056176Train Epoch: 10 [635008/702208 (90%)]	Loss: 0.013978Train Epoch: 10 [636032/702208 (91%)]	Loss: 0.052486Train Epoch: 10 [637056/702208 (91%)]	Loss: 0.041507Train Epoch: 10 [638080/702208 (91%)]	Loss: 0.044035Train Epoch: 10 [639104/702208 (91%)]	Loss: 0.023222Train Epoch: 10 [640000/702208 (91%)]	Loss: 0.019328Train Epoch: 10 [640128/702208 (91%)]	Loss: 0.046530Train Epoch: 10 [641024/702208 (91%)]	Loss: 0.093457Train Epoch: 10 [642048/702208 (91%)]	Loss: 0.047137Train Epoch: 10 [643072/702208 (92%)]	Loss: 0.033573Train Epoch: 10 [644096/702208 (92%)]	Loss: 0.017749Train Epoch: 10 [645120/702208 (92%)]	Loss: 0.017482Train Epoch: 10 [646016/702208 (92%)]	Loss: 0.068281Train Epoch: 10 [647040/702208 (92%)]	Loss: 0.035671Train Epoch: 10 [648064/702208 (92%)]	Loss: 0.012070Train Epoch: 10 [649088/702208 (92%)]	Loss: 0.025674Train Epoch: 10 [650112/702208 (93%)]	Loss: 0.045539
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8081 / 8283] 97 %
Accuracy of the network on test loader class  1: [4512 / 4517] 99 %

Writing model: iterations-6969984-total-98.38-class0-97.56-class1-99.89

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 98 %
Accuracy of the network on train loader class  0: [12551 / 12833] 97 %
Accuracy of the network on train loader class  1: [7095 / 7135] 99 %
Train Epoch: 10 [651008/702208 (93%)]	Loss: 0.081259Train Epoch: 10 [652032/702208 (93%)]	Loss: 0.076869Train Epoch: 10 [653056/702208 (93%)]	Loss: 0.078534Train Epoch: 10 [654080/702208 (93%)]	Loss: 0.035515Train Epoch: 10 [655104/702208 (93%)]	Loss: 0.054337Train Epoch: 10 [656000/702208 (93%)]	Loss: 0.060800Train Epoch: 10 [656128/702208 (93%)]	Loss: 0.018884Train Epoch: 10 [657024/702208 (94%)]	Loss: 0.051521Train Epoch: 10 [658048/702208 (94%)]	Loss: 0.030351Train Epoch: 10 [659072/702208 (94%)]	Loss: 0.027193Train Epoch: 10 [660096/702208 (94%)]	Loss: 0.023666Train Epoch: 10 [661120/702208 (94%)]	Loss: 0.038445Train Epoch: 10 [662016/702208 (94%)]	Loss: 0.031085Train Epoch: 10 [663040/702208 (94%)]	Loss: 0.078875Train Epoch: 10 [664064/702208 (95%)]	Loss: 0.070273Train Epoch: 10 [665088/702208 (95%)]	Loss: 0.060477Train Epoch: 10 [666112/702208 (95%)]	Loss: 0.045018Train Epoch: 10 [667008/702208 (95%)]	Loss: 0.059716Train Epoch: 10 [668032/702208 (95%)]	Loss: 0.078981Train Epoch: 10 [669056/702208 (95%)]	Loss: 0.010758Train Epoch: 10 [670080/702208 (95%)]	Loss: 0.055883Train Epoch: 10 [671104/702208 (96%)]	Loss: 0.135136Train Epoch: 10 [672000/702208 (96%)]	Loss: 0.118668Train Epoch: 10 [672128/702208 (96%)]	Loss: 0.014164Train Epoch: 10 [673024/702208 (96%)]	Loss: 0.092117Train Epoch: 10 [674048/702208 (96%)]	Loss: 0.039977Train Epoch: 10 [675072/702208 (96%)]	Loss: 0.036735
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [8001 / 8283] 96 %
Accuracy of the network on test loader class  1: [4505 / 4517] 99 %

Writing model: iterations-6994944-total-97.7-class0-96.6-class1-99.72999999999999
Train Epoch: 10 [676096/702208 (96%)]	Loss: 0.103236Train Epoch: 10 [677120/702208 (96%)]	Loss: 0.048338Train Epoch: 10 [678016/702208 (97%)]	Loss: 0.059705Train Epoch: 10 [679040/702208 (97%)]	Loss: 0.043761Train Epoch: 10 [680064/702208 (97%)]	Loss: 0.116626Train Epoch: 10 [681088/702208 (97%)]	Loss: 0.055691Train Epoch: 10 [682112/702208 (97%)]	Loss: 0.030205Train Epoch: 10 [683008/702208 (97%)]	Loss: 0.027878Train Epoch: 10 [684032/702208 (97%)]	Loss: 0.031889Train Epoch: 10 [685056/702208 (98%)]	Loss: 0.044960Train Epoch: 10 [686080/702208 (98%)]	Loss: 0.036393Train Epoch: 10 [687104/702208 (98%)]	Loss: 0.056124Train Epoch: 10 [688000/702208 (98%)]	Loss: 0.056190Train Epoch: 10 [688128/702208 (98%)]	Loss: 0.076174Train Epoch: 10 [689024/702208 (98%)]	Loss: 0.060598Train Epoch: 10 [690048/702208 (98%)]	Loss: 0.033008Train Epoch: 10 [691072/702208 (98%)]	Loss: 0.034924Train Epoch: 10 [692096/702208 (99%)]	Loss: 0.010783Train Epoch: 10 [693120/702208 (99%)]	Loss: 0.036095Train Epoch: 10 [694016/702208 (99%)]	Loss: 0.029675Train Epoch: 10 [695040/702208 (99%)]	Loss: 0.027213Train Epoch: 10 [696064/702208 (99%)]	Loss: 0.108480Train Epoch: 10 [697088/702208 (99%)]	Loss: 0.037877Train Epoch: 10 [698112/702208 (99%)]	Loss: 0.040499Train Epoch: 10 [699008/702208 (100%)]	Loss: 0.030604Train Epoch: 10 [700032/702208 (100%)]	Loss: 0.050705
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 98 %
Accuracy of the network on test loader class  0: [8079 / 8283] 97 %
Accuracy of the network on test loader class  1: [4514 / 4517] 99 %

Writing model: iterations-7019904-total-98.38-class0-97.54-class1-99.92999999999999

Testing for train loader...
128/19968256/19968384/19968512/19968640/19968768/19968896/199681024/199681152/199681280/199681408/199681536/199681664/199681792/199681920/199682048/199682176/199682304/199682432/199682560/199682688/199682816/199682944/199683072/199683200/199683328/199683456/199683584/199683712/199683840/199683968/199684096/199684224/199684352/199684480/199684608/199684736/199684864/199684992/199685120/199685248/199685376/199685504/199685632/199685760/199685888/199686016/199686144/199686272/199686400/199686528/199686656/199686784/199686912/199687040/199687168/199687296/199687424/199687552/199687680/199687808/199687936/199688064/199688192/199688320/199688448/199688576/199688704/199688832/199688960/199689088/199689216/199689344/199689472/199689600/199689728/199689856/199689984/1996810112/1996810240/1996810368/1996810496/1996810624/1996810752/1996810880/1996811008/1996811136/1996811264/1996811392/1996811520/1996811648/1996811776/1996811904/1996812032/1996812160/1996812288/1996812416/1996812544/1996812672/1996812800/1996812928/1996813056/1996813184/1996813312/1996813440/1996813568/1996813696/1996813824/1996813952/1996814080/1996814208/1996814336/1996814464/1996814592/1996814720/1996814848/1996814976/1996815104/1996815232/1996815360/1996815488/1996815616/1996815744/1996815872/1996816000/1996816128/1996816256/1996816384/1996816512/1996816640/1996816768/1996816896/1996817024/1996817152/1996817280/1996817408/1996817536/1996817664/1996817792/1996817920/1996818048/1996818176/1996818304/1996818432/1996818560/1996818688/1996818816/1996818944/1996819072/1996819200/1996819328/1996819456/1996819584/1996819712/1996819840/1996819968/19968
Accuracy of the network on train loader images: 97 %
Accuracy of the network on train loader class  0: [12391 / 12833] 96 %
Accuracy of the network on train loader class  1: [7118 / 7135] 99 %
Train Epoch: 10 [701056/702208 (100%)]	Loss: 0.059772Train Epoch: 10 [702080/702208 (100%)]	Loss: 0.098381
Testing for test loader...
128/12800256/12800384/12800512/12800640/12800768/12800896/128001024/128001152/128001280/128001408/128001536/128001664/128001792/128001920/128002048/128002176/128002304/128002432/128002560/128002688/128002816/128002944/128003072/128003200/128003328/128003456/128003584/128003712/128003840/128003968/128004096/128004224/128004352/128004480/128004608/128004736/128004864/128004992/128005120/128005248/128005376/128005504/128005632/128005760/128005888/128006016/128006144/128006272/128006400/128006528/128006656/128006784/128006912/128007040/128007168/128007296/128007424/128007552/128007680/128007808/128007936/128008064/128008192/128008320/128008448/128008576/128008704/128008832/128008960/128009088/128009216/128009344/128009472/128009600/128009728/128009856/128009984/1280010112/1280010240/1280010368/1280010496/1280010624/1280010752/1280010880/1280011008/1280011136/1280011264/1280011392/1280011520/1280011648/1280011776/1280011904/1280012032/1280012160/1280012288/1280012416/1280012544/1280012672/1280012800/12800
Accuracy of the network on test loader images: 97 %
Accuracy of the network on test loader class  0: [7994 / 8283] 96 %
Accuracy of the network on test loader class  1: [4511 / 4517] 99 %
